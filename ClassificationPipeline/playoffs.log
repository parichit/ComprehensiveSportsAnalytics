nohup: ignoring input
[1] "Started execution on: 2023-05-29 23:29:01"
[1] "###################################"
[1] "1 Install packages"
[1] "###################################"

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union


Attaching package: ‘gridExtra’

The following object is masked from ‘package:dplyr’:

    combine

[1] "Total classification models:  141 Number of required libraries: 42 Number of missing libraries:  0"
[1] "No missing libraries found"
[1] "42 required libraries already installed"
[1] "Total Models: 141"
[1] "###################################"
[1] "2 READ/COMBINE DATA"
[1] "###################################"
Loading required package: readxl
Loading required package: stringr
Loading required package: caret
Loading required package: lattice
[1] "Data read-in successfully"
[1] "Rows: 270  Cols: 23"
Loading required package: tidyverse
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ forcats   1.0.0     ✔ readr     2.1.4
✔ lubridate 1.9.2     ✔ tibble    3.2.1
✔ purrr     1.0.1     ✔ tidyr     1.3.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ gridExtra::combine() masks dplyr::combine()
✖ tidyr::extract()     masks magrittr::extract()
✖ dplyr::filter()      masks stats::filter()
✖ dplyr::lag()         masks stats::lag()
✖ purrr::lift()        masks caret::lift()
✖ purrr::set_names()   masks magrittr::set_names()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
Loading required package: caretEnsemble

Attaching package: ‘caretEnsemble’

The following object is masked from ‘package:ggplot2’:

    autoplot

Loading required package: ggthemes
Loading required package: xtable
Loading required package: tictoc
Loading required package: R.utils
Loading required package: R.oo
Loading required package: R.methodsS3
R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.
R.oo v1.25.0 (2022-06-12 02:20:02 UTC) successfully loaded. See ?R.oo for help.

Attaching package: ‘R.oo’

The following object is masked from ‘package:R.methodsS3’:

    throw

The following object is masked from ‘package:magrittr’:

    equals

The following objects are masked from ‘package:methods’:

    getClasses, getMethods

The following objects are masked from ‘package:base’:

    attach, detach, load, save

R.utils v2.12.2 (2022-11-11 22:00:03 UTC) successfully loaded. See ?R.utils for help.

Attaching package: ‘R.utils’

The following object is masked from ‘package:tidyr’:

    extract

The following object is masked from ‘package:magrittr’:

    extract

The following object is masked from ‘package:utils’:

    timestamp

The following objects are masked from ‘package:base’:

    cat, commandArgs, getOption, isOpen, nullfile, parse, warnings

[1] "###################################"
[1] "3 RUN MODELS FOR PREDICTING REAL COMPONENT OF IMPEDANCE"
[1] "###################################"
[1] "/nfs/nfs8/home/scratch/parishar/ComprehensiveSportsAnalytics/NBA_Playoffs/train_results.csv"
[1] "/nfs/nfs8/home/scratch/parishar/ComprehensiveSportsAnalytics/NBA_Playoffs/test_results.csv"
[1] "Running bartMachine"
<simpleError in tuneGrid[!duplicated(tuneGrid), , drop = FALSE]: incorrect number of dimensions>
0.313 sec elapsed
[1] "Running bayesglm"
1.43 sec elapsed
[1] "Running glm"
0.431 sec elapsed
[1] "Running binda"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3    
<simpleError: Stopping>
0.436 sec elapsed
[1] "Running blackboost"
55.963 sec elapsed
[1] "Running cforest"
48.022 sec elapsed
[1] "Running ctree"
1.931 sec elapsed
[1] "Running ctree2"
4.619 sec elapsed
[1] "Running BstLm"
4.313 sec elapsed
[1] "Running bstSm"
83.101 sec elapsed
[1] "Running bstTree"
73.801 sec elapsed
[1] "Running C5.0"
10.369 sec elapsed
[1] "Running C5.0Cost"
19.279 sec elapsed
[1] "Running C5.0Rules"
1.108 sec elapsed
[1] "Running C5.0Tree"
1.109 sec elapsed
[1] "Running CSimca"
Registered S3 methods overwritten by 'spls':
  method         from 
  predict.splsda caret
  print.splsda   caret
0.941 sec elapsed
[1] "Running Linda"
14.271 sec elapsed
[1] "Running QdaCov"
8.502 sec elapsed
[1] "Running dda"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :6     NA's   :6    
<simpleError: Stopping>
0.953 sec elapsed
[1] "Running hdrda"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :18    NA's   :18   
<simpleError: Stopping>
1.964 sec elapsed
[1] "Running rda"
6.045 sec elapsed
[1] "Running rlda"
<simpleError in {    if (!(length(ctrl$seeds) == 1 && is.na(ctrl$seeds)))         set.seed(ctrl$seeds[[iter]][parm])    loadNamespace("caret")    lapply(pkgs, requireNamespaceQuietStop)    if (ctrl$verboseIter)         progress(printed[parm, , drop = FALSE], names(resampleIndex),             iter)    if (names(resampleIndex)[iter] != "AllData") {        modelIndex <- resampleIndex[[iter]]        holdoutIndex <- ctrl$indexOut[[iter]]    }    else {        modelIndex <- 1:nrow(x)        holdoutIndex <- modelIndex    }    if (testing)         cat("pre-model\n")    if (!is.null(info$submodels[[parm]]) && nrow(info$submodels[[parm]]) >         0) {        submod <- info$submodels[[parm]]    }    else submod <- NULL    mod <- try(createModel(x = subset_x(x, modelIndex), y = y[modelIndex],         wts = wts[modelIndex], method = method, tuneValue = info$loop[parm,             , drop = FALSE], obsLevels = lev, pp = ppp, classProbs = ctrl$classProbs,         sampling = ctrl$sampling, ...), silent = TRUE)    if (testing)         print(mod)    if (!model_failed(mod)) {        predicted <- try(predictionFunction(method = method,             modelFit = mod$fit, newdata = subset_x(x, holdoutIndex),             preProc = mod$preProc, param = submod), silent = TRUE)        if (pred_failed(predicted)) {            fail_warning(settings = printed[parm, , drop = FALSE],                 msg = predicted, where = "predictions", iter = names(resampleIndex)[iter],                 verb = ctrl$verboseIter)            predicted <- fill_failed_pred(index = holdoutIndex,                 lev = lev, submod)        }    }    else {        fail_warning(settings = printed[parm, , drop = FALSE],             msg = mod, iter = names(resampleIndex)[iter], verb = ctrl$verboseIter)        predicted <- fill_failed_pred(index = holdoutIndex, lev = lev,             submod)    }    if (testing)         print(head(predicted))    if (ctrl$classProbs) {        if (!model_failed(mod)) {            probValues <- probFunction(method = method, modelFit = mod$fit,                 newdata = subset_x(x, holdoutIndex), preProc = mod$preProc,                 param = submod)        }        else {            probValues <- fill_failed_prob(holdoutIndex, lev,                 submod)        }        if (testing)             print(head(probValues))    }    predicted <- trim_values(predicted, ctrl, is.null(lev))    if (!is.null(submod)) {        allParam <- expandParameters(info$loop[parm, , drop = FALSE],             info$submodels[[parm]])        allParam <- allParam[complete.cases(allParam), , drop = FALSE]        predicted <- lapply(predicted, function(x, y, wts, lv,             rows) {            x <- outcome_conversion(x, lv = lev)            out <- data.frame(pred = x, obs = y, stringsAsFactors = FALSE)            if (!is.null(wts))                 out$weights <- wts            out$rowIndex <- rows            out        }, y = y[holdoutIndex], wts = wts[holdoutIndex], lv = lev,             rows = holdoutIndex)        if (ctrl$classProbs)             predicted <- mapply(cbind, predicted, probValues,                 SIMPLIFY = FALSE)        if (keep_pred) {            tmpPred <- predicted            for (modIndex in seq(along = tmpPred)) {                tmpPred[[modIndex]] <- merge(tmpPred[[modIndex]],                   allParam[modIndex, , drop = FALSE], all = TRUE)            }            tmpPred <- rbind.fill(tmpPred)            tmpPred$Resample <- names(resampleIndex)[iter]        }        else tmpPred <- NULL        thisResample <- lapply(predicted, ctrl$summaryFunction,             lev = lev, model = method)        if (testing)             print(head(thisResample))        if (length(lev) > 1 && length(lev) <= 50) {            cells <- lapply(predicted, function(x) flatTable(x$pred,                 x$obs))            for (ind in seq(along = cells)) thisResample[[ind]] <- c(thisResample[[ind]],                 cells[[ind]])        }        thisResample <- do.call("rbind", thisResample)        thisResample <- cbind(allParam, thisResample)    }    else {        if (is.factor(y))             predicted <- outcome_conversion(predicted, lv = lev)        tmp <- data.frame(pred = predicted, obs = y[holdoutIndex],             stringsAsFactors = FALSE)        names(tmp)[1] <- "pred"        if (!is.null(wts))             tmp$weights <- wts[holdoutIndex]        if (ctrl$classProbs)             tmp <- cbind(tmp, probValues)        tmp$rowIndex <- holdoutIndex        if (keep_pred) {            tmpPred <- tmp            tmpPred$rowIndex <- holdoutIndex            tmpPred <- merge(tmpPred, info$loop[parm, , drop = FALSE],                 all = TRUE)            tmpPred$Resample <- names(resampleIndex)[iter]        }        else tmpPred <- NULL        thisResample <- ctrl$summaryFunction(tmp, lev = lev,             model = method)        if (length(lev) > 1 && length(lev) <= 50)             thisResample <- c(thisResample, flatTable(tmp$pred,                 tmp$obs))        thisResample <- as.data.frame(t(thisResample), stringsAsFactors = FALSE)        thisResample <- cbind(thisResample, info$loop[parm, ,             drop = FALSE])    }    thisResample$Resample <- names(resampleIndex)[iter]    thisResampleExtra <- optimism_xy(ctrl, x, y, wts, iter, lev,         method, mod, predicted, submod, info$loop[parm, , drop = FALSE])    if (ctrl$verboseIter)         progress(printed[parm, , drop = FALSE], names(resampleIndex),             iter, FALSE)    if (testing)         print(thisResample)    list(resamples = thisResample, pred = tmpPred, resamplesExtra = thisResampleExtra)}: task 1 failed - "$ operator is invalid for atomic vectors">
1.218 sec elapsed
[1] "Running dnn"
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
77.506 sec elapsed
[1] "Running dwdLinear"
1.468 sec elapsed
[1] "Running dwdPoly"
38.517 sec elapsed
[1] "Running dwdRadial"
5.94 sec elapsed
[1] "Running gaussprLinear"
44.761 sec elapsed
[1] "Running gaussprPoly"
37.282 sec elapsed
[1] "Running gaussprRadial"
1.389 sec elapsed
[1] "Running lssvmLinear"
<simpleError in if (truegain[k] < tol) break: missing value where TRUE/FALSE needed>
7.249 sec elapsed
[1] "Running lssvmPoly"
<simpleError in if (truegain[k] < tol) break: missing value where TRUE/FALSE needed>
46.187 sec elapsed
[1] "Running lssvmRadial"
65.344 sec elapsed
[1] "Running svmBoundrangeString"
<simpleError: 'x' should be a character matrix with a single column for string kernel methods>
0.03 sec elapsed
[1] "Running svmExpoString"
<simpleError: 'x' should be a character matrix with a single column for string kernel methods>
0.029 sec elapsed
[1] "Running svmLinear"
1.704 sec elapsed
[1] "Running svmPoly"
21.457 sec elapsed
[1] "Running svmRadial"
2.463 sec elapsed
[1] "Running svmRadialCost"
2.453 sec elapsed
[1] "Running svmRadialSigma"
7.169 sec elapsed
[1] "Running svmRadialWeights"
6.32 sec elapsed
[1] "Running svmSpectrumString"
<simpleError: 'x' should be a character matrix with a single column for string kernel methods>
0.03 sec elapsed
[1] "Running evtree"
137.075 sec elapsed
[1] "Running FH.GBML"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |=====================                                                 |  30%  |                                                                              |============================                                          |  40%  |                                                                              |===================================                                   |  50%  |                                                                              |==========================================                            |  60%  |                                                                              |=================================================                     |  70%  |                                                                              |========================================================              |  80%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
<simpleError in FH.GBML(data.tra.norm, popu.size, max.num.rule, persen_cross,     persen_mutant, max.gen, num.class, range.data.input, p.dcare,     p.gccl): frbs cannot generate the fuzzy rules, please set the higher value of popu.size and max.num.rule>
8227.59 sec elapsed
[1] "Running FRBCS.CHI"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
909.755 sec elapsed
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "Running FRBCS.W"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
910.581 sec elapsed
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "note: Some of your new data are out of the previously specified range"
[1] "Running SLAVE"
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   0%Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3    
<simpleError: Stopping>
5.071 sec elapsed
[1] "Running gamboost"
8.259 sec elapsed
[1] "Running gamLoess"
Loading required package: gam
Loading required package: splines
Loading required package: foreach

Attaching package: ‘foreach’

The following objects are masked from ‘package:purrr’:

    accumulate, when

Loaded gam 1.22-2

21.707 sec elapsed
[1] "Running gamSpline"
33.958 sec elapsed
[1] "Running gbm"
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3218            -nan     0.1000    0.0233
     2        1.2806            -nan     0.1000    0.0232
     3        1.2352            -nan     0.1000    0.0209
     4        1.2025            -nan     0.1000    0.0131
     5        1.1672            -nan     0.1000    0.0110
     6        1.1451            -nan     0.1000    0.0075
     7        1.1247            -nan     0.1000    0.0067
     8        1.1056            -nan     0.1000    0.0062
     9        1.0868            -nan     0.1000    0.0018
    10        1.0689            -nan     0.1000    0.0028
    20        0.9553            -nan     0.1000   -0.0029
    40        0.8153            -nan     0.1000    0.0006
    60        0.7314            -nan     0.1000   -0.0016
    80        0.6656            -nan     0.1000   -0.0000
   100        0.6075            -nan     0.1000   -0.0006
   120        0.5684            -nan     0.1000   -0.0038
   140        0.5238            -nan     0.1000   -0.0019
   150        0.5038            -nan     0.1000   -0.0015

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3067            -nan     0.1000    0.0248
     2        1.2484            -nan     0.1000    0.0237
     3        1.1900            -nan     0.1000    0.0198
     4        1.1440            -nan     0.1000    0.0154
     5        1.1057            -nan     0.1000    0.0165
     6        1.0742            -nan     0.1000    0.0102
     7        1.0482            -nan     0.1000    0.0054
     8        1.0148            -nan     0.1000    0.0133
     9        0.9941            -nan     0.1000    0.0040
    10        0.9698            -nan     0.1000    0.0099
    20        0.7961            -nan     0.1000   -0.0016
    40        0.6071            -nan     0.1000    0.0002
    60        0.4898            -nan     0.1000   -0.0038
    80        0.4107            -nan     0.1000   -0.0040
   100        0.3395            -nan     0.1000   -0.0002
   120        0.2901            -nan     0.1000   -0.0023
   140        0.2481            -nan     0.1000   -0.0036
   150        0.2268            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2766            -nan     0.1000    0.0395
     2        1.2054            -nan     0.1000    0.0289
     3        1.1470            -nan     0.1000    0.0233
     4        1.0914            -nan     0.1000    0.0230
     5        1.0555            -nan     0.1000    0.0080
     6        1.0021            -nan     0.1000    0.0157
     7        0.9676            -nan     0.1000    0.0080
     8        0.9227            -nan     0.1000    0.0167
     9        0.8886            -nan     0.1000    0.0121
    10        0.8525            -nan     0.1000    0.0115
    20        0.6625            -nan     0.1000    0.0020
    40        0.4615            -nan     0.1000   -0.0030
    60        0.3460            -nan     0.1000   -0.0011
    80        0.2701            -nan     0.1000   -0.0002
   100        0.2069            -nan     0.1000   -0.0002
   120        0.1616            -nan     0.1000   -0.0009
   140        0.1315            -nan     0.1000   -0.0011
   150        0.1178            -nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3309            -nan     0.1000    0.0223
     2        1.2933            -nan     0.1000    0.0146
     3        1.2543            -nan     0.1000    0.0151
     4        1.2103            -nan     0.1000    0.0162
     5        1.1738            -nan     0.1000    0.0147
     6        1.1482            -nan     0.1000    0.0065
     7        1.1236            -nan     0.1000    0.0093
     8        1.1062            -nan     0.1000    0.0083
     9        1.0891            -nan     0.1000    0.0070
    10        1.0704            -nan     0.1000    0.0055
    20        0.9537            -nan     0.1000    0.0008
    40        0.8300            -nan     0.1000   -0.0020
    60        0.7416            -nan     0.1000   -0.0002
    80        0.6731            -nan     0.1000   -0.0003
   100        0.6168            -nan     0.1000   -0.0019
   120        0.5759            -nan     0.1000   -0.0027
   140        0.5337            -nan     0.1000   -0.0020
   150        0.5122            -nan     0.1000    0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3158            -nan     0.1000    0.0249
     2        1.2681            -nan     0.1000    0.0191
     3        1.2204            -nan     0.1000    0.0199
     4        1.1792            -nan     0.1000    0.0165
     5        1.1355            -nan     0.1000    0.0188
     6        1.1056            -nan     0.1000    0.0078
     7        1.0782            -nan     0.1000    0.0104
     8        1.0501            -nan     0.1000    0.0077
     9        1.0212            -nan     0.1000    0.0083
    10        0.9947            -nan     0.1000    0.0072
    20        0.8185            -nan     0.1000    0.0001
    40        0.6340            -nan     0.1000    0.0002
    60        0.5125            -nan     0.1000   -0.0006
    80        0.4240            -nan     0.1000   -0.0022
   100        0.3585            -nan     0.1000   -0.0009
   120        0.3054            -nan     0.1000   -0.0012
   140        0.2629            -nan     0.1000   -0.0011
   150        0.2433            -nan     0.1000   -0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2984            -nan     0.1000    0.0335
     2        1.2324            -nan     0.1000    0.0164
     3        1.1717            -nan     0.1000    0.0255
     4        1.1212            -nan     0.1000    0.0219
     5        1.0864            -nan     0.1000    0.0083
     6        1.0516            -nan     0.1000    0.0143
     7        1.0063            -nan     0.1000    0.0162
     8        0.9748            -nan     0.1000    0.0039
     9        0.9460            -nan     0.1000    0.0091
    10        0.9223            -nan     0.1000    0.0067
    20        0.7321            -nan     0.1000    0.0033
    40        0.5076            -nan     0.1000   -0.0006
    60        0.3691            -nan     0.1000   -0.0009
    80        0.2807            -nan     0.1000   -0.0022
   100        0.2153            -nan     0.1000   -0.0018
   120        0.1622            -nan     0.1000   -0.0001
   140        0.1249            -nan     0.1000   -0.0004
   150        0.1112            -nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3449            -nan     0.1000    0.0172
     2        1.3089            -nan     0.1000    0.0109
     3        1.2742            -nan     0.1000    0.0134
     4        1.2481            -nan     0.1000    0.0090
     5        1.2247            -nan     0.1000    0.0064
     6        1.2001            -nan     0.1000    0.0096
     7        1.1850            -nan     0.1000    0.0054
     8        1.1706            -nan     0.1000    0.0035
     9        1.1548            -nan     0.1000    0.0018
    10        1.1402            -nan     0.1000   -0.0005
    20        1.0343            -nan     0.1000    0.0005
    40        0.9028            -nan     0.1000   -0.0043
    60        0.8067            -nan     0.1000    0.0002
    80        0.7276            -nan     0.1000   -0.0010
   100        0.6647            -nan     0.1000   -0.0006
   120        0.6125            -nan     0.1000   -0.0011
   140        0.5696            -nan     0.1000   -0.0010
   150        0.5501            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3433            -nan     0.1000    0.0141
     2        1.3020            -nan     0.1000    0.0176
     3        1.2512            -nan     0.1000    0.0259
     4        1.2203            -nan     0.1000    0.0106
     5        1.1899            -nan     0.1000    0.0140
     6        1.1563            -nan     0.1000    0.0063
     7        1.1319            -nan     0.1000    0.0059
     8        1.1077            -nan     0.1000    0.0076
     9        1.0794            -nan     0.1000    0.0069
    10        1.0474            -nan     0.1000    0.0055
    20        0.8832            -nan     0.1000    0.0010
    40        0.6581            -nan     0.1000    0.0023
    60        0.5342            -nan     0.1000   -0.0047
    80        0.4454            -nan     0.1000   -0.0000
   100        0.3789            -nan     0.1000   -0.0007
   120        0.3240            -nan     0.1000   -0.0026
   140        0.2751            -nan     0.1000   -0.0011
   150        0.2563            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3232            -nan     0.1000    0.0261
     2        1.2581            -nan     0.1000    0.0298
     3        1.1915            -nan     0.1000    0.0217
     4        1.1505            -nan     0.1000    0.0077
     5        1.1113            -nan     0.1000    0.0080
     6        1.0701            -nan     0.1000    0.0139
     7        1.0289            -nan     0.1000    0.0103
     8        1.0070            -nan     0.1000    0.0062
     9        0.9757            -nan     0.1000    0.0088
    10        0.9350            -nan     0.1000    0.0112
    20        0.7316            -nan     0.1000    0.0046
    40        0.5024            -nan     0.1000    0.0003
    60        0.3742            -nan     0.1000   -0.0016
    80        0.2882            -nan     0.1000   -0.0032
   100        0.2234            -nan     0.1000   -0.0012
   120        0.1734            -nan     0.1000    0.0000
   140        0.1394            -nan     0.1000   -0.0010
   150        0.1268            -nan     0.1000   -0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3297            -nan     0.1000    0.0272
     2        1.2837            -nan     0.1000    0.0184
     3        1.2541            -nan     0.1000    0.0107
     4        1.2138            -nan     0.1000    0.0149
     5        1.1946            -nan     0.1000    0.0060
     6        1.1705            -nan     0.1000    0.0045
     7        1.1477            -nan     0.1000    0.0119
     8        1.1247            -nan     0.1000    0.0069
     9        1.1089            -nan     0.1000    0.0067
    10        1.0921            -nan     0.1000    0.0064
    20        1.0003            -nan     0.1000   -0.0001
    40        0.8803            -nan     0.1000   -0.0004
    60        0.7909            -nan     0.1000   -0.0011
    80        0.7244            -nan     0.1000   -0.0003
   100        0.6646            -nan     0.1000   -0.0020
   120        0.6227            -nan     0.1000   -0.0006
   140        0.5757            -nan     0.1000   -0.0016
   150        0.5502            -nan     0.1000   -0.0011

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3215            -nan     0.1000    0.0264
     2        1.2733            -nan     0.1000    0.0140
     3        1.2291            -nan     0.1000    0.0219
     4        1.1882            -nan     0.1000    0.0162
     5        1.1585            -nan     0.1000    0.0088
     6        1.1198            -nan     0.1000    0.0107
     7        1.0918            -nan     0.1000    0.0075
     8        1.0645            -nan     0.1000    0.0084
     9        1.0472            -nan     0.1000    0.0037
    10        1.0227            -nan     0.1000    0.0097
    20        0.8546            -nan     0.1000   -0.0034
    40        0.6548            -nan     0.1000    0.0025
    60        0.5409            -nan     0.1000   -0.0003
    80        0.4443            -nan     0.1000   -0.0031
   100        0.3687            -nan     0.1000   -0.0004
   120        0.3135            -nan     0.1000   -0.0007
   140        0.2708            -nan     0.1000   -0.0001
   150        0.2547            -nan     0.1000   -0.0017

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2977            -nan     0.1000    0.0307
     2        1.2350            -nan     0.1000    0.0253
     3        1.1819            -nan     0.1000    0.0163
     4        1.1309            -nan     0.1000    0.0197
     5        1.0760            -nan     0.1000    0.0215
     6        1.0360            -nan     0.1000    0.0101
     7        0.9998            -nan     0.1000    0.0132
     8        0.9679            -nan     0.1000    0.0089
     9        0.9395            -nan     0.1000    0.0090
    10        0.9143            -nan     0.1000    0.0021
    20        0.7185            -nan     0.1000    0.0005
    40        0.4991            -nan     0.1000   -0.0035
    60        0.3692            -nan     0.1000    0.0001
    80        0.2859            -nan     0.1000   -0.0002
   100        0.2268            -nan     0.1000   -0.0011
   120        0.1779            -nan     0.1000   -0.0014
   140        0.1441            -nan     0.1000   -0.0015
   150        0.1292            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3293            -nan     0.1000    0.0176
     2        1.2947            -nan     0.1000    0.0134
     3        1.2644            -nan     0.1000    0.0160
     4        1.2402            -nan     0.1000    0.0095
     5        1.2169            -nan     0.1000    0.0080
     6        1.2009            -nan     0.1000    0.0043
     7        1.1730            -nan     0.1000    0.0096
     8        1.1576            -nan     0.1000    0.0034
     9        1.1458            -nan     0.1000    0.0031
    10        1.1288            -nan     0.1000    0.0071
    20        1.0195            -nan     0.1000    0.0029
    40        0.8857            -nan     0.1000   -0.0003
    60        0.7952            -nan     0.1000   -0.0022
    80        0.7331            -nan     0.1000   -0.0005
   100        0.6764            -nan     0.1000   -0.0030
   120        0.6309            -nan     0.1000   -0.0032
   140        0.5908            -nan     0.1000   -0.0014
   150        0.5710            -nan     0.1000   -0.0021

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3104            -nan     0.1000    0.0259
     2        1.2641            -nan     0.1000    0.0164
     3        1.2228            -nan     0.1000    0.0174
     4        1.1873            -nan     0.1000    0.0103
     5        1.1515            -nan     0.1000    0.0143
     6        1.1086            -nan     0.1000    0.0153
     7        1.0816            -nan     0.1000    0.0098
     8        1.0624            -nan     0.1000    0.0043
     9        1.0410            -nan     0.1000    0.0004
    10        1.0238            -nan     0.1000   -0.0007
    20        0.8557            -nan     0.1000    0.0012
    40        0.6823            -nan     0.1000   -0.0032
    60        0.5544            -nan     0.1000    0.0011
    80        0.4751            -nan     0.1000   -0.0002
   100        0.4131            -nan     0.1000   -0.0033
   120        0.3570            -nan     0.1000   -0.0033
   140        0.3008            -nan     0.1000   -0.0021
   150        0.2814            -nan     0.1000   -0.0016

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2992            -nan     0.1000    0.0309
     2        1.2351            -nan     0.1000    0.0241
     3        1.1767            -nan     0.1000    0.0213
     4        1.1302            -nan     0.1000    0.0175
     5        1.0827            -nan     0.1000    0.0145
     6        1.0523            -nan     0.1000    0.0080
     7        1.0244            -nan     0.1000   -0.0004
     8        0.9950            -nan     0.1000    0.0067
     9        0.9688            -nan     0.1000    0.0050
    10        0.9443            -nan     0.1000    0.0041
    20        0.7534            -nan     0.1000    0.0003
    40        0.5405            -nan     0.1000   -0.0009
    60        0.4105            -nan     0.1000   -0.0052
    80        0.3108            -nan     0.1000    0.0005
   100        0.2521            -nan     0.1000   -0.0008
   120        0.2011            -nan     0.1000   -0.0004
   140        0.1574            -nan     0.1000   -0.0013
   150        0.1394            -nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3447            -nan     0.1000    0.0186
     2        1.3181            -nan     0.1000    0.0098
     3        1.2843            -nan     0.1000    0.0085
     4        1.2604            -nan     0.1000    0.0083
     5        1.2344            -nan     0.1000    0.0122
     6        1.2151            -nan     0.1000    0.0071
     7        1.1990            -nan     0.1000    0.0044
     8        1.1799            -nan     0.1000    0.0051
     9        1.1645            -nan     0.1000    0.0041
    10        1.1499            -nan     0.1000    0.0044
    20        1.0567            -nan     0.1000    0.0035
    40        0.9313            -nan     0.1000    0.0008
    60        0.8366            -nan     0.1000   -0.0038
    80        0.7591            -nan     0.1000   -0.0007
   100        0.6879            -nan     0.1000   -0.0008
   120        0.6319            -nan     0.1000   -0.0016
   140        0.5917            -nan     0.1000   -0.0011
   150        0.5656            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3270            -nan     0.1000    0.0260
     2        1.2740            -nan     0.1000    0.0158
     3        1.2329            -nan     0.1000    0.0103
     4        1.1989            -nan     0.1000    0.0092
     5        1.1699            -nan     0.1000    0.0092
     6        1.1409            -nan     0.1000    0.0082
     7        1.1121            -nan     0.1000    0.0108
     8        1.0934            -nan     0.1000    0.0006
     9        1.0732            -nan     0.1000    0.0014
    10        1.0500            -nan     0.1000    0.0079
    20        0.8914            -nan     0.1000    0.0033
    40        0.7017            -nan     0.1000   -0.0037
    60        0.5555            -nan     0.1000   -0.0023
    80        0.4547            -nan     0.1000   -0.0017
   100        0.3743            -nan     0.1000   -0.0007
   120        0.3080            -nan     0.1000    0.0003
   140        0.2563            -nan     0.1000   -0.0023
   150        0.2349            -nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3115            -nan     0.1000    0.0210
     2        1.2529            -nan     0.1000    0.0250
     3        1.2046            -nan     0.1000    0.0099
     4        1.1549            -nan     0.1000    0.0154
     5        1.1246            -nan     0.1000    0.0096
     6        1.0937            -nan     0.1000    0.0086
     7        1.0632            -nan     0.1000    0.0069
     8        1.0413            -nan     0.1000    0.0012
     9        1.0072            -nan     0.1000    0.0102
    10        0.9785            -nan     0.1000    0.0029
    20        0.7675            -nan     0.1000    0.0012
    40        0.5201            -nan     0.1000    0.0014
    60        0.3772            -nan     0.1000   -0.0006
    80        0.2768            -nan     0.1000   -0.0012
   100        0.2079            -nan     0.1000   -0.0009
   120        0.1543            -nan     0.1000   -0.0010
   140        0.1207            -nan     0.1000   -0.0001
   150        0.1062            -nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3221            -nan     0.1000    0.0184
     2        1.2816            -nan     0.1000    0.0145
     3        1.2561            -nan     0.1000    0.0088
     4        1.2303            -nan     0.1000    0.0083
     5        1.2127            -nan     0.1000    0.0084
     6        1.1843            -nan     0.1000    0.0129
     7        1.1703            -nan     0.1000    0.0067
     8        1.1455            -nan     0.1000    0.0032
     9        1.1291            -nan     0.1000    0.0070
    10        1.1167            -nan     0.1000    0.0050
    20        1.0042            -nan     0.1000   -0.0006
    40        0.8718            -nan     0.1000    0.0023
    60        0.7719            -nan     0.1000   -0.0010
    80        0.7068            -nan     0.1000   -0.0015
   100        0.6475            -nan     0.1000   -0.0000
   120        0.5981            -nan     0.1000   -0.0010
   140        0.5577            -nan     0.1000   -0.0030
   150        0.5361            -nan     0.1000   -0.0013

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2897            -nan     0.1000    0.0244
     2        1.2405            -nan     0.1000    0.0192
     3        1.2087            -nan     0.1000    0.0078
     4        1.1812            -nan     0.1000    0.0083
     5        1.1450            -nan     0.1000    0.0153
     6        1.1246            -nan     0.1000   -0.0032
     7        1.1007            -nan     0.1000    0.0046
     8        1.0775            -nan     0.1000    0.0049
     9        1.0571            -nan     0.1000    0.0020
    10        1.0418            -nan     0.1000   -0.0012
    20        0.8639            -nan     0.1000    0.0021
    40        0.6516            -nan     0.1000    0.0006
    60        0.5114            -nan     0.1000   -0.0010
    80        0.4288            -nan     0.1000   -0.0013
   100        0.3594            -nan     0.1000   -0.0006
   120        0.3083            -nan     0.1000   -0.0011
   140        0.2614            -nan     0.1000   -0.0011
   150        0.2421            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2968            -nan     0.1000    0.0157
     2        1.2215            -nan     0.1000    0.0294
     3        1.1678            -nan     0.1000    0.0213
     4        1.1014            -nan     0.1000    0.0233
     5        1.0513            -nan     0.1000    0.0162
     6        1.0177            -nan     0.1000    0.0072
     7        0.9887            -nan     0.1000    0.0045
     8        0.9563            -nan     0.1000    0.0094
     9        0.9230            -nan     0.1000    0.0052
    10        0.8984            -nan     0.1000    0.0018
    20        0.7169            -nan     0.1000    0.0044
    40        0.4968            -nan     0.1000    0.0006
    60        0.3655            -nan     0.1000   -0.0023
    80        0.2716            -nan     0.1000   -0.0012
   100        0.2142            -nan     0.1000   -0.0004
   120        0.1679            -nan     0.1000   -0.0007
   140        0.1335            -nan     0.1000   -0.0014
   150        0.1173            -nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3558            -nan     0.1000    0.0146
     2        1.3332            -nan     0.1000    0.0056
     3        1.3027            -nan     0.1000    0.0100
     4        1.2909            -nan     0.1000    0.0006
     5        1.2633            -nan     0.1000    0.0097
     6        1.2481            -nan     0.1000    0.0056
     7        1.2326            -nan     0.1000    0.0055
     8        1.2254            -nan     0.1000   -0.0008
     9        1.2130            -nan     0.1000    0.0010
    10        1.1960            -nan     0.1000    0.0030
    20        1.0879            -nan     0.1000    0.0005
    40        0.9278            -nan     0.1000    0.0012
    60        0.8318            -nan     0.1000   -0.0001
    80        0.7560            -nan     0.1000    0.0001
   100        0.6887            -nan     0.1000   -0.0013
   120        0.6309            -nan     0.1000    0.0009
   140        0.5820            -nan     0.1000   -0.0007
   150        0.5595            -nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3287            -nan     0.1000    0.0226
     2        1.2863            -nan     0.1000    0.0169
     3        1.2497            -nan     0.1000    0.0080
     4        1.2139            -nan     0.1000    0.0116
     5        1.1777            -nan     0.1000    0.0140
     6        1.1530            -nan     0.1000    0.0008
     7        1.1179            -nan     0.1000    0.0096
     8        1.0896            -nan     0.1000    0.0084
     9        1.0674            -nan     0.1000    0.0071
    10        1.0471            -nan     0.1000    0.0026
    20        0.8725            -nan     0.1000   -0.0009
    40        0.6673            -nan     0.1000    0.0045
    60        0.5264            -nan     0.1000   -0.0010
    80        0.4272            -nan     0.1000   -0.0008
   100        0.3499            -nan     0.1000   -0.0014
   120        0.2868            -nan     0.1000    0.0004
   140        0.2416            -nan     0.1000   -0.0008
   150        0.2197            -nan     0.1000   -0.0018

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3253            -nan     0.1000    0.0230
     2        1.2675            -nan     0.1000    0.0241
     3        1.2080            -nan     0.1000    0.0239
     4        1.1551            -nan     0.1000    0.0147
     5        1.1170            -nan     0.1000    0.0097
     6        1.0868            -nan     0.1000    0.0053
     7        1.0505            -nan     0.1000    0.0165
     8        1.0066            -nan     0.1000    0.0134
     9        0.9790            -nan     0.1000    0.0061
    10        0.9546            -nan     0.1000    0.0000
    20        0.7304            -nan     0.1000    0.0043
    40        0.5002            -nan     0.1000   -0.0011
    60        0.3524            -nan     0.1000   -0.0000
    80        0.2615            -nan     0.1000   -0.0008
   100        0.2000            -nan     0.1000   -0.0008
   120        0.1567            -nan     0.1000   -0.0014
   140        0.1192            -nan     0.1000   -0.0003
   150        0.1054            -nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3365            -nan     0.1000    0.0241
     2        1.2925            -nan     0.1000    0.0148
     3        1.2516            -nan     0.1000    0.0118
     4        1.2167            -nan     0.1000    0.0129
     5        1.1901            -nan     0.1000    0.0116
     6        1.1659            -nan     0.1000    0.0065
     7        1.1398            -nan     0.1000    0.0090
     8        1.1201            -nan     0.1000    0.0059
     9        1.0968            -nan     0.1000    0.0095
    10        1.0797            -nan     0.1000    0.0027
    20        0.9673            -nan     0.1000    0.0005
    40        0.8161            -nan     0.1000    0.0016
    60        0.7218            -nan     0.1000   -0.0009
    80        0.6490            -nan     0.1000    0.0006
   100        0.5828            -nan     0.1000   -0.0014
   120        0.5335            -nan     0.1000   -0.0021
   140        0.4907            -nan     0.1000   -0.0012
   150        0.4690            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3354            -nan     0.1000    0.0200
     2        1.2666            -nan     0.1000    0.0307
     3        1.2280            -nan     0.1000    0.0127
     4        1.1870            -nan     0.1000    0.0127
     5        1.1406            -nan     0.1000    0.0181
     6        1.0959            -nan     0.1000    0.0181
     7        1.0570            -nan     0.1000    0.0135
     8        1.0319            -nan     0.1000    0.0098
     9        1.0065            -nan     0.1000    0.0064
    10        0.9797            -nan     0.1000    0.0064
    20        0.8131            -nan     0.1000   -0.0009
    40        0.5830            -nan     0.1000   -0.0001
    60        0.4473            -nan     0.1000    0.0003
    80        0.3593            -nan     0.1000    0.0003
   100        0.2998            -nan     0.1000   -0.0006
   120        0.2497            -nan     0.1000   -0.0023
   140        0.2080            -nan     0.1000   -0.0009
   150        0.1922            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3123            -nan     0.1000    0.0259
     2        1.2412            -nan     0.1000    0.0294
     3        1.1799            -nan     0.1000    0.0242
     4        1.1262            -nan     0.1000    0.0207
     5        1.0681            -nan     0.1000    0.0195
     6        1.0290            -nan     0.1000    0.0121
     7        0.9894            -nan     0.1000    0.0141
     8        0.9508            -nan     0.1000    0.0149
     9        0.9129            -nan     0.1000    0.0127
    10        0.8764            -nan     0.1000    0.0097
    20        0.6831            -nan     0.1000    0.0048
    40        0.4323            -nan     0.1000    0.0004
    60        0.2984            -nan     0.1000    0.0004
    80        0.2185            -nan     0.1000   -0.0003
   100        0.1653            -nan     0.1000   -0.0000
   120        0.1254            -nan     0.1000   -0.0006
   140        0.0966            -nan     0.1000   -0.0009
   150        0.0840            -nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3448            -nan     0.1000    0.0118
     2        1.3208            -nan     0.1000    0.0107
     3        1.2842            -nan     0.1000    0.0180
     4        1.2534            -nan     0.1000    0.0104
     5        1.2212            -nan     0.1000    0.0093
     6        1.2043            -nan     0.1000    0.0025
     7        1.1852            -nan     0.1000    0.0043
     8        1.1692            -nan     0.1000    0.0012
     9        1.1562            -nan     0.1000    0.0009
    10        1.1433            -nan     0.1000    0.0006
    20        1.0254            -nan     0.1000    0.0018
    40        0.8850            -nan     0.1000   -0.0014
    60        0.7976            -nan     0.1000    0.0007
    80        0.7270            -nan     0.1000   -0.0009
   100        0.6643            -nan     0.1000   -0.0006
   120        0.6111            -nan     0.1000   -0.0007
   140        0.5668            -nan     0.1000   -0.0017
   150        0.5458            -nan     0.1000   -0.0025

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3313            -nan     0.1000    0.0205
     2        1.2796            -nan     0.1000    0.0190
     3        1.2307            -nan     0.1000    0.0187
     4        1.1862            -nan     0.1000    0.0161
     5        1.1592            -nan     0.1000    0.0079
     6        1.1227            -nan     0.1000    0.0072
     7        1.0884            -nan     0.1000    0.0091
     8        1.0650            -nan     0.1000    0.0081
     9        1.0422            -nan     0.1000    0.0070
    10        1.0183            -nan     0.1000    0.0107
    20        0.8479            -nan     0.1000    0.0046
    40        0.6555            -nan     0.1000   -0.0001
    60        0.5384            -nan     0.1000    0.0010
    80        0.4423            -nan     0.1000   -0.0020
   100        0.3599            -nan     0.1000   -0.0006
   120        0.3039            -nan     0.1000   -0.0006
   140        0.2569            -nan     0.1000   -0.0009
   150        0.2387            -nan     0.1000   -0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3228            -nan     0.1000    0.0245
     2        1.2482            -nan     0.1000    0.0318
     3        1.1959            -nan     0.1000    0.0228
     4        1.1524            -nan     0.1000    0.0119
     5        1.1066            -nan     0.1000    0.0201
     6        1.0742            -nan     0.1000    0.0024
     7        1.0368            -nan     0.1000    0.0089
     8        1.0038            -nan     0.1000    0.0022
     9        0.9700            -nan     0.1000    0.0046
    10        0.9419            -nan     0.1000    0.0079
    20        0.7402            -nan     0.1000    0.0030
    40        0.5175            -nan     0.1000    0.0020
    60        0.3926            -nan     0.1000   -0.0002
    80        0.2967            -nan     0.1000   -0.0001
   100        0.2245            -nan     0.1000   -0.0015
   120        0.1765            -nan     0.1000   -0.0007
   140        0.1397            -nan     0.1000   -0.0009
   150        0.1239            -nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3417            -nan     0.1000    0.0151
     2        1.3088            -nan     0.1000    0.0079
     3        1.2816            -nan     0.1000    0.0065
     4        1.2549            -nan     0.1000    0.0110
     5        1.2269            -nan     0.1000    0.0124
     6        1.2033            -nan     0.1000    0.0099
     7        1.1809            -nan     0.1000    0.0094
     8        1.1584            -nan     0.1000    0.0080
     9        1.1357            -nan     0.1000    0.0053
    10        1.1206            -nan     0.1000    0.0023
    20        1.0066            -nan     0.1000   -0.0039
    40        0.8758            -nan     0.1000   -0.0002
    60        0.7909            -nan     0.1000   -0.0019
    80        0.7161            -nan     0.1000    0.0001
   100        0.6539            -nan     0.1000    0.0007
   120        0.6058            -nan     0.1000   -0.0005
   140        0.5663            -nan     0.1000   -0.0012
   150        0.5472            -nan     0.1000   -0.0022

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3270            -nan     0.1000    0.0210
     2        1.2712            -nan     0.1000    0.0166
     3        1.2267            -nan     0.1000    0.0186
     4        1.1893            -nan     0.1000    0.0138
     5        1.1522            -nan     0.1000    0.0126
     6        1.1218            -nan     0.1000    0.0029
     7        1.0920            -nan     0.1000    0.0074
     8        1.0697            -nan     0.1000    0.0007
     9        1.0466            -nan     0.1000    0.0073
    10        1.0244            -nan     0.1000    0.0064
    20        0.8613            -nan     0.1000    0.0023
    40        0.6702            -nan     0.1000    0.0018
    60        0.5300            -nan     0.1000   -0.0000
    80        0.4354            -nan     0.1000   -0.0010
   100        0.3691            -nan     0.1000   -0.0002
   120        0.3101            -nan     0.1000   -0.0013
   140        0.2644            -nan     0.1000   -0.0009
   150        0.2455            -nan     0.1000   -0.0016

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3243            -nan     0.1000    0.0114
     2        1.2637            -nan     0.1000    0.0245
     3        1.2131            -nan     0.1000    0.0146
     4        1.1689            -nan     0.1000    0.0121
     5        1.1212            -nan     0.1000    0.0196
     6        1.0792            -nan     0.1000    0.0167
     7        1.0626            -nan     0.1000   -0.0057
     8        1.0321            -nan     0.1000    0.0025
     9        1.0031            -nan     0.1000    0.0017
    10        0.9744            -nan     0.1000    0.0041
    20        0.7470            -nan     0.1000   -0.0029
    40        0.5300            -nan     0.1000   -0.0031
    60        0.3881            -nan     0.1000    0.0013
    80        0.2956            -nan     0.1000   -0.0008
   100        0.2286            -nan     0.1000   -0.0002
   120        0.1787            -nan     0.1000   -0.0006
   140        0.1423            -nan     0.1000   -0.0013
   150        0.1280            -nan     0.1000   -0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3347            -nan     0.1000    0.0251
     2        1.3078            -nan     0.1000    0.0073
     3        1.2653            -nan     0.1000    0.0209
     4        1.2326            -nan     0.1000    0.0134
     5        1.2088            -nan     0.1000    0.0089
     6        1.1907            -nan     0.1000    0.0048
     7        1.1608            -nan     0.1000    0.0120
     8        1.1467            -nan     0.1000   -0.0030
     9        1.1221            -nan     0.1000    0.0090
    10        1.1029            -nan     0.1000    0.0068
    20        0.9808            -nan     0.1000    0.0026
    40        0.8345            -nan     0.1000   -0.0007
    60        0.7358            -nan     0.1000    0.0005
    80        0.6642            -nan     0.1000   -0.0012
   100        0.5930            -nan     0.1000    0.0012
   120        0.5389            -nan     0.1000   -0.0023
   140        0.4924            -nan     0.1000   -0.0006
   150        0.4744            -nan     0.1000   -0.0017

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3157            -nan     0.1000    0.0286
     2        1.2540            -nan     0.1000    0.0268
     3        1.2126            -nan     0.1000    0.0153
     4        1.1754            -nan     0.1000    0.0064
     5        1.1414            -nan     0.1000    0.0138
     6        1.1048            -nan     0.1000    0.0087
     7        1.0764            -nan     0.1000    0.0092
     8        1.0545            -nan     0.1000    0.0010
     9        1.0354            -nan     0.1000    0.0019
    10        1.0027            -nan     0.1000    0.0135
    20        0.8149            -nan     0.1000    0.0042
    40        0.5981            -nan     0.1000   -0.0040
    60        0.4721            -nan     0.1000   -0.0007
    80        0.3868            -nan     0.1000   -0.0003
   100        0.3205            -nan     0.1000   -0.0032
   120        0.2633            -nan     0.1000   -0.0009
   140        0.2172            -nan     0.1000   -0.0001
   150        0.1963            -nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3062            -nan     0.1000    0.0353
     2        1.2322            -nan     0.1000    0.0307
     3        1.1732            -nan     0.1000    0.0223
     4        1.1291            -nan     0.1000    0.0112
     5        1.0708            -nan     0.1000    0.0239
     6        1.0199            -nan     0.1000    0.0197
     7        0.9723            -nan     0.1000    0.0115
     8        0.9287            -nan     0.1000    0.0169
     9        0.8966            -nan     0.1000    0.0115
    10        0.8729            -nan     0.1000    0.0022
    20        0.6723            -nan     0.1000    0.0052
    40        0.4423            -nan     0.1000   -0.0021
    60        0.3067            -nan     0.1000   -0.0013
    80        0.2254            -nan     0.1000    0.0009
   100        0.1701            -nan     0.1000   -0.0010
   120        0.1314            -nan     0.1000   -0.0004
   140        0.0986            -nan     0.1000    0.0003
   150        0.0858            -nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3339            -nan     0.1000    0.0183
     2        1.2859            -nan     0.1000    0.0200
     3        1.2449            -nan     0.1000    0.0124
     4        1.2164            -nan     0.1000    0.0148
     5        1.1914            -nan     0.1000    0.0108
     6        1.1701            -nan     0.1000    0.0073
     7        1.1492            -nan     0.1000    0.0044
     8        1.1295            -nan     0.1000    0.0077
     9        1.1132            -nan     0.1000    0.0073
    10        1.0970            -nan     0.1000    0.0036
    20        0.9888            -nan     0.1000    0.0013
    40        0.8765            -nan     0.1000    0.0007
    60        0.7827            -nan     0.1000    0.0008
    80        0.7098            -nan     0.1000   -0.0019
   100        0.6563            -nan     0.1000   -0.0004
   120        0.6067            -nan     0.1000   -0.0035
   140        0.5633            -nan     0.1000   -0.0013
   150        0.5414            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3248            -nan     0.1000    0.0333
     2        1.2661            -nan     0.1000    0.0241
     3        1.2002            -nan     0.1000    0.0197
     4        1.1645            -nan     0.1000    0.0115
     5        1.1293            -nan     0.1000    0.0130
     6        1.0908            -nan     0.1000    0.0162
     7        1.0683            -nan     0.1000    0.0045
     8        1.0495            -nan     0.1000    0.0005
     9        1.0252            -nan     0.1000    0.0096
    10        1.0045            -nan     0.1000    0.0066
    20        0.8266            -nan     0.1000   -0.0012
    40        0.6429            -nan     0.1000    0.0020
    60        0.5186            -nan     0.1000   -0.0009
    80        0.4236            -nan     0.1000   -0.0024
   100        0.3520            -nan     0.1000   -0.0021
   120        0.2995            -nan     0.1000   -0.0012
   140        0.2562            -nan     0.1000   -0.0000
   150        0.2346            -nan     0.1000   -0.0006

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3034            -nan     0.1000    0.0333
     2        1.2281            -nan     0.1000    0.0331
     3        1.1831            -nan     0.1000    0.0130
     4        1.1272            -nan     0.1000    0.0243
     5        1.0901            -nan     0.1000    0.0093
     6        1.0454            -nan     0.1000    0.0184
     7        1.0056            -nan     0.1000    0.0109
     8        0.9742            -nan     0.1000    0.0004
     9        0.9477            -nan     0.1000    0.0049
    10        0.9254            -nan     0.1000    0.0002
    20        0.7072            -nan     0.1000    0.0027
    40        0.4932            -nan     0.1000   -0.0004
    60        0.3612            -nan     0.1000   -0.0017
    80        0.2694            -nan     0.1000   -0.0021
   100        0.2137            -nan     0.1000   -0.0019
   120        0.1637            -nan     0.1000   -0.0005
   140        0.1292            -nan     0.1000   -0.0012
   150        0.1124            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3172            -nan     0.1000    0.0111
     2        1.2848            -nan     0.1000    0.0127
     3        1.2593            -nan     0.1000    0.0102
     4        1.2344            -nan     0.1000    0.0074
     5        1.2112            -nan     0.1000    0.0049
     6        1.1928            -nan     0.1000    0.0016
     7        1.1721            -nan     0.1000    0.0070
     8        1.1562            -nan     0.1000    0.0049
     9        1.1391            -nan     0.1000    0.0025
    10        1.1260            -nan     0.1000    0.0046
    20        1.0246            -nan     0.1000    0.0004
    40        0.8831            -nan     0.1000   -0.0006
    60        0.7724            -nan     0.1000   -0.0002
    80        0.6924            -nan     0.1000   -0.0019
   100        0.6309            -nan     0.1000    0.0002
   120        0.5801            -nan     0.1000   -0.0013
   140        0.5281            -nan     0.1000   -0.0003
   150        0.5071            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3031            -nan     0.1000    0.0253
     2        1.2574            -nan     0.1000    0.0126
     3        1.2207            -nan     0.1000    0.0129
     4        1.1767            -nan     0.1000    0.0173
     5        1.1500            -nan     0.1000    0.0092
     6        1.1249            -nan     0.1000    0.0047
     7        1.1014            -nan     0.1000    0.0083
     8        1.0704            -nan     0.1000    0.0089
     9        1.0478            -nan     0.1000    0.0082
    10        1.0225            -nan     0.1000    0.0063
    20        0.8497            -nan     0.1000    0.0004
    40        0.6321            -nan     0.1000    0.0015
    60        0.4976            -nan     0.1000    0.0021
    80        0.4097            -nan     0.1000    0.0007
   100        0.3446            -nan     0.1000   -0.0018
   120        0.2920            -nan     0.1000    0.0003
   140        0.2515            -nan     0.1000   -0.0022
   150        0.2317            -nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2823            -nan     0.1000    0.0295
     2        1.2195            -nan     0.1000    0.0188
     3        1.1703            -nan     0.1000    0.0150
     4        1.1215            -nan     0.1000    0.0112
     5        1.0855            -nan     0.1000    0.0102
     6        1.0366            -nan     0.1000    0.0124
     7        0.9919            -nan     0.1000    0.0114
     8        0.9679            -nan     0.1000    0.0044
     9        0.9425            -nan     0.1000    0.0076
    10        0.9150            -nan     0.1000    0.0079
    20        0.7012            -nan     0.1000    0.0007
    40        0.4900            -nan     0.1000   -0.0019
    60        0.3512            -nan     0.1000   -0.0016
    80        0.2671            -nan     0.1000   -0.0002
   100        0.2083            -nan     0.1000   -0.0019
   120        0.1621            -nan     0.1000   -0.0007
   140        0.1267            -nan     0.1000   -0.0006
   150        0.1120            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3424            -nan     0.1000    0.0171
     2        1.3023            -nan     0.1000    0.0218
     3        1.2592            -nan     0.1000    0.0185
     4        1.2289            -nan     0.1000    0.0121
     5        1.1998            -nan     0.1000    0.0104
     6        1.1733            -nan     0.1000    0.0078
     7        1.1528            -nan     0.1000    0.0070
     8        1.1339            -nan     0.1000    0.0041
     9        1.1106            -nan     0.1000    0.0104
    10        1.0948            -nan     0.1000    0.0067
    20        0.9868            -nan     0.1000   -0.0028
    40        0.8288            -nan     0.1000   -0.0011
    60        0.7272            -nan     0.1000    0.0013
    80        0.6434            -nan     0.1000   -0.0004
   100        0.5757            -nan     0.1000    0.0017
   120        0.5144            -nan     0.1000    0.0009
   140        0.4647            -nan     0.1000   -0.0005
   150        0.4442            -nan     0.1000    0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3261            -nan     0.1000    0.0244
     2        1.2864            -nan     0.1000    0.0066
     3        1.2268            -nan     0.1000    0.0216
     4        1.1818            -nan     0.1000    0.0182
     5        1.1384            -nan     0.1000    0.0083
     6        1.0992            -nan     0.1000    0.0144
     7        1.0777            -nan     0.1000    0.0008
     8        1.0523            -nan     0.1000    0.0068
     9        1.0281            -nan     0.1000    0.0047
    10        0.9969            -nan     0.1000    0.0134
    20        0.7978            -nan     0.1000    0.0032
    40        0.5897            -nan     0.1000    0.0008
    60        0.4500            -nan     0.1000    0.0022
    80        0.3516            -nan     0.1000    0.0000
   100        0.2832            -nan     0.1000   -0.0006
   120        0.2327            -nan     0.1000   -0.0004
   140        0.1918            -nan     0.1000   -0.0010
   150        0.1770            -nan     0.1000   -0.0012

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3215            -nan     0.1000    0.0227
     2        1.2553            -nan     0.1000    0.0227
     3        1.1891            -nan     0.1000    0.0236
     4        1.1404            -nan     0.1000    0.0168
     5        1.0955            -nan     0.1000    0.0126
     6        1.0533            -nan     0.1000    0.0144
     7        1.0130            -nan     0.1000    0.0154
     8        0.9787            -nan     0.1000    0.0127
     9        0.9453            -nan     0.1000    0.0096
    10        0.9090            -nan     0.1000    0.0099
    20        0.6779            -nan     0.1000    0.0013
    40        0.4278            -nan     0.1000   -0.0021
    60        0.2951            -nan     0.1000    0.0002
    80        0.2125            -nan     0.1000   -0.0018
   100        0.1530            -nan     0.1000   -0.0010
   120        0.1160            -nan     0.1000   -0.0005
   140        0.0871            -nan     0.1000   -0.0000
   150        0.0752            -nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3533            -nan     0.1000    0.0071
     2        1.3348            -nan     0.1000    0.0076
     3        1.3146            -nan     0.1000    0.0096
     4        1.3009            -nan     0.1000    0.0044
     5        1.2793            -nan     0.1000   -0.0015
     6        1.2638            -nan     0.1000    0.0054
     7        1.2555            -nan     0.1000    0.0011
     8        1.2412            -nan     0.1000    0.0047
     9        1.2337            -nan     0.1000    0.0017
    10        1.2229            -nan     0.1000    0.0049
    20        1.1357            -nan     0.1000    0.0014
    40        1.0187            -nan     0.1000   -0.0049
    60        0.9270            -nan     0.1000   -0.0028
    80        0.8530            -nan     0.1000   -0.0009
   100        0.7868            -nan     0.1000   -0.0021
   120        0.7243            -nan     0.1000   -0.0021
   140        0.6804            -nan     0.1000    0.0005
   150        0.6516            -nan     0.1000    0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3430            -nan     0.1000    0.0164
     2        1.3015            -nan     0.1000    0.0124
     3        1.2712            -nan     0.1000    0.0104
     4        1.2519            -nan     0.1000    0.0016
     5        1.2301            -nan     0.1000    0.0020
     6        1.2089            -nan     0.1000    0.0035
     7        1.1877            -nan     0.1000    0.0065
     8        1.1643            -nan     0.1000    0.0022
     9        1.1388            -nan     0.1000    0.0103
    10        1.1172            -nan     0.1000    0.0055
    20        0.9499            -nan     0.1000   -0.0028
    40        0.7452            -nan     0.1000   -0.0048
    60        0.6016            -nan     0.1000   -0.0026
    80        0.4959            -nan     0.1000    0.0024
   100        0.4141            -nan     0.1000    0.0003
   120        0.3501            -nan     0.1000   -0.0007
   140        0.3032            -nan     0.1000   -0.0003
   150        0.2790            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3277            -nan     0.1000    0.0171
     2        1.2966            -nan     0.1000    0.0041
     3        1.2392            -nan     0.1000    0.0160
     4        1.2102            -nan     0.1000    0.0059
     5        1.1797            -nan     0.1000    0.0093
     6        1.1493            -nan     0.1000    0.0067
     7        1.1164            -nan     0.1000    0.0058
     8        1.0862            -nan     0.1000    0.0089
     9        1.0630            -nan     0.1000    0.0013
    10        1.0352            -nan     0.1000    0.0071
    20        0.8511            -nan     0.1000    0.0032
    40        0.6056            -nan     0.1000    0.0024
    60        0.4481            -nan     0.1000   -0.0007
    80        0.3510            -nan     0.1000   -0.0017
   100        0.2716            -nan     0.1000   -0.0005
   120        0.2141            -nan     0.1000   -0.0009
   140        0.1668            -nan     0.1000   -0.0006
   150        0.1483            -nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3201            -nan     0.1000    0.0358
     2        1.2669            -nan     0.1000    0.0260
     3        1.2200            -nan     0.1000    0.0219
     4        1.1877            -nan     0.1000    0.0183
     5        1.1544            -nan     0.1000    0.0146
     6        1.1283            -nan     0.1000    0.0050
     7        1.1061            -nan     0.1000    0.0065
     8        1.0859            -nan     0.1000    0.0041
     9        1.0776            -nan     0.1000   -0.0022
    10        1.0646            -nan     0.1000    0.0047
    20        0.9483            -nan     0.1000    0.0028
    40        0.8068            -nan     0.1000    0.0022
    60        0.7154            -nan     0.1000   -0.0002
    80        0.6302            -nan     0.1000   -0.0013
   100        0.5776            -nan     0.1000   -0.0024
   120        0.5260            -nan     0.1000   -0.0019
   140        0.4809            -nan     0.1000   -0.0016
   150        0.4654            -nan     0.1000   -0.0019

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3115            -nan     0.1000    0.0323
     2        1.2499            -nan     0.1000    0.0300
     3        1.1934            -nan     0.1000    0.0289
     4        1.1458            -nan     0.1000    0.0225
     5        1.1027            -nan     0.1000    0.0181
     6        1.0644            -nan     0.1000    0.0129
     7        1.0320            -nan     0.1000    0.0075
     8        1.0068            -nan     0.1000    0.0056
     9        0.9875            -nan     0.1000    0.0056
    10        0.9704            -nan     0.1000   -0.0004
    20        0.7807            -nan     0.1000    0.0056
    40        0.5858            -nan     0.1000    0.0017
    60        0.4575            -nan     0.1000   -0.0003
    80        0.3710            -nan     0.1000   -0.0005
   100        0.3018            -nan     0.1000   -0.0001
   120        0.2524            -nan     0.1000   -0.0014
   140        0.2162            -nan     0.1000   -0.0003
   150        0.1974            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2890            -nan     0.1000    0.0432
     2        1.2055            -nan     0.1000    0.0336
     3        1.1560            -nan     0.1000    0.0162
     4        1.0996            -nan     0.1000    0.0209
     5        1.0515            -nan     0.1000    0.0135
     6        1.0035            -nan     0.1000    0.0165
     7        0.9606            -nan     0.1000    0.0182
     8        0.9205            -nan     0.1000    0.0117
     9        0.8884            -nan     0.1000    0.0077
    10        0.8542            -nan     0.1000    0.0120
    20        0.6491            -nan     0.1000    0.0029
    40        0.4370            -nan     0.1000   -0.0029
    60        0.3147            -nan     0.1000    0.0013
    80        0.2339            -nan     0.1000   -0.0014
   100        0.1733            -nan     0.1000   -0.0008
   120        0.1352            -nan     0.1000   -0.0011
   140        0.1015            -nan     0.1000   -0.0004
   150        0.0896            -nan     0.1000   -0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3507            -nan     0.1000    0.0170
     2        1.3108            -nan     0.1000    0.0103
     3        1.2780            -nan     0.1000    0.0089
     4        1.2594            -nan     0.1000    0.0057
     5        1.2331            -nan     0.1000    0.0058
     6        1.2051            -nan     0.1000    0.0064
     7        1.1928            -nan     0.1000    0.0015
     8        1.1706            -nan     0.1000    0.0053
     9        1.1513            -nan     0.1000    0.0044
    10        1.1362            -nan     0.1000    0.0067
    20        1.0405            -nan     0.1000   -0.0011
    40        0.8971            -nan     0.1000   -0.0029
    60        0.8049            -nan     0.1000   -0.0010
    80        0.7263            -nan     0.1000   -0.0005
   100        0.6681            -nan     0.1000    0.0008
   120        0.6139            -nan     0.1000   -0.0017
   140        0.5659            -nan     0.1000   -0.0001
   150        0.5474            -nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3347            -nan     0.1000    0.0157
     2        1.2876            -nan     0.1000    0.0171
     3        1.2475            -nan     0.1000    0.0133
     4        1.2033            -nan     0.1000    0.0164
     5        1.1716            -nan     0.1000    0.0134
     6        1.1366            -nan     0.1000    0.0127
     7        1.1092            -nan     0.1000    0.0084
     8        1.0829            -nan     0.1000    0.0101
     9        1.0646            -nan     0.1000    0.0048
    10        1.0405            -nan     0.1000    0.0067
    20        0.8643            -nan     0.1000    0.0001
    40        0.6604            -nan     0.1000    0.0011
    60        0.5392            -nan     0.1000   -0.0017
    80        0.4456            -nan     0.1000   -0.0001
   100        0.3791            -nan     0.1000   -0.0006
   120        0.3217            -nan     0.1000    0.0001
   140        0.2714            -nan     0.1000    0.0003
   150        0.2522            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3204            -nan     0.1000    0.0211
     2        1.2461            -nan     0.1000    0.0291
     3        1.1946            -nan     0.1000    0.0205
     4        1.1522            -nan     0.1000    0.0154
     5        1.1052            -nan     0.1000    0.0224
     6        1.0741            -nan     0.1000    0.0124
     7        1.0337            -nan     0.1000    0.0113
     8        1.0032            -nan     0.1000    0.0100
     9        0.9753            -nan     0.1000    0.0050
    10        0.9495            -nan     0.1000    0.0041
    20        0.7479            -nan     0.1000    0.0045
    40        0.5139            -nan     0.1000   -0.0005
    60        0.3870            -nan     0.1000    0.0015
    80        0.2969            -nan     0.1000   -0.0008
   100        0.2251            -nan     0.1000   -0.0022
   120        0.1757            -nan     0.1000    0.0001
   140        0.1367            -nan     0.1000   -0.0007
   150        0.1231            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3317            -nan     0.1000    0.0140
     2        1.3078            -nan     0.1000    0.0019
     3        1.2796            -nan     0.1000    0.0117
     4        1.2550            -nan     0.1000    0.0087
     5        1.2384            -nan     0.1000    0.0028
     6        1.2221            -nan     0.1000    0.0076
     7        1.2085            -nan     0.1000    0.0027
     8        1.1893            -nan     0.1000    0.0072
     9        1.1735            -nan     0.1000    0.0025
    10        1.1597            -nan     0.1000    0.0037
    20        1.0762            -nan     0.1000   -0.0026
    40        0.9324            -nan     0.1000    0.0002
    60        0.8348            -nan     0.1000   -0.0004
    80        0.7498            -nan     0.1000   -0.0003
   100        0.6816            -nan     0.1000   -0.0046
   120        0.6302            -nan     0.1000   -0.0007
   140        0.5851            -nan     0.1000    0.0001
   150        0.5627            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3266            -nan     0.1000    0.0115
     2        1.2892            -nan     0.1000    0.0164
     3        1.2467            -nan     0.1000    0.0173
     4        1.2148            -nan     0.1000    0.0138
     5        1.1832            -nan     0.1000    0.0071
     6        1.1547            -nan     0.1000    0.0081
     7        1.1291            -nan     0.1000    0.0008
     8        1.1038            -nan     0.1000    0.0059
     9        1.0841            -nan     0.1000    0.0039
    10        1.0633            -nan     0.1000    0.0042
    20        0.8887            -nan     0.1000    0.0013
    40        0.6857            -nan     0.1000    0.0013
    60        0.5542            -nan     0.1000    0.0009
    80        0.4460            -nan     0.1000   -0.0007
   100        0.3652            -nan     0.1000   -0.0006
   120        0.3094            -nan     0.1000   -0.0008
   140        0.2604            -nan     0.1000   -0.0020
   150        0.2435            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3057            -nan     0.1000    0.0267
     2        1.2602            -nan     0.1000    0.0131
     3        1.2053            -nan     0.1000    0.0190
     4        1.1670            -nan     0.1000    0.0107
     5        1.1261            -nan     0.1000    0.0089
     6        1.0944            -nan     0.1000    0.0105
     7        1.0662            -nan     0.1000    0.0009
     8        1.0302            -nan     0.1000    0.0095
     9        1.0049            -nan     0.1000    0.0053
    10        0.9765            -nan     0.1000    0.0076
    20        0.7654            -nan     0.1000    0.0030
    40        0.5160            -nan     0.1000    0.0000
    60        0.3687            -nan     0.1000    0.0008
    80        0.2778            -nan     0.1000   -0.0011
   100        0.2110            -nan     0.1000   -0.0006
   120        0.1607            -nan     0.1000   -0.0012
   140        0.1237            -nan     0.1000   -0.0007
   150        0.1109            -nan     0.1000   -0.0006

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3363            -nan     0.1000    0.0150
     2        1.3003            -nan     0.1000    0.0160
     3        1.2667            -nan     0.1000    0.0131
     4        1.2403            -nan     0.1000    0.0058
     5        1.2270            -nan     0.1000    0.0018
     6        1.1994            -nan     0.1000    0.0112
     7        1.1829            -nan     0.1000    0.0058
     8        1.1651            -nan     0.1000    0.0006
     9        1.1442            -nan     0.1000    0.0086
    10        1.1255            -nan     0.1000    0.0083
    20        0.9957            -nan     0.1000    0.0012
    40        0.8339            -nan     0.1000    0.0005
    60        0.7434            -nan     0.1000   -0.0040
    80        0.6748            -nan     0.1000   -0.0018
   100        0.6077            -nan     0.1000   -0.0011
   120        0.5493            -nan     0.1000   -0.0001
   140        0.5036            -nan     0.1000   -0.0008
   150        0.4817            -nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3245            -nan     0.1000    0.0223
     2        1.2652            -nan     0.1000    0.0214
     3        1.2273            -nan     0.1000    0.0108
     4        1.1922            -nan     0.1000    0.0080
     5        1.1574            -nan     0.1000    0.0150
     6        1.1085            -nan     0.1000    0.0187
     7        1.0785            -nan     0.1000    0.0095
     8        1.0428            -nan     0.1000    0.0134
     9        1.0143            -nan     0.1000    0.0052
    10        0.9916            -nan     0.1000    0.0016
    20        0.8095            -nan     0.1000    0.0006
    40        0.5913            -nan     0.1000    0.0001
    60        0.4697            -nan     0.1000    0.0003
    80        0.3824            -nan     0.1000   -0.0003
   100        0.3113            -nan     0.1000    0.0009
   120        0.2551            -nan     0.1000   -0.0013
   140        0.2122            -nan     0.1000   -0.0004
   150        0.1904            -nan     0.1000    0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3168            -nan     0.1000    0.0237
     2        1.2644            -nan     0.1000    0.0175
     3        1.2177            -nan     0.1000    0.0127
     4        1.1603            -nan     0.1000    0.0260
     5        1.1234            -nan     0.1000    0.0105
     6        1.0693            -nan     0.1000    0.0204
     7        1.0389            -nan     0.1000    0.0083
     8        1.0083            -nan     0.1000    0.0032
     9        0.9761            -nan     0.1000    0.0080
    10        0.9430            -nan     0.1000    0.0136
    20        0.7208            -nan     0.1000    0.0058
    40        0.4867            -nan     0.1000    0.0005
    60        0.3440            -nan     0.1000    0.0002
    80        0.2429            -nan     0.1000    0.0009
   100        0.1796            -nan     0.1000   -0.0005
   120        0.1325            -nan     0.1000   -0.0009
   140        0.1003            -nan     0.1000   -0.0001
   150        0.0884            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3554            -nan     0.1000    0.0086
     2        1.3282            -nan     0.1000    0.0095
     3        1.2955            -nan     0.1000    0.0092
     4        1.2753            -nan     0.1000    0.0058
     5        1.2589            -nan     0.1000    0.0036
     6        1.2441            -nan     0.1000    0.0034
     7        1.2277            -nan     0.1000    0.0053
     8        1.2172            -nan     0.1000    0.0001
     9        1.1957            -nan     0.1000    0.0013
    10        1.1863            -nan     0.1000   -0.0002
    20        1.0770            -nan     0.1000    0.0043
    40        0.9529            -nan     0.1000   -0.0033
    60        0.8591            -nan     0.1000   -0.0002
    80        0.7892            -nan     0.1000    0.0004
   100        0.7324            -nan     0.1000   -0.0015
   120        0.6683            -nan     0.1000    0.0005
   140        0.6181            -nan     0.1000   -0.0036
   150        0.5905            -nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3425            -nan     0.1000    0.0146
     2        1.2994            -nan     0.1000    0.0158
     3        1.2606            -nan     0.1000    0.0053
     4        1.2280            -nan     0.1000    0.0060
     5        1.1972            -nan     0.1000    0.0040
     6        1.1718            -nan     0.1000    0.0065
     7        1.1511            -nan     0.1000    0.0055
     8        1.1289            -nan     0.1000    0.0023
     9        1.0974            -nan     0.1000    0.0094
    10        1.0790            -nan     0.1000    0.0008
    20        0.9122            -nan     0.1000    0.0028
    40        0.6778            -nan     0.1000   -0.0004
    60        0.5525            -nan     0.1000    0.0009
    80        0.4565            -nan     0.1000   -0.0021
   100        0.3773            -nan     0.1000    0.0002
   120        0.3155            -nan     0.1000   -0.0015
   140        0.2658            -nan     0.1000   -0.0007
   150        0.2422            -nan     0.1000    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3328            -nan     0.1000    0.0168
     2        1.2833            -nan     0.1000    0.0168
     3        1.2448            -nan     0.1000    0.0078
     4        1.2042            -nan     0.1000    0.0096
     5        1.1625            -nan     0.1000    0.0176
     6        1.1218            -nan     0.1000    0.0097
     7        1.0856            -nan     0.1000    0.0071
     8        1.0589            -nan     0.1000    0.0007
     9        1.0228            -nan     0.1000    0.0105
    10        0.9882            -nan     0.1000    0.0071
    20        0.7710            -nan     0.1000    0.0043
    40        0.5188            -nan     0.1000   -0.0005
    60        0.3795            -nan     0.1000   -0.0044
    80        0.2911            -nan     0.1000   -0.0008
   100        0.2286            -nan     0.1000   -0.0009
   120        0.1764            -nan     0.1000   -0.0009
   140        0.1400            -nan     0.1000   -0.0006
   150        0.1250            -nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3440            -nan     0.1000    0.0126
     2        1.3158            -nan     0.1000    0.0052
     3        1.2827            -nan     0.1000    0.0069
     4        1.2575            -nan     0.1000    0.0092
     5        1.2336            -nan     0.1000    0.0062
     6        1.2139            -nan     0.1000    0.0033
     7        1.2001            -nan     0.1000    0.0027
     8        1.1810            -nan     0.1000    0.0083
     9        1.1685            -nan     0.1000    0.0037
    10        1.1530            -nan     0.1000    0.0060
    20        1.0600            -nan     0.1000    0.0002
    40        0.9508            -nan     0.1000    0.0010
    60        0.8578            -nan     0.1000    0.0006
    80        0.7728            -nan     0.1000    0.0005
   100        0.7100            -nan     0.1000   -0.0010
   120        0.6612            -nan     0.1000    0.0003
   140        0.6201            -nan     0.1000   -0.0014
   150        0.5965            -nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3306            -nan     0.1000    0.0252
     2        1.2874            -nan     0.1000    0.0161
     3        1.2459            -nan     0.1000    0.0140
     4        1.2067            -nan     0.1000    0.0144
     5        1.1681            -nan     0.1000    0.0158
     6        1.1415            -nan     0.1000    0.0089
     7        1.1175            -nan     0.1000    0.0084
     8        1.0967            -nan     0.1000    0.0041
     9        1.0704            -nan     0.1000    0.0088
    10        1.0522            -nan     0.1000    0.0056
    20        0.8966            -nan     0.1000    0.0006
    40        0.7049            -nan     0.1000    0.0027
    60        0.5763            -nan     0.1000   -0.0007
    80        0.4758            -nan     0.1000   -0.0010
   100        0.3966            -nan     0.1000   -0.0028
   120        0.3301            -nan     0.1000   -0.0029
   140        0.2819            -nan     0.1000   -0.0013
   150        0.2546            -nan     0.1000    0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3131            -nan     0.1000    0.0268
     2        1.2585            -nan     0.1000    0.0210
     3        1.2136            -nan     0.1000    0.0160
     4        1.1725            -nan     0.1000    0.0118
     5        1.1403            -nan     0.1000    0.0070
     6        1.0912            -nan     0.1000    0.0212
     7        1.0594            -nan     0.1000    0.0076
     8        1.0254            -nan     0.1000    0.0061
     9        0.9931            -nan     0.1000    0.0085
    10        0.9607            -nan     0.1000    0.0098
    20        0.7642            -nan     0.1000    0.0002
    40        0.5347            -nan     0.1000    0.0008
    60        0.3942            -nan     0.1000    0.0005
    80        0.2981            -nan     0.1000    0.0010
   100        0.2320            -nan     0.1000   -0.0001
   120        0.1791            -nan     0.1000   -0.0012
   140        0.1392            -nan     0.1000   -0.0005
   150        0.1227            -nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3308            -nan     0.1000    0.0211
     2        1.2969            -nan     0.1000    0.0174
     3        1.2671            -nan     0.1000    0.0049
     4        1.2359            -nan     0.1000    0.0162
     5        1.2073            -nan     0.1000    0.0134
     6        1.1873            -nan     0.1000    0.0054
     7        1.1719            -nan     0.1000    0.0037
     8        1.1479            -nan     0.1000    0.0074
     9        1.1284            -nan     0.1000    0.0073
    10        1.1145            -nan     0.1000    0.0017
    20        0.9996            -nan     0.1000    0.0036
    40        0.8526            -nan     0.1000    0.0005
    60        0.7609            -nan     0.1000   -0.0006
    80        0.6827            -nan     0.1000   -0.0012
   100        0.6250            -nan     0.1000   -0.0008
   120        0.5770            -nan     0.1000   -0.0011
   140        0.5309            -nan     0.1000   -0.0014
   150        0.5065            -nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3210            -nan     0.1000    0.0211
     2        1.2616            -nan     0.1000    0.0226
     3        1.2154            -nan     0.1000    0.0148
     4        1.1712            -nan     0.1000    0.0113
     5        1.1385            -nan     0.1000    0.0141
     6        1.1191            -nan     0.1000    0.0026
     7        1.0883            -nan     0.1000    0.0069
     8        1.0611            -nan     0.1000    0.0103
     9        1.0377            -nan     0.1000    0.0069
    10        1.0243            -nan     0.1000   -0.0007
    20        0.8565            -nan     0.1000    0.0041
    40        0.6487            -nan     0.1000    0.0021
    60        0.5158            -nan     0.1000    0.0002
    80        0.4323            -nan     0.1000   -0.0031
   100        0.3541            -nan     0.1000   -0.0010
   120        0.2981            -nan     0.1000   -0.0006
   140        0.2447            -nan     0.1000   -0.0013
   150        0.2268            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2999            -nan     0.1000    0.0306
     2        1.2434            -nan     0.1000    0.0164
     3        1.1889            -nan     0.1000    0.0125
     4        1.1415            -nan     0.1000    0.0188
     5        1.0896            -nan     0.1000    0.0228
     6        1.0462            -nan     0.1000    0.0152
     7        1.0183            -nan     0.1000    0.0027
     8        0.9826            -nan     0.1000    0.0106
     9        0.9601            -nan     0.1000    0.0037
    10        0.9302            -nan     0.1000    0.0083
    20        0.7291            -nan     0.1000   -0.0006
    40        0.4899            -nan     0.1000   -0.0009
    60        0.3542            -nan     0.1000    0.0007
    80        0.2619            -nan     0.1000    0.0002
   100        0.2031            -nan     0.1000   -0.0006
   120        0.1611            -nan     0.1000   -0.0003
   140        0.1236            -nan     0.1000    0.0003
   150        0.1117            -nan     0.1000   -0.0006

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3479            -nan     0.1000    0.0119
     2        1.3109            -nan     0.1000    0.0165
     3        1.2781            -nan     0.1000    0.0182
     4        1.2543            -nan     0.1000    0.0096
     5        1.2310            -nan     0.1000    0.0087
     6        1.2097            -nan     0.1000    0.0074
     7        1.1903            -nan     0.1000    0.0076
     8        1.1697            -nan     0.1000    0.0077
     9        1.1528            -nan     0.1000    0.0074
    10        1.1419            -nan     0.1000    0.0030
    20        1.0317            -nan     0.1000   -0.0007
    40        0.8815            -nan     0.1000   -0.0039
    60        0.7732            -nan     0.1000    0.0010
    80        0.6895            -nan     0.1000   -0.0000
   100        0.6233            -nan     0.1000   -0.0004
   120        0.5655            -nan     0.1000   -0.0002
   140        0.5226            -nan     0.1000   -0.0015
   150        0.5048            -nan     0.1000   -0.0016

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3299            -nan     0.1000    0.0302
     2        1.2812            -nan     0.1000    0.0208
     3        1.2406            -nan     0.1000    0.0144
     4        1.2044            -nan     0.1000    0.0116
     5        1.1686            -nan     0.1000    0.0123
     6        1.1334            -nan     0.1000    0.0130
     7        1.1028            -nan     0.1000    0.0134
     8        1.0769            -nan     0.1000    0.0078
     9        1.0573            -nan     0.1000    0.0025
    10        1.0335            -nan     0.1000    0.0086
    20        0.8475            -nan     0.1000    0.0037
    40        0.6323            -nan     0.1000    0.0033
    60        0.4944            -nan     0.1000   -0.0003
    80        0.4028            -nan     0.1000   -0.0006
   100        0.3381            -nan     0.1000   -0.0015
   120        0.2686            -nan     0.1000    0.0010
   140        0.2257            -nan     0.1000    0.0002
   150        0.2074            -nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3178            -nan     0.1000    0.0244
     2        1.2624            -nan     0.1000    0.0233
     3        1.2025            -nan     0.1000    0.0281
     4        1.1549            -nan     0.1000    0.0182
     5        1.1198            -nan     0.1000    0.0146
     6        1.0844            -nan     0.1000    0.0117
     7        1.0523            -nan     0.1000   -0.0009
     8        1.0104            -nan     0.1000    0.0117
     9        0.9805            -nan     0.1000    0.0082
    10        0.9482            -nan     0.1000    0.0084
    20        0.7196            -nan     0.1000   -0.0015
    40        0.4744            -nan     0.1000    0.0030
    60        0.3322            -nan     0.1000    0.0006
    80        0.2473            -nan     0.1000   -0.0016
   100        0.1783            -nan     0.1000   -0.0005
   120        0.1362            -nan     0.1000   -0.0006
   140        0.1014            -nan     0.1000   -0.0002
   150        0.0890            -nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3339            -nan     0.1000    0.0182
     2        1.2858            -nan     0.1000    0.0128
     3        1.2549            -nan     0.1000    0.0117
     4        1.2244            -nan     0.1000    0.0082
     5        1.1927            -nan     0.1000    0.0124
     6        1.1714            -nan     0.1000    0.0077
     7        1.1471            -nan     0.1000    0.0073
     8        1.1267            -nan     0.1000    0.0054
     9        1.1098            -nan     0.1000    0.0076
    10        1.0936            -nan     0.1000    0.0074
    20        0.9711            -nan     0.1000    0.0022
    40        0.8432            -nan     0.1000    0.0018
    60        0.7490            -nan     0.1000   -0.0019
    80        0.6760            -nan     0.1000   -0.0031
   100        0.6196            -nan     0.1000   -0.0003
   120        0.5667            -nan     0.1000   -0.0001
   140        0.5180            -nan     0.1000   -0.0014
   150        0.4983            -nan     0.1000    0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3170            -nan     0.1000    0.0263
     2        1.2631            -nan     0.1000    0.0173
     3        1.2223            -nan     0.1000    0.0156
     4        1.1690            -nan     0.1000    0.0207
     5        1.1287            -nan     0.1000    0.0147
     6        1.0978            -nan     0.1000    0.0123
     7        1.0643            -nan     0.1000    0.0096
     8        1.0432            -nan     0.1000   -0.0032
     9        1.0167            -nan     0.1000    0.0062
    10        0.9916            -nan     0.1000    0.0073
    20        0.8160            -nan     0.1000   -0.0004
    40        0.6029            -nan     0.1000    0.0019
    60        0.4718            -nan     0.1000    0.0015
    80        0.3786            -nan     0.1000   -0.0003
   100        0.3101            -nan     0.1000   -0.0000
   120        0.2599            -nan     0.1000   -0.0018
   140        0.2158            -nan     0.1000   -0.0007
   150        0.1956            -nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2997            -nan     0.1000    0.0332
     2        1.2326            -nan     0.1000    0.0247
     3        1.1664            -nan     0.1000    0.0261
     4        1.1111            -nan     0.1000    0.0191
     5        1.0674            -nan     0.1000    0.0146
     6        1.0315            -nan     0.1000    0.0115
     7        0.9917            -nan     0.1000    0.0092
     8        0.9543            -nan     0.1000    0.0077
     9        0.9193            -nan     0.1000    0.0124
    10        0.8880            -nan     0.1000    0.0078
    20        0.6669            -nan     0.1000    0.0017
    40        0.4431            -nan     0.1000   -0.0004
    60        0.3095            -nan     0.1000   -0.0008
    80        0.2231            -nan     0.1000    0.0001
   100        0.1635            -nan     0.1000   -0.0009
   120        0.1201            -nan     0.1000   -0.0006
   140        0.0957            -nan     0.1000   -0.0004
   150        0.0842            -nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3387            -nan     0.1000    0.0161
     2        1.3018            -nan     0.1000    0.0129
     3        1.2746            -nan     0.1000    0.0113
     4        1.2536            -nan     0.1000   -0.0005
     5        1.2311            -nan     0.1000    0.0051
     6        1.2200            -nan     0.1000    0.0004
     7        1.2043            -nan     0.1000    0.0048
     8        1.1867            -nan     0.1000    0.0030
     9        1.1768            -nan     0.1000    0.0005
    10        1.1612            -nan     0.1000    0.0019
    20        1.0850            -nan     0.1000   -0.0037
    40        0.9757            -nan     0.1000    0.0004
    60        0.8864            -nan     0.1000   -0.0001
    80        0.8270            -nan     0.1000   -0.0018
   100        0.7746            -nan     0.1000   -0.0007
   120        0.7272            -nan     0.1000   -0.0014
   140        0.6871            -nan     0.1000   -0.0048
   150        0.6660            -nan     0.1000    0.0005

2.9 sec elapsed
[1] "Running gbm_h2o"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9    
<simpleError: Stopping>
61.843 sec elapsed
[1] "Running glmnet"
6.213 sec elapsed
[1] "Running glmnet_h2o"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9    
<simpleError: Stopping>
61.623 sec elapsed
[1] "Running glmboost"
1.274 sec elapsed
[1] "Running glmStepAIC"
Start:  AIC=157.61
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   111.61 155.62
- e_fg_percent   1   111.63 155.63
- orb            1   111.80 155.80
- drb            1   111.84 155.84
- tov            1   111.92 155.92
- x3p_percent    1   112.09 156.09
- fg             1   112.29 156.29
- pf             1   112.30 156.30
- trb            1   112.56 156.56
- fg_percent     1   113.35 157.35
- x2p_percent    1   113.43 157.43
<none>               111.61 157.61
- blk            1   113.79 157.79
- pts            1   119.65 163.65
- fga            1   120.46 164.46
- teamChemistry  1   120.69 164.69
- stl            1   120.98 164.98
- x2p            1   128.75 172.75
- x3p            1   131.53 175.53
- fta            1   138.19 182.19
- x2pa           1   140.74 184.74
- x3pa           1   148.83 192.83
- ft             1   152.19 196.19

Step:  AIC=155.61
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   111.64 153.64
- orb            1   111.82 153.82
- drb            1   111.86 153.86
- tov            1   111.93 153.93
- x3p_percent    1   112.13 154.13
- pf             1   112.32 154.32
- fg             1   112.42 154.41
- trb            1   112.59 154.59
- fg_percent     1   113.35 155.35
- x2p_percent    1   113.46 155.46
<none>               111.61 155.62
- blk            1   113.88 155.88
- pts            1   120.03 162.03
- fga            1   120.69 162.69
- teamChemistry  1   120.73 162.73
- stl            1   121.09 163.09
- x2p            1   128.81 170.81
- x3p            1   134.46 176.46
- fta            1   139.10 181.10
- x2pa           1   140.91 182.91
- x3pa           1   151.69 193.69
- ft             1   152.23 194.23

Step:  AIC=153.64
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + drb + trb + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- orb            1   111.84 151.84
- drb            1   111.89 151.90
- tov            1   111.95 151.95
- x3p_percent    1   112.31 152.31
- pf             1   112.32 152.32
- fg             1   112.44 152.44
- trb            1   112.65 152.65
- x2p_percent    1   113.50 153.50
<none>               111.64 153.64
- blk            1   113.93 153.93
- fg_percent     1   116.35 156.35
- pts            1   120.46 160.46
- teamChemistry  1   120.74 160.74
- fga            1   120.85 160.85
- stl            1   121.72 161.72
- x2p            1   129.03 169.03
- x3p            1   134.57 174.57
- fta            1   140.35 180.35
- x2pa           1   142.43 182.43
- x3pa           1   151.82 191.82
- ft             1   154.09 194.09

Step:  AIC=151.85
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + drb + trb + stl + blk + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   111.99 149.99
- tov            1   112.26 150.26
- x3p_percent    1   112.34 150.34
- fg             1   112.47 150.47
- pf             1   112.80 150.80
<none>               111.84 151.84
- x2p_percent    1   114.04 152.04
- blk            1   114.17 152.17
- fg_percent     1   116.88 154.88
- pts            1   120.46 158.46
- fga            1   121.46 159.46
- teamChemistry  1   122.73 160.73
- stl            1   122.87 160.87
- x2p            1   129.03 167.03
- trb            1   133.31 171.31
- x3p            1   134.65 172.65
- fta            1   140.35 178.35
- x2pa           1   143.29 181.29
- x3pa           1   153.42 191.42
- ft             1   154.24 192.24

Step:  AIC=149.99
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + trb + stl + blk + tov + 
    pf + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   112.47 148.47
- tov            1   112.78 148.78
- fg             1   112.97 148.97
- pf             1   113.32 149.32
<none>               111.99 149.99
- x2p_percent    1   114.13 150.13
- blk            1   114.24 150.24
- fg_percent     1   117.11 153.11
- pts            1   122.91 158.91
- teamChemistry  1   123.80 159.80
- fga            1   124.85 160.85
- stl            1   124.89 160.89
- x2p            1   133.86 169.86
- x3p            1   134.86 170.86
- fta            1   140.84 176.84
- x2pa           1   147.64 183.64
- x3pa           1   153.97 189.97
- ft             1   154.38 190.38
- trb            1   157.67 193.67

Step:  AIC=148.47
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + ft + fta + trb + stl + blk + tov + pf + pts + 
    teamChemistry

                Df Deviance    AIC
- fg             1   113.55 147.54
- pf             1   113.91 147.91
- tov            1   114.06 148.06
- blk            1   114.44 148.44
<none>               112.47 148.47
- x2p_percent    1   117.16 151.16
- fg_percent     1   120.48 154.49
- pts            1   123.52 157.51
- teamChemistry  1   125.15 159.15
- stl            1   125.79 159.79
- fga            1   126.05 160.05
- x2p            1   133.98 167.98
- x3p            1   135.00 169.00
- fta            1   140.85 174.85
- x2pa           1   147.76 181.76
- ft             1   154.43 188.43
- x3pa           1   154.44 188.44
- trb            1   158.38 192.38

Step:  AIC=147.55
.outcome ~ fga + fg_percent + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- tov            1   114.95 146.95
- pf             1   115.18 147.18
- blk            1   115.22 147.22
<none>               113.55 147.54
- x2p_percent    1   117.80 149.80
- fg_percent     1   120.96 152.96
- pts            1   124.59 156.59
- teamChemistry  1   125.30 157.30
- fga            1   126.43 158.43
- stl            1   127.54 159.54
- x3p            1   135.13 167.13
- x2p            1   137.84 169.84
- fta            1   140.89 172.89
- x2pa           1   147.76 179.76
- x3pa           1   154.44 186.44
- ft             1   154.92 186.92
- trb            1   162.40 194.40

Step:  AIC=146.95
.outcome ~ fga + fg_percent + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + trb + stl + blk + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   115.62 145.62
- blk            1   116.49 146.49
<none>               114.95 146.95
- x2p_percent    1   119.01 149.01
- fg_percent     1   122.23 152.23
- pts            1   126.00 156.00
- stl            1   127.54 157.54
- fga            1   128.16 158.16
- teamChemistry  1   128.80 158.80
- x3p            1   136.63 166.63
- x2p            1   139.22 169.22
- x2pa           1   148.40 178.40
- fta            1   151.61 181.61
- x3pa           1   155.48 185.48
- trb            1   162.51 192.51
- ft             1   168.79 198.79

Step:  AIC=145.62
.outcome ~ fga + fg_percent + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + trb + stl + blk + pts + teamChemistry

                Df Deviance    AIC
- blk            1   117.07 145.07
<none>               115.62 145.62
- x2p_percent    1   120.28 148.28
- fg_percent     1   123.86 151.86
- pts            1   126.35 154.35
- fga            1   128.24 156.24
- teamChemistry  1   128.85 156.85
- stl            1   132.25 160.25
- x3p            1   137.88 165.88
- x2p            1   139.22 167.22
- x2pa           1   148.87 176.87
- fta            1   152.94 180.94
- x3pa           1   155.55 183.55
- trb            1   162.88 190.88
- ft             1   170.22 198.22

Step:  AIC=145.07
.outcome ~ fga + fg_percent + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + trb + stl + pts + teamChemistry

                Df Deviance    AIC
<none>               117.07 145.07
- x2p_percent    1   121.16 147.16
- fg_percent     1   124.05 150.05
- pts            1   126.41 152.41
- fga            1   128.24 154.24
- teamChemistry  1   129.67 155.67
- stl            1   132.31 158.31
- x3p            1   137.91 163.91
- x2p            1   139.32 165.32
- x2pa           1   149.10 175.10
- fta            1   153.79 179.79
- x3pa           1   156.12 182.12
- trb            1   163.61 189.61
- ft             1   171.31 197.31
Start:  AIC=158.92
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   112.94 156.94
- drb            1   112.98 156.98
- pf             1   112.99 156.99
- fg_percent     1   113.01 157.01
- e_fg_percent   1   113.07 157.07
- x2p_percent    1   113.08 157.07
- orb            1   113.10 157.10
- fg             1   113.40 157.40
- trb            1   113.81 157.81
- tov            1   114.91 158.91
<none>               112.92 158.92
- ast            1   116.04 160.04
- x3p_percent    1   118.22 162.22
- teamChemistry  1   119.15 163.15
- fga            1   125.53 169.53
- pts            1   129.53 173.53
- x2p            1   130.88 174.88
- stl            1   132.26 176.26
- x3p            1   133.64 177.64
- x3pa           1   148.51 192.51
- fta            1   151.41 195.41
- x2pa           1   156.27 200.27
- ft             1   163.08 207.08

Step:  AIC=156.94
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   113.00 155.00
- pf             1   113.04 155.04
- fg_percent     1   113.05 155.05
- orb            1   113.11 155.11
- x2p_percent    1   113.11 155.11
- e_fg_percent   1   113.14 155.13
- fg             1   113.45 155.45
- trb            1   113.81 155.81
<none>               112.94 156.94
- tov            1   114.99 156.99
- ast            1   116.05 158.05
- x3p_percent    1   118.23 160.23
- teamChemistry  1   119.26 161.26
- fga            1   126.25 168.25
- x2p            1   131.75 173.75
- pts            1   132.58 174.58
- stl            1   132.81 174.81
- x3p            1   135.09 177.09
- x3pa           1   150.73 192.73
- fta            1   151.44 193.44
- x2pa           1   160.53 202.53
- ft             1   163.09 205.09

Step:  AIC=155
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    trb + ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   113.11 153.10
- fg_percent     1   113.11 153.12
- x2p_percent    1   113.19 153.19
- e_fg_percent   1   113.21 153.21
- fg             1   113.45 153.45
- orb            1   114.13 154.13
- tov            1   114.99 154.99
<none>               113.00 155.00
- ast            1   116.29 156.29
- x3p_percent    1   118.25 158.25
- teamChemistry  1   120.01 160.01
- fga            1   126.47 166.47
- x2p            1   131.96 171.96
- pts            1   132.58 172.58
- stl            1   132.92 172.92
- x3p            1   135.14 175.14
- x3pa           1   150.73 190.73
- fta            1   151.61 191.61
- trb            1   158.94 198.94
- x2pa           1   160.56 200.56
- ft             1   163.12 203.12

Step:  AIC=153.1
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   113.21 151.21
- e_fg_percent   1   113.33 151.34
- x2p_percent    1   113.40 151.40
- fg             1   113.48 151.49
- orb            1   114.47 152.47
<none>               113.11 153.10
- tov            1   115.84 153.84
- ast            1   116.31 154.31
- x3p_percent    1   118.42 156.42
- teamChemistry  1   120.09 158.09
- fga            1   126.87 164.87
- x2p            1   132.00 170.00
- pts            1   132.60 170.60
- stl            1   134.63 172.63
- x3p            1   136.13 174.13
- x3pa           1   151.42 189.42
- fta            1   154.89 192.89
- trb            1   159.04 197.04
- x2pa           1   160.56 198.56
- ft             1   167.63 205.63

Step:  AIC=151.21
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + trb + ast + 
    stl + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   113.37 149.37
- fg             1   113.52 149.52
- x2p_percent    1   113.96 149.96
- orb            1   114.71 150.71
<none>               113.21 151.21
- tov            1   115.86 151.85
- ast            1   116.54 152.54
- x3p_percent    1   119.63 155.63
- teamChemistry  1   120.18 156.18
- fga            1   127.32 163.32
- x2p            1   132.25 168.25
- pts            1   132.60 168.60
- stl            1   134.72 170.72
- x3p            1   137.43 173.43
- fta            1   155.04 191.04
- x3pa           1   155.27 191.27
- trb            1   159.96 195.96
- x2pa           1   160.69 196.69
- ft             1   167.65 203.65

Step:  AIC=149.37
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + ft + fta + orb + trb + ast + stl + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- fg             1   113.69 147.69
- x2p_percent    1   114.17 148.17
- orb            1   114.73 148.73
<none>               113.37 149.37
- tov            1   116.39 150.40
- ast            1   116.84 150.84
- teamChemistry  1   120.23 154.23
- x3p_percent    1   123.09 157.09
- fga            1   127.83 161.83
- x2p            1   132.95 166.95
- pts            1   133.33 167.33
- stl            1   135.40 169.40
- x3p            1   141.01 175.01
- fta            1   155.59 189.59
- trb            1   160.39 194.39
- x2pa           1   162.89 196.89
- x3pa           1   163.13 197.13
- ft             1   167.83 201.83

Step:  AIC=147.69
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + x2p_percent + 
    ft + fta + orb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   114.32 146.32
- orb            1   114.75 146.75
<none>               113.69 147.69
- tov            1   116.40 148.40
- ast            1   116.85 148.85
- teamChemistry  1   121.03 153.03
- x3p_percent    1   123.62 155.62
- pts            1   133.93 165.93
- fga            1   133.94 165.94
- stl            1   135.95 167.95
- x3p            1   142.80 174.80
- x2p            1   146.08 178.08
- fta            1   157.27 189.27
- trb            1   161.05 193.05
- x3pa           1   164.19 196.19
- x2pa           1   167.59 199.59
- ft             1   174.02 206.02

Step:  AIC=146.32
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + ft + 
    fta + orb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- orb            1   114.97 144.97
<none>               114.32 146.32
- ast            1   117.52 147.51
- tov            1   117.62 147.62
- teamChemistry  1   123.42 153.42
- x3p_percent    1   123.65 153.65
- fga            1   133.94 163.94
- pts            1   133.98 163.98
- stl            1   137.76 167.76
- x3p            1   142.95 172.95
- x2p            1   148.62 178.62
- fta            1   157.28 187.28
- trb            1   161.86 191.86
- x3pa           1   164.42 194.42
- x2pa           1   169.50 199.50
- ft             1   174.02 204.02

Step:  AIC=144.97
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + ft + 
    fta + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               114.97 144.97
- tov            1   118.25 146.25
- ast            1   118.50 146.50
- x3p_percent    1   123.75 151.75
- teamChemistry  1   127.78 155.78
- pts            1   134.06 162.06
- fga            1   134.21 162.21
- stl            1   138.38 166.38
- x3p            1   146.81 174.81
- x2p            1   149.13 177.13
- fta            1   158.04 186.04
- trb            1   166.65 194.65
- x2pa           1   171.43 199.43
- x3pa           1   172.10 200.10
- ft             1   174.30 202.30
Start:  AIC=178.05
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   132.38 176.38
- pf             1   132.39 176.39
- x2p_percent    1   132.49 176.49
- ast            1   132.72 176.72
- drb            1   132.93 176.93
- x3p_percent    1   133.12 177.12
- blk            1   133.13 177.13
- e_fg_percent   1   133.23 177.23
- fg             1   133.25 177.25
- orb            1   133.48 177.48
<none>               132.05 178.05
- trb            1   134.35 178.35
- teamChemistry  1   137.28 181.28
- fga            1   137.87 181.87
- pts            1   139.53 183.53
- x3p            1   141.35 185.35
- x2p            1   143.98 187.98
- fta            1   148.13 192.13
- x3pa           1   152.09 196.09
- ft             1   154.52 198.52
- x2pa           1   157.19 201.19
- tov            1   158.68 202.68
- stl            1   167.48 211.48

Step:  AIC=176.38
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   132.65 174.65
- ast            1   132.90 174.90
- x3p_percent    1   133.14 175.14
- fg             1   133.27 175.27
- drb            1   133.44 175.44
- x2p_percent    1   133.63 175.63
- e_fg_percent   1   133.80 175.80
- blk            1   133.81 175.81
- orb            1   134.02 176.02
<none>               132.38 176.38
- trb            1   134.99 176.99
- teamChemistry  1   137.28 179.28
- fga            1   137.88 179.88
- pts            1   140.27 182.27
- x3p            1   141.51 183.51
- x2p            1   144.00 186.00
- fta            1   148.48 190.48
- x3pa           1   153.29 195.29
- ft             1   154.78 196.78
- x2pa           1   157.54 199.54
- tov            1   159.14 201.14
- stl            1   168.79 210.79

Step:  AIC=174.65
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- ast            1   133.12 173.12
- x3p_percent    1   133.31 173.31
- drb            1   133.62 173.62
- fg             1   133.67 173.67
- x2p_percent    1   133.70 173.70
- e_fg_percent   1   133.85 173.85
- orb            1   134.18 174.18
- blk            1   134.22 174.22
<none>               132.65 174.65
- trb            1   135.14 175.14
- teamChemistry  1   137.40 177.40
- fga            1   138.87 178.87
- pts            1   140.97 180.97
- x3p            1   143.17 183.17
- x2p            1   144.52 184.52
- fta            1   148.55 188.55
- x3pa           1   154.86 194.86
- ft             1   155.93 195.93
- x2pa           1   157.55 197.55
- tov            1   162.79 202.79
- stl            1   171.43 211.43

Step:  AIC=173.12
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   133.85 171.85
- fg             1   133.92 171.92
- drb            1   134.23 172.23
- e_fg_percent   1   134.49 172.49
- x2p_percent    1   134.56 172.56
- orb            1   134.82 172.82
- blk            1   134.92 172.92
<none>               133.12 173.12
- trb            1   135.82 173.82
- teamChemistry  1   137.93 175.93
- fga            1   139.72 177.72
- pts            1   142.01 180.01
- x3p            1   143.30 181.30
- x2p            1   146.55 184.55
- fta            1   150.99 188.99
- x3pa           1   154.86 192.86
- ft             1   158.24 196.24
- x2pa           1   159.61 197.61
- tov            1   162.98 200.98
- stl            1   175.31 213.31

Step:  AIC=171.86
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + x2p_percent + 
    e_fg_percent + ft + fta + orb + drb + trb + stl + blk + tov + 
    pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   134.51 170.51
- x2p_percent    1   134.59 170.59
- drb            1   134.69 170.69
- fg             1   134.75 170.75
- orb            1   135.20 171.20
<none>               133.85 171.85
- trb            1   136.16 172.16
- blk            1   136.40 172.40
- teamChemistry  1   139.03 175.03
- fga            1   140.63 176.63
- pts            1   142.83 178.83
- x3p            1   146.04 182.04
- x2p            1   147.50 183.50
- fta            1   151.08 187.08
- ft             1   158.65 194.65
- x3pa           1   158.90 194.90
- x2pa           1   160.56 196.56
- tov            1   165.77 201.77
- stl            1   182.04 218.04

Step:  AIC=170.51
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + orb + drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   134.67 168.67
- drb            1   135.63 169.63
- fg             1   135.72 169.72
- orb            1   136.25 170.25
<none>               134.51 170.51
- trb            1   137.32 171.32
- blk            1   138.16 172.16
- teamChemistry  1   139.06 173.06
- fga            1   141.60 175.60
- pts            1   143.53 177.53
- x3p            1   148.13 182.13
- x2p            1   150.14 184.14
- fta            1   151.82 185.82
- ft             1   160.45 194.45
- x3pa           1   160.97 194.97
- x2pa           1   163.81 197.81
- tov            1   165.94 199.94
- stl            1   182.60 216.60

Step:  AIC=168.67
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- drb            1   135.89 167.89
- fg             1   136.09 168.09
- orb            1   136.56 168.56
<none>               134.67 168.67
- trb            1   137.66 169.66
- blk            1   138.30 170.30
- teamChemistry  1   139.28 171.28
- fga            1   141.78 173.78
- pts            1   143.83 175.83
- x3p            1   148.54 180.54
- x2p            1   150.19 182.19
- fta            1   151.83 183.83
- ft             1   160.50 192.50
- x3pa           1   161.09 193.09
- x2pa           1   164.45 196.45
- tov            1   167.09 199.09
- stl            1   184.34 216.34

Step:  AIC=167.89
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- fg             1   136.53 166.53
<none>               135.89 167.89
- blk            1   140.40 170.40
- teamChemistry  1   140.88 170.88
- orb            1   141.37 171.37
- fga            1   142.66 172.66
- pts            1   144.24 174.24
- x3p            1   148.69 178.69
- x2p            1   150.19 180.19
- fta            1   151.97 181.97
- ft             1   160.51 190.51
- x3pa           1   163.44 193.44
- x2pa           1   165.77 195.77
- tov            1   167.12 197.12
- trb            1   181.93 211.93
- stl            1   186.30 216.30

Step:  AIC=166.53
.outcome ~ fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + trb + 
    stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               136.53 166.53
- blk            1   140.85 168.85
- orb            1   141.41 169.41
- teamChemistry  1   141.92 169.92
- fga            1   143.67 171.67
- pts            1   144.24 172.24
- x3p            1   149.22 177.22
- fta            1   152.73 180.73
- x2p            1   156.35 184.35
- ft             1   160.51 188.51
- x3pa           1   163.57 191.57
- x2pa           1   166.98 194.98
- tov            1   167.79 195.79
- trb            1   182.22 210.22
- stl            1   186.95 214.95
Start:  AIC=175.43
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   129.48 173.48
- pf             1   129.49 173.49
- fga            1   129.68 173.68
- ast            1   129.88 173.88
- fg             1   129.98 173.98
- x2p_percent    1   130.22 174.22
- pts            1   130.86 174.86
- drb            1   131.04 175.04
- orb            1   131.32 175.32
<none>               129.43 175.43
- trb            1   131.89 175.89
- tov            1   132.77 176.77
- teamChemistry  1   133.28 177.28
- x3p_percent    1   135.29 179.29
- stl            1   135.32 179.32
- e_fg_percent   1   135.65 179.65
- fg_percent     1   139.07 183.07
- x2p            1   139.60 183.60
- fta            1   141.31 185.31
- x2pa           1   141.46 185.46
- x3p            1   142.74 186.74
- x3pa           1   146.57 190.57
- ft             1   148.13 192.13

Step:  AIC=173.48
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   129.55 171.55
- fga            1   129.70 171.70
- ast            1   129.94 171.94
- fg             1   130.00 172.00
- x2p_percent    1   130.23 172.23
- pts            1   130.86 172.86
- drb            1   131.06 173.06
- orb            1   131.32 173.32
<none>               129.48 173.48
- trb            1   131.89 173.89
- tov            1   132.83 174.83
- teamChemistry  1   133.52 175.52
- stl            1   135.38 177.38
- x3p_percent    1   135.52 177.52
- e_fg_percent   1   135.83 177.83
- fg_percent     1   139.11 181.11
- x2p            1   139.64 181.64
- x2pa           1   141.50 183.50
- fta            1   141.55 183.55
- x3p            1   143.34 185.34
- x3pa           1   147.34 189.34
- ft             1   148.30 190.30

Step:  AIC=171.55
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- fga            1   129.75 169.75
- ast            1   130.07 170.07
- fg             1   130.14 170.14
- x2p_percent    1   130.23 170.23
- pts            1   130.88 170.88
- drb            1   131.11 171.11
- orb            1   131.39 171.39
<none>               129.55 171.55
- trb            1   131.94 171.94
- teamChemistry  1   133.53 173.53
- tov            1   135.35 175.35
- stl            1   135.63 175.63
- x3p_percent    1   135.72 175.72
- e_fg_percent   1   135.92 175.92
- fg_percent     1   139.14 179.14
- x2p            1   139.82 179.82
- fta            1   141.55 181.55
- x2pa           1   141.63 181.63
- x3p            1   143.66 183.66
- x3pa           1   147.70 187.70
- ft             1   148.76 188.76

Step:  AIC=169.75
.outcome ~ fg + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + x2p_percent + e_fg_percent + ft + fta + orb + drb + 
    trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- fg             1   130.14 168.14
- ast            1   130.20 168.20
- x2p_percent    1   130.41 168.41
- pts            1   131.02 169.02
- drb            1   131.38 169.38
- orb            1   131.58 169.58
<none>               129.75 169.75
- trb            1   132.15 170.15
- teamChemistry  1   134.15 172.15
- tov            1   135.41 173.41
- stl            1   135.75 173.75
- x3p_percent    1   135.92 173.92
- e_fg_percent   1   136.13 174.13
- fg_percent     1   139.29 177.29
- fta            1   141.59 179.59
- x3p            1   147.04 185.04
- ft             1   149.29 187.29
- x2p            1   153.11 191.11
- x3pa           1   155.69 193.69
- x2pa           1   159.12 197.12

Step:  AIC=168.14
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- ast            1   130.49 166.49
- x2p_percent    1   130.71 166.71
- drb            1   131.47 167.47
- orb            1   131.65 167.65
- pts            1   131.77 167.77
<none>               130.14 168.14
- trb            1   132.21 168.21
- teamChemistry  1   134.66 170.66
- tov            1   135.42 171.42
- x3p_percent    1   136.07 172.07
- e_fg_percent   1   136.26 172.26
- stl            1   137.04 173.04
- fg_percent     1   139.29 175.29
- fta            1   141.65 177.65
- x3p            1   147.09 183.09
- ft             1   149.38 185.38
- x2p            1   156.50 192.50
- x3pa           1   157.52 193.52
- x2pa           1   164.02 200.02

Step:  AIC=166.49
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   130.93 164.93
- pts            1   131.79 165.79
- drb            1   132.19 166.19
- orb            1   132.38 166.38
<none>               130.49 166.49
- trb            1   132.93 166.93
- teamChemistry  1   134.94 168.94
- tov            1   135.76 169.76
- e_fg_percent   1   136.53 170.53
- x3p_percent    1   136.56 170.56
- stl            1   137.21 171.21
- fg_percent     1   139.49 173.49
- fta            1   141.82 175.82
- x3p            1   147.13 181.13
- ft             1   149.41 183.41
- x3pa           1   158.42 192.42
- x2p            1   160.02 194.02
- x2pa           1   164.21 198.21

Step:  AIC=164.93
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + drb + trb + stl + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- pts            1   132.41 164.41
- drb            1   132.73 164.73
<none>               130.93 164.93
- orb            1   132.95 164.95
- trb            1   133.49 165.49
- teamChemistry  1   135.29 167.29
- tov            1   135.98 167.98
- e_fg_percent   1   136.80 168.80
- x3p_percent    1   137.71 169.71
- stl            1   137.78 169.78
- fg_percent     1   139.94 171.94
- fta            1   142.62 174.62
- x3p            1   147.17 179.17
- ft             1   149.99 181.99
- x3pa           1   159.60 191.60
- x2p            1   163.18 195.18
- x2pa           1   169.21 201.21

Step:  AIC=164.41
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + drb + trb + stl + tov + teamChemistry

                Df Deviance    AIC
- drb            1   133.49 163.49
- orb            1   133.62 163.62
- trb            1   134.07 164.07
<none>               132.41 164.41
- tov            1   137.50 167.50
- teamChemistry  1   137.57 167.57
- stl            1   137.96 167.96
- e_fg_percent   1   138.79 168.79
- x3p_percent    1   139.26 169.26
- fg_percent     1   142.03 172.03
- fta            1   143.13 173.13
- x3p            1   148.50 178.50
- ft             1   150.05 180.05
- x3pa           1   159.91 189.91
- x2pa           1   169.22 199.22
- x2p            1   169.61 199.61

Step:  AIC=163.49
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + trb + stl + tov + teamChemistry

                Df Deviance    AIC
- orb            1   133.84 161.84
<none>               133.49 163.49
- tov            1   137.78 165.78
- teamChemistry  1   138.98 166.98
- stl            1   140.01 168.01
- e_fg_percent   1   140.11 168.11
- x3p_percent    1   140.74 168.74
- fg_percent     1   143.40 171.40
- trb            1   143.99 171.99
- fta            1   145.59 173.59
- x3p            1   149.22 177.22
- ft             1   153.69 181.69
- x3pa           1   160.09 188.09
- x2p            1   169.61 197.61
- x2pa           1   169.65 197.65

Step:  AIC=161.84
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + trb + stl + tov + teamChemistry

                Df Deviance    AIC
<none>               133.84 161.84
- tov            1   137.96 163.96
- teamChemistry  1   140.14 166.14
- e_fg_percent   1   140.18 166.18
- stl            1   140.19 166.19
- x3p_percent    1   140.76 166.76
- fg_percent     1   143.44 169.44
- fta            1   146.43 172.43
- trb            1   146.79 172.79
- x3p            1   151.86 177.86
- ft             1   155.46 181.46
- x3pa           1   161.30 187.30
- x2pa           1   169.90 195.90
- x2p            1   170.89 196.89
Start:  AIC=153.23
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   107.23 151.23
- x3p_percent    1   107.46 151.46
- e_fg_percent   1   107.70 151.70
- fg_percent     1   107.85 151.85
- drb            1   108.05 152.05
- x2p_percent    1   108.37 152.37
- fg             1   108.89 152.89
- orb            1   109.01 153.01
- pf             1   109.22 153.22
<none>               107.23 153.23
- trb            1   109.78 153.78
- blk            1   110.93 154.93
- tov            1   111.41 155.41
- teamChemistry  1   114.00 158.00
- fga            1   115.03 159.03
- pts            1   115.08 159.08
- fta            1   119.62 163.62
- ft             1   123.51 167.51
- x2p            1   124.31 168.31
- x3p            1   128.65 172.65
- stl            1   131.54 175.54
- x3pa           1   144.75 188.75
- x2pa           1   148.94 192.94

Step:  AIC=151.23
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   107.46 149.46
- e_fg_percent   1   107.73 149.73
- fg_percent     1   107.88 149.88
- drb            1   108.05 150.05
- x2p_percent    1   108.37 150.37
- orb            1   109.02 151.02
- fg             1   109.18 151.18
<none>               107.23 151.23
- pf             1   109.24 151.24
- trb            1   109.79 151.79
- blk            1   110.93 152.93
- tov            1   111.45 153.46
- teamChemistry  1   114.02 156.02
- fga            1   115.07 157.07
- pts            1   115.14 157.14
- fta            1   119.75 161.75
- ft             1   123.52 165.51
- x2p            1   124.34 166.34
- x3p            1   129.93 171.93
- stl            1   132.17 174.17
- x3pa           1   144.94 186.94
- x2pa           1   149.41 191.41

Step:  AIC=149.46
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   108.10 148.10
- x2p_percent    1   108.38 148.38
- fg_percent     1   108.76 148.76
- orb            1   109.02 149.02
- fg             1   109.18 149.18
- pf             1   109.40 149.40
<none>               107.46 149.46
- e_fg_percent   1   109.78 149.78
- trb            1   109.79 149.79
- blk            1   110.99 150.99
- tov            1   111.73 151.73
- teamChemistry  1   114.81 154.81
- fga            1   115.07 155.07
- pts            1   115.27 155.27
- fta            1   119.78 159.78
- ft             1   123.66 163.66
- x2p            1   125.04 165.04
- x3p            1   129.94 169.94
- stl            1   137.22 177.22
- x3pa           1   145.34 185.34
- x2pa           1   149.52 189.52

Step:  AIC=148.1
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + trb + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   109.09 147.09
- fg_percent     1   109.33 147.34
- fg             1   109.43 147.43
<none>               108.10 148.10
- e_fg_percent   1   110.36 148.37
- pf             1   110.89 148.89
- blk            1   111.50 149.50
- tov            1   111.98 149.98
- orb            1   113.96 151.96
- teamChemistry  1   115.73 153.73
- pts            1   115.92 153.92
- fga            1   116.34 154.34
- fta            1   120.70 158.70
- ft             1   124.70 162.70
- x2p            1   125.14 163.14
- x3p            1   130.21 168.21
- stl            1   142.08 180.08
- trb            1   145.85 183.85
- x3pa           1   148.33 186.33
- x2pa           1   152.97 190.97

Step:  AIC=147.09
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + trb + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   109.44 145.44
- e_fg_percent   1   110.71 146.71
- fg             1   111.06 147.06
<none>               109.09 147.09
- pf             1   111.49 147.49
- tov            1   112.87 148.87
- blk            1   113.00 149.00
- orb            1   116.02 152.02
- teamChemistry  1   116.67 152.67
- pts            1   117.59 153.59
- fga            1   119.25 155.25
- fta            1   121.38 157.38
- ft             1   126.28 162.28
- x2p            1   127.57 163.57
- x3p            1   137.22 173.22
- stl            1   143.41 179.41
- trb            1   147.23 183.23
- x2pa           1   153.87 189.87
- x3pa           1   162.52 198.52

Step:  AIC=145.44
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
<none>               109.44 145.44
- fg             1   111.58 145.57
- pf             1   112.04 146.04
- tov            1   113.14 147.14
- e_fg_percent   1   113.24 147.24
- blk            1   113.28 147.28
- orb            1   116.33 150.33
- pts            1   118.19 152.19
- teamChemistry  1   118.23 152.23
- fga            1   120.28 154.28
- fta            1   122.43 156.43
- ft             1   127.73 161.73
- x2p            1   129.29 163.29
- x3p            1   138.29 172.29
- stl            1   143.51 177.51
- trb            1   147.40 181.40
- x2pa           1   154.62 188.62
- x3pa           1   163.60 197.60
Start:  AIC=155.55
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   109.56 153.56
- x2p_percent    1   109.87 153.87
- blk            1   110.96 154.96
- e_fg_percent   1   111.08 155.09
<none>               109.55 155.55
- fg_percent     1   111.65 155.65
- x3p_percent    1   112.53 156.53
- ast            1   112.58 156.58
- drb            1   113.28 157.28
- tov            1   114.41 158.41
- orb            1   114.65 158.65
- fga            1   115.03 159.03
- trb            1   115.84 159.84
- fg             1   116.36 160.37
- teamChemistry  1   116.52 160.52
- fta            1   117.42 161.42
- pts            1   120.21 164.21
- ft             1   125.29 169.29
- x2p            1   132.31 176.31
- x3p            1   132.35 176.35
- stl            1   135.33 179.33
- x2pa           1   135.96 179.96
- x3pa           1   137.85 181.85

Step:  AIC=153.56
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   109.92 151.92
- blk            1   110.96 152.96
- e_fg_percent   1   111.10 153.10
<none>               109.56 153.56
- fg_percent     1   111.66 153.66
- x3p_percent    1   112.53 154.53
- ast            1   112.73 154.73
- drb            1   113.36 155.36
- orb            1   114.78 156.78
- fga            1   115.15 157.15
- tov            1   115.89 157.89
- trb            1   116.02 158.02
- fg             1   116.41 158.41
- teamChemistry  1   116.56 158.56
- fta            1   117.46 159.46
- pts            1   120.27 162.27
- ft             1   125.71 167.71
- x2p            1   132.34 174.34
- x3p            1   132.97 174.97
- x2pa           1   136.02 178.02
- stl            1   137.10 179.10
- x3pa           1   138.09 180.09

Step:  AIC=151.92
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   111.29 151.29
- blk            1   111.42 151.42
<none>               109.92 151.92
- x3p_percent    1   112.54 152.54
- fg_percent     1   112.93 152.93
- drb            1   113.46 153.46
- ast            1   113.55 153.55
- orb            1   114.86 154.85
- fga            1   115.82 155.82
- trb            1   116.09 156.09
- teamChemistry  1   116.67 156.68
- fg             1   116.86 156.86
- fta            1   117.48 157.48
- tov            1   117.53 157.53
- pts            1   120.39 160.39
- ft             1   125.80 165.80
- x2p            1   132.39 172.39
- x3p            1   135.90 175.90
- x2pa           1   136.06 176.06
- stl            1   137.70 177.70
- x3pa           1   143.72 183.72

Step:  AIC=151.29
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + ast + stl + blk + 
    tov + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   112.55 150.55
- blk            1   112.81 150.81
<none>               111.29 151.29
- ast            1   114.63 152.63
- drb            1   114.78 152.78
- orb            1   115.99 153.99
- fga            1   116.14 154.13
- fg_percent     1   116.19 154.19
- teamChemistry  1   116.91 154.91
- fg             1   117.22 155.22
- trb            1   117.30 155.30
- fta            1   118.60 156.60
- tov            1   118.90 156.90
- pts            1   120.81 158.81
- ft             1   126.41 164.41
- x2p            1   132.39 170.39
- x3p            1   136.07 174.07
- x2pa           1   136.59 174.59
- stl            1   139.30 177.30
- x3pa           1   143.73 181.73

Step:  AIC=150.55
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    ft + fta + orb + drb + trb + ast + stl + blk + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- blk            1   114.16 150.16
<none>               112.55 150.55
- drb            1   115.16 151.16
- ast            1   115.48 151.48
- orb            1   116.15 152.15
- fga            1   116.46 152.46
- fg_percent     1   117.08 153.09
- fg             1   117.31 153.31
- trb            1   117.45 153.45
- fta            1   118.91 154.91
- teamChemistry  1   119.74 155.74
- tov            1   120.07 156.07
- pts            1   121.16 157.16
- ft             1   126.42 162.42
- x2p            1   132.61 168.61
- x3p            1   136.45 172.45
- x2pa           1   136.79 172.79
- stl            1   141.63 177.63
- x3pa           1   143.96 179.96

Step:  AIC=150.16
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    ft + fta + orb + drb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               114.16 150.16
- drb            1   116.70 150.70
- fga            1   117.17 151.17
- ast            1   117.18 151.18
- fg_percent     1   117.38 151.38
- orb            1   117.69 151.69
- trb            1   118.79 152.79
- fg             1   118.83 152.83
- tov            1   120.52 154.52
- fta            1   121.29 155.29
- pts            1   121.96 155.96
- teamChemistry  1   122.57 156.57
- ft             1   128.50 162.50
- x2p            1   132.93 166.93
- x3p            1   136.53 170.53
- x2pa           1   136.79 170.79
- stl            1   141.64 175.64
- x3pa           1   144.37 178.37
Start:  AIC=165.8
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   119.86 163.86
- x2p_percent    1   120.05 164.05
- blk            1   120.12 164.12
- ast            1   120.38 164.38
- e_fg_percent   1   120.45 164.45
- drb            1   120.65 164.65
- teamChemistry  1   120.67 164.67
- fg             1   121.12 165.12
- orb            1   121.37 165.37
<none>               119.80 165.79
- trb            1   121.80 165.80
- x3p_percent    1   122.23 166.23
- pf             1   125.50 169.50
- tov            1   125.53 169.53
- x3p            1   129.00 173.00
- fga            1   129.81 173.81
- fta            1   131.56 175.56
- x2p            1   132.98 176.98
- pts            1   133.50 177.50
- x3pa           1   134.84 178.84
- ft             1   141.61 185.61
- x2pa           1   146.26 190.26
- stl            1   150.62 194.62

Step:  AIC=163.86
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   120.21 162.21
- x2p_percent    1   120.33 162.33
- ast            1   120.42 162.43
- teamChemistry  1   120.68 162.68
- drb            1   120.86 162.86
- fg             1   121.12 163.12
- e_fg_percent   1   121.64 163.64
- orb            1   121.66 163.66
<none>               119.86 163.86
- trb            1   122.17 164.16
- x3p_percent    1   122.71 164.71
- pf             1   125.50 167.50
- tov            1   125.53 167.53
- x3p            1   129.10 171.10
- fga            1   129.81 171.81
- fta            1   132.03 174.03
- x2p            1   132.98 174.98
- pts            1   134.09 176.09
- x3pa           1   134.96 176.96
- ft             1   142.04 184.04
- x2pa           1   147.59 189.59
- stl            1   151.89 193.89

Step:  AIC=162.21
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   120.71 160.71
- drb            1   120.97 160.97
- ast            1   121.13 161.13
- fg             1   121.39 161.39
- teamChemistry  1   121.43 161.43
- orb            1   121.70 161.70
- e_fg_percent   1   122.08 162.08
- trb            1   122.18 162.18
<none>               120.21 162.21
- x3p_percent    1   123.15 163.15
- tov            1   125.53 165.53
- pf             1   125.86 165.86
- x3p            1   129.10 169.10
- fga            1   129.85 169.85
- fta            1   132.88 172.88
- x2p            1   132.99 172.99
- pts            1   134.14 174.14
- x3pa           1   135.17 175.17
- ft             1   143.07 183.07
- x2pa           1   147.88 187.88
- stl            1   153.25 193.25

Step:  AIC=160.71
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + drb + trb + ast + stl + tov + 
    pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   121.38 159.38
- ast            1   121.72 159.72
- teamChemistry  1   121.79 159.79
- fg             1   121.91 159.91
- orb            1   122.08 160.08
- e_fg_percent   1   122.56 160.56
- trb            1   122.57 160.57
<none>               120.71 160.71
- x3p_percent    1   123.22 161.22
- tov            1   126.16 164.16
- pf             1   126.56 164.56
- fga            1   130.31 168.31
- x3p            1   130.80 168.80
- fta            1   132.88 170.88
- x2p            1   132.99 170.99
- pts            1   134.83 172.83
- x3pa           1   137.42 175.42
- ft             1   143.07 181.07
- x2pa           1   147.88 185.88
- stl            1   155.90 193.90

Step:  AIC=159.38
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + trb + ast + stl + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- fg             1   122.23 158.23
- ast            1   122.69 158.69
- teamChemistry  1   123.01 159.01
- e_fg_percent   1   123.14 159.14
<none>               121.38 159.38
- x3p_percent    1   123.55 159.55
- tov            1   126.31 162.31
- pf             1   127.98 163.98
- orb            1   130.21 166.21
- fga            1   131.29 167.29
- x3p            1   131.49 167.49
- x2p            1   132.99 168.99
- fta            1   133.06 169.06
- pts            1   134.92 170.92
- x3pa           1   139.35 175.35
- ft             1   143.07 179.07
- x2pa           1   147.99 183.99
- stl            1   155.95 191.95
- trb            1   158.06 194.06

Step:  AIC=158.23
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + trb + ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   122.97 156.97
- x3p_percent    1   124.11 158.11
- teamChemistry  1   124.12 158.12
<none>               122.23 158.23
- e_fg_percent   1   124.46 158.46
- tov            1   126.67 160.67
- pf             1   128.29 162.29
- orb            1   130.59 164.59
- x3p            1   131.79 165.79
- fta            1   133.07 167.07
- fga            1   133.46 167.46
- pts            1   135.06 169.06
- x2p            1   137.49 171.49
- x3pa           1   139.38 173.38
- ft             1   144.73 178.73
- x2pa           1   149.16 183.16
- trb            1   158.42 192.42
- stl            1   162.00 196.00

Step:  AIC=156.97
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + trb + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- teamChemistry  1   124.57 156.57
- x3p_percent    1   124.96 156.96
<none>               122.97 156.97
- e_fg_percent   1   125.01 157.01
- tov            1   126.93 158.93
- pf             1   130.50 162.50
- x3p            1   132.15 164.15
- orb            1   132.35 164.35
- fga            1   134.53 166.53
- pts            1   135.18 167.18
- fta            1   136.53 168.53
- x3pa           1   139.53 171.53
- x2p            1   139.94 171.94
- ft             1   148.36 180.36
- x2pa           1   150.30 182.30
- trb            1   158.44 190.44
- stl            1   166.74 198.74

Step:  AIC=156.57
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + trb + stl + tov + pf + pts

               Df Deviance    AIC
- e_fg_percent  1   126.04 156.04
- x3p_percent   1   126.38 156.38
<none>              124.57 156.57
- tov           1   129.88 159.88
- pf            1   131.81 161.81
- x3p           1   134.31 164.31
- orb           1   135.22 165.22
- fga           1   136.99 166.99
- pts           1   137.51 167.51
- fta           1   138.36 168.36
- x2p           1   142.45 172.45
- x3pa          1   142.49 172.49
- ft            1   149.61 179.61
- x2pa          1   155.64 185.64
- trb           1   167.13 197.13
- stl           1   170.09 200.09

Step:  AIC=156.04
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + ft + 
    fta + orb + trb + stl + tov + pf + pts

              Df Deviance    AIC
- x3p_percent  1   127.24 155.24
<none>             126.04 156.04
- tov          1   130.21 158.21
- pf           1   133.90 161.90
- orb          1   136.46 164.46
- x3p          1   137.12 165.12
- fga          1   138.51 166.51
- pts          1   138.75 166.75
- fta          1   139.77 167.77
- x3pa         1   145.17 173.17
- x2p          1   146.71 174.71
- ft           1   152.10 180.10
- x2pa         1   159.65 187.65
- trb          1   167.25 195.25
- stl          1   170.13 198.13

Step:  AIC=155.24
.outcome ~ fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + trb + 
    stl + tov + pf + pts

       Df Deviance    AIC
<none>      127.24 155.24
- tov   1   132.89 158.89
- pf    1   135.16 161.16
- orb   1   137.94 163.94
- x3p   1   137.94 163.94
- fta   1   140.03 166.03
- pts   1   140.30 166.30
- fga   1   141.04 167.04
- x3pa  1   147.03 173.03
- x2p   1   147.63 173.63
- ft    1   152.41 178.41
- x2pa  1   161.71 187.71
- trb   1   170.10 196.10
- stl   1   176.58 202.58
Start:  AIC=157.57
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   111.66 155.66
- ast            1   112.40 156.40
- x2p_percent    1   112.59 156.59
- e_fg_percent   1   112.61 156.61
- drb            1   112.98 156.98
<none>               111.57 157.57
- orb            1   113.75 157.75
- fga            1   113.78 157.78
- blk            1   114.08 158.08
- trb            1   114.22 158.22
- fg             1   114.30 158.30
- x3p            1   115.28 159.28
- teamChemistry  1   115.53 159.53
- pts            1   115.59 159.59
- x3p_percent    1   117.85 161.85
- x3pa           1   119.17 163.17
- fta            1   119.54 163.54
- ft             1   119.72 163.72
- pf             1   123.43 167.43
- x2p            1   129.34 173.34
- stl            1   134.45 178.45
- x2pa           1   134.50 178.50
- tov            1   146.38 190.38

Step:  AIC=155.66
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   112.44 154.44
- drb            1   113.03 155.03
<none>               111.66 155.66
- x2p_percent    1   113.67 155.67
- orb            1   113.79 155.79
- fga            1   113.84 155.84
- trb            1   114.27 156.27
- e_fg_percent   1   114.34 156.34
- blk            1   114.40 156.40
- fg             1   114.42 156.42
- x3p            1   115.37 157.37
- teamChemistry  1   115.53 157.53
- pts            1   115.59 157.59
- x3p_percent    1   118.61 160.60
- x3pa           1   119.51 161.51
- fta            1   119.61 161.61
- ft             1   119.74 161.74
- pf             1   123.63 165.63
- x2p            1   129.65 171.65
- x2pa           1   134.68 176.68
- stl            1   137.22 179.22
- tov            1   146.38 188.38

Step:  AIC=154.44
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   114.17 154.17
<none>               112.44 154.44
- fg             1   114.56 154.56
- fga            1   114.84 154.84
- orb            1   115.10 155.10
- x2p_percent    1   115.26 155.26
- e_fg_percent   1   115.55 155.55
- trb            1   115.56 155.56
- blk            1   115.59 155.59
- x3p            1   115.69 155.69
- teamChemistry  1   116.18 156.18
- pts            1   116.78 156.78
- x3p_percent    1   119.60 159.60
- x3pa           1   119.67 159.67
- ft             1   120.47 160.47
- fta            1   120.97 160.97
- pf             1   125.55 165.55
- x2p            1   132.60 172.60
- x2pa           1   137.00 177.00
- stl            1   140.68 180.68
- tov            1   149.10 189.10

Step:  AIC=154.17
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + trb + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg             1   115.24 153.24
<none>               114.17 154.17
- fga            1   116.68 154.68
- x3p            1   116.74 154.74
- blk            1   117.98 155.98
- x2p_percent    1   117.99 155.99
- pts            1   118.42 156.42
- e_fg_percent   1   119.26 157.26
- x3pa           1   121.24 159.24
- x3p_percent    1   121.86 159.87
- teamChemistry  1   121.94 159.94
- ft             1   122.49 160.49
- fta            1   122.67 160.67
- orb            1   123.53 161.53
- pf             1   126.96 164.96
- x2p            1   132.72 170.72
- x2pa           1   138.84 176.84
- stl            1   147.91 185.91
- trb            1   147.94 185.94
- tov            1   149.58 187.58

Step:  AIC=153.24
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + x2p_percent + 
    e_fg_percent + ft + fta + orb + trb + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- fga            1   116.69 152.69
- x3p            1   116.79 152.79
<none>               115.24 153.24
- pts            1   118.47 154.47
- blk            1   119.02 155.02
- x2p_percent    1   120.43 156.43
- e_fg_percent   1   121.23 157.23
- x3pa           1   121.26 157.26
- ft             1   122.51 158.51
- fta            1   122.79 158.79
- teamChemistry  1   122.96 158.96
- orb            1   123.53 159.53
- x3p_percent    1   124.61 160.61
- pf             1   128.15 164.15
- x2pa           1   139.98 175.98
- x2p            1   140.49 176.49
- stl            1   148.09 184.09
- trb            1   148.15 184.15
- tov            1   149.71 185.71

Step:  AIC=152.69
.outcome ~ x3p + x3pa + x3p_percent + x2p + x2pa + x2p_percent + 
    e_fg_percent + ft + fta + orb + trb + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- x3p            1   117.29 151.29
- pts            1   118.54 152.54
<none>               116.69 152.69
- blk            1   119.62 153.62
- x3pa           1   121.65 155.65
- ft             1   122.56 156.56
- x2p_percent    1   122.81 156.81
- fta            1   123.40 157.40
- e_fg_percent   1   123.85 157.85
- orb            1   124.64 158.64
- teamChemistry  1   126.11 160.12
- x3p_percent    1   126.80 160.79
- pf             1   129.48 163.48
- stl            1   148.16 182.16
- trb            1   150.39 184.39
- tov            1   153.55 187.55
- x2p            1   153.71 187.71
- x2pa           1   163.24 197.24

Step:  AIC=151.29
.outcome ~ x3pa + x3p_percent + x2p + x2pa + x2p_percent + e_fg_percent + 
    ft + fta + orb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pts            1   118.67 150.67
<none>               117.29 151.29
- blk            1   120.06 152.06
- ft             1   123.74 155.74
- x2p_percent    1   124.86 156.86
- fta            1   125.51 157.51
- x3pa           1   125.53 157.53
- e_fg_percent   1   126.40 158.40
- teamChemistry  1   127.02 159.02
- orb            1   127.53 159.53
- x3p_percent    1   128.07 160.07
- pf             1   131.83 163.83
- stl            1   148.16 180.16
- trb            1   154.99 186.99
- x2p            1   158.43 190.43
- tov            1   158.75 190.75
- x2pa           1   177.08 209.08

Step:  AIC=150.67
.outcome ~ x3pa + x3p_percent + x2p + x2pa + x2p_percent + e_fg_percent + 
    ft + fta + orb + trb + stl + blk + tov + pf + teamChemistry

                Df Deviance    AIC
<none>               118.67 150.67
- blk            1   121.43 151.43
- ft             1   123.79 153.79
- fta            1   125.95 155.95
- x2p_percent    1   126.19 156.19
- e_fg_percent   1   127.44 157.44
- teamChemistry  1   127.58 157.58
- orb            1   127.64 157.64
- x3p_percent    1   130.17 160.17
- pf             1   133.47 163.47
- x3pa           1   140.31 170.31
- stl            1   148.76 178.76
- trb            1   157.70 187.70
- tov            1   159.12 189.12
- x2p            1   165.42 195.42
- x2pa           1   177.18 207.18
Start:  AIC=148.99
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   103.08 147.08
- e_fg_percent   1   103.30 147.30
- fg_percent     1   103.35 147.35
- x2p_percent    1   104.20 148.20
- drb            1   104.32 148.32
- pf             1   104.89 148.89
<none>               102.99 148.99
- orb            1   105.45 149.45
- teamChemistry  1   105.89 149.89
- trb            1   106.39 150.39
- blk            1   109.14 153.15
- ast            1   110.40 154.40
- fg             1   111.82 155.82
- fga            1   115.69 159.69
- fta            1   115.74 159.74
- pts            1   118.21 162.21
- tov            1   123.75 167.75
- x3p            1   124.87 168.87
- ft             1   125.50 169.50
- x2p            1   132.80 176.80
- x3pa           1   137.05 181.05
- stl            1   138.79 182.79
- x2pa           1   146.13 190.13

Step:  AIC=147.08
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   103.32 145.32
- fg_percent     1   103.36 145.36
- x2p_percent    1   104.22 146.22
- drb            1   104.36 146.35
- pf             1   104.91 146.91
<none>               103.08 147.08
- orb            1   105.46 147.46
- teamChemistry  1   105.92 147.92
- trb            1   106.41 148.41
- blk            1   109.28 151.28
- ast            1   110.41 152.41
- fg             1   111.89 153.89
- fga            1   116.61 158.61
- fta            1   116.78 158.78
- pts            1   118.48 160.48
- tov            1   123.99 165.99
- x3p            1   125.58 167.58
- ft             1   127.17 169.17
- x2p            1   133.99 175.99
- x3pa           1   139.18 181.18
- stl            1   142.23 184.23
- x2pa           1   152.39 194.39

Step:  AIC=145.32
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + ft + fta + orb + drb + trb + ast + stl + blk + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   103.37 143.37
- x2p_percent    1   104.22 144.22
- drb            1   104.90 144.90
- pf             1   105.15 145.15
<none>               103.32 145.32
- teamChemistry  1   105.97 145.97
- orb            1   106.05 146.05
- trb            1   107.09 147.09
- blk            1   109.48 149.48
- ast            1   110.58 150.58
- fg             1   111.94 151.94
- fga            1   116.67 156.67
- pts            1   118.52 158.52
- fta            1   118.91 158.91
- tov            1   124.14 164.14
- x3p            1   125.97 165.97
- ft             1   128.59 168.59
- x2p            1   134.28 174.28
- x3pa           1   139.22 179.22
- stl            1   142.32 182.32
- x2pa           1   153.96 193.96

Step:  AIC=143.37
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + orb + drb + trb + ast + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- drb            1   104.90 142.90
- x2p_percent    1   105.21 143.21
- pf             1   105.35 143.35
<none>               103.37 143.37
- orb            1   106.07 144.07
- teamChemistry  1   106.12 144.12
- trb            1   107.12 145.12
- blk            1   109.58 147.58
- ast            1   110.91 148.91
- fg             1   112.75 150.75
- fga            1   116.90 154.90
- pts            1   118.64 156.64
- fta            1   119.09 157.09
- tov            1   124.16 162.16
- ft             1   128.75 166.75
- x3p            1   129.72 167.72
- x2p            1   135.01 173.01
- stl            1   142.67 180.67
- x3pa           1   143.01 181.01
- x2pa           1   153.96 191.96

Step:  AIC=142.9
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + x2p_percent + 
    ft + fta + orb + trb + ast + stl + blk + tov + pf + pts + 
    teamChemistry

                Df Deviance    AIC
<none>               104.90 142.90
- pf             1   107.55 143.55
- x2p_percent    1   108.50 144.50
- teamChemistry  1   109.73 145.73
- blk            1   110.90 146.90
- fg             1   113.93 149.93
- orb            1   115.80 151.80
- ast            1   115.96 151.96
- fta            1   119.17 155.17
- pts            1   119.94 155.94
- fga            1   120.08 156.07
- tov            1   125.67 161.67
- ft             1   128.76 164.76
- x3p            1   132.67 168.67
- x2p            1   135.55 171.55
- stl            1   145.03 181.03
- x3pa           1   150.11 186.11
- x2pa           1   156.77 192.77
- trb            1   160.33 196.33
Start:  AIC=149.4
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   103.44 147.44
- fg             1   103.59 147.59
- x2p_percent    1   103.74 147.74
- blk            1   104.06 148.06
- drb            1   104.46 148.46
- tov            1   104.97 148.97
- orb            1   105.25 149.25
<none>               103.40 149.40
- trb            1   106.27 150.26
- pf             1   106.58 150.58
- fg_percent     1   110.15 154.15
- fga            1   110.90 154.90
- e_fg_percent   1   111.05 155.04
- fta            1   115.58 159.58
- pts            1   116.61 160.61
- x3p            1   117.22 161.22
- stl            1   119.69 163.69
- x3p_percent    1   120.49 164.49
- teamChemistry  1   121.54 165.54
- ft             1   126.00 170.00
- x2p            1   127.71 171.71
- x3pa           1   139.54 183.54
- x2pa           1   153.67 197.67

Step:  AIC=147.44
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg             1   103.60 145.60
- x2p_percent    1   103.79 145.79
- blk            1   104.18 146.18
- drb            1   104.50 146.50
- tov            1   105.09 147.09
- orb            1   105.31 147.31
<none>               103.44 147.44
- trb            1   106.31 148.31
- pf             1   106.93 148.93
- fg_percent     1   110.68 152.68
- fga            1   110.92 152.92
- e_fg_percent   1   111.56 153.56
- fta            1   115.66 157.66
- pts            1   116.63 158.63
- x3p            1   119.80 161.80
- stl            1   120.68 162.68
- x3p_percent    1   120.81 162.81
- teamChemistry  1   121.66 163.66
- ft             1   126.01 168.01
- x2p            1   127.72 169.72
- x3pa           1   140.48 182.48
- x2pa           1   154.51 196.51

Step:  AIC=145.6
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + x2p_percent + e_fg_percent + ft + fta + orb + drb + 
    trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   103.86 143.86
- blk            1   104.34 144.34
- drb            1   104.51 144.51
- tov            1   105.12 145.12
- orb            1   105.32 145.32
<none>               103.60 145.60
- trb            1   106.33 146.33
- pf             1   107.79 147.79
- fg_percent     1   111.04 151.04
- e_fg_percent   1   111.82 151.82
- fga            1   112.86 152.86
- fta            1   115.66 155.66
- pts            1   116.86 156.86
- stl            1   120.68 160.68
- x3p_percent    1   121.06 161.06
- teamChemistry  1   121.71 161.71
- x3p            1   122.42 162.42
- ft             1   126.49 166.49
- x3pa           1   141.77 181.77
- x2p            1   158.56 198.56
- x2pa           1   161.83 201.83

Step:  AIC=143.86
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + drb + trb + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   104.70 142.70
- drb            1   104.92 142.92
- tov            1   105.29 143.29
- orb            1   105.80 143.80
<none>               103.86 143.86
- trb            1   106.83 144.83
- pf             1   108.56 146.56
- e_fg_percent   1   111.85 149.85
- fg_percent     1   112.02 150.02
- fga            1   112.87 150.87
- pts            1   116.97 154.97
- fta            1   117.29 155.29
- stl            1   120.75 158.75
- teamChemistry  1   121.80 159.80
- x3p_percent    1   122.56 160.56
- x3p            1   122.64 160.63
- ft             1   127.80 165.80
- x3pa           1   143.88 181.88
- x2p            1   161.20 199.20
- x2pa           1   163.21 201.21

Step:  AIC=142.7
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + drb + trb + stl + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- tov            1   105.79 141.79
- drb            1   105.82 141.82
- orb            1   106.68 142.68
<none>               104.70 142.70
- trb            1   107.64 143.65
- pf             1   109.10 145.10
- fga            1   112.88 148.88
- fg_percent     1   114.57 150.57
- e_fg_percent   1   114.78 150.78
- pts            1   117.01 153.01
- fta            1   117.76 153.76
- stl            1   120.82 156.82
- x3p            1   122.65 158.65
- x3p_percent    1   125.85 161.85
- ft             1   128.58 164.58
- teamChemistry  1   130.48 166.48
- x3pa           1   144.13 180.13
- x2p            1   161.48 197.48
- x2pa           1   163.58 199.58

Step:  AIC=141.79
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + drb + trb + stl + 
    pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   106.87 140.87
- orb            1   107.64 141.64
<none>               105.79 141.79
- trb            1   108.59 142.59
- pf             1   109.13 143.13
- fga            1   114.10 148.10
- e_fg_percent   1   115.89 149.89
- fg_percent     1   116.10 150.10
- pts            1   118.48 152.48
- stl            1   120.91 154.91
- fta            1   124.33 158.34
- x3p_percent    1   127.73 161.73
- x3p            1   130.43 164.43
- teamChemistry  1   134.70 168.70
- ft             1   140.95 174.95
- x3pa           1   149.16 183.16
- x2p            1   165.69 199.69
- x2pa           1   166.23 200.23

Step:  AIC=140.87
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + trb + stl + pf + pts + 
    teamChemistry

                Df Deviance    AIC
<none>               106.87 140.87
- orb            1   111.58 143.58
- pf             1   112.82 144.82
- fg_percent     1   117.71 149.71
- e_fg_percent   1   117.73 149.73
- fga            1   118.19 150.19
- pts            1   118.94 150.94
- stl            1   123.59 155.59
- fta            1   126.47 158.47
- x3p_percent    1   129.47 161.47
- x3p            1   130.44 162.44
- teamChemistry  1   137.26 169.26
- ft             1   142.29 174.29
- trb            1   149.07 181.07
- x3pa           1   151.16 183.16
- x2p            1   166.62 198.62
- x2pa           1   171.64 203.64
Start:  AIC=153.63
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   107.75 151.75
- e_fg_percent   1   107.81 151.81
- x2p_percent    1   107.93 151.93
- blk            1   108.12 152.12
- fg_percent     1   108.41 152.41
- x3p_percent    1   109.55 153.54
<none>               107.63 153.63
- drb            1   109.92 153.92
- teamChemistry  1   110.18 154.18
- orb            1   110.26 154.26
- trb            1   112.10 156.10
- fg             1   113.41 157.41
- fga            1   116.89 160.89
- tov            1   117.13 161.13
- pts            1   121.47 165.47
- fta            1   122.17 166.17
- ast            1   125.93 169.93
- x2p            1   128.06 172.06
- ft             1   133.00 177.00
- stl            1   138.24 182.24
- x3p            1   138.28 182.28
- x2pa           1   140.70 184.70
- x3pa           1   150.16 194.16

Step:  AIC=151.75
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   107.95 149.96
- x2p_percent    1   108.15 150.15
- blk            1   108.25 150.25
- fg_percent     1   108.70 150.70
- x3p_percent    1   109.70 151.70
<none>               107.75 151.75
- drb            1   110.11 152.11
- teamChemistry  1   110.34 152.34
- orb            1   110.42 152.42
- trb            1   112.26 154.26
- fg             1   113.47 155.47
- fga            1   117.08 159.08
- tov            1   117.94 159.94
- pts            1   121.55 163.55
- fta            1   123.08 165.08
- ast            1   126.35 168.35
- x2p            1   128.08 170.08
- ft             1   133.70 175.70
- x3p            1   138.28 180.28
- stl            1   139.46 181.46
- x2pa           1   140.90 182.90
- x3pa           1   150.21 192.21

Step:  AIC=149.95
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + drb + trb + ast + 
    stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   108.28 148.28
- blk            1   108.55 148.55
- fg_percent     1   109.48 149.48
- x3p_percent    1   109.94 149.94
<none>               107.95 149.96
- teamChemistry  1   110.34 150.34
- drb            1   110.66 150.66
- orb            1   110.98 150.98
- trb            1   113.00 153.00
- fg             1   113.76 153.76
- fga            1   117.47 157.47
- tov            1   117.97 157.97
- pts            1   123.23 163.23
- fta            1   124.83 164.83
- ast            1   127.20 167.20
- x2p            1   129.62 169.62
- ft             1   136.70 176.70
- x3p            1   139.60 179.60
- stl            1   140.82 180.82
- x2pa           1   145.65 185.65
- x3pa           1   151.16 191.16

Step:  AIC=148.28
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + ast + stl + blk + 
    tov + pts + teamChemistry

                Df Deviance    AIC
- blk            1   108.74 146.74
- fg_percent     1   110.22 148.22
<none>               108.28 148.28
- teamChemistry  1   110.48 148.48
- drb            1   111.00 149.00
- orb            1   111.26 149.26
- x3p_percent    1   111.41 149.41
- trb            1   113.27 151.27
- fg             1   113.76 151.76
- fga            1   117.60 155.60
- tov            1   118.02 156.02
- pts            1   123.25 161.25
- fta            1   125.28 163.28
- ast            1   127.29 165.29
- x2p            1   129.81 167.81
- ft             1   136.81 174.81
- x3p            1   140.71 178.71
- stl            1   141.10 179.10
- x2pa           1   146.16 184.16
- x3pa           1   154.53 192.53

Step:  AIC=146.74
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + ast + stl + tov + 
    pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   110.39 146.39
<none>               108.74 146.74
- drb            1   111.24 147.24
- orb            1   111.43 147.43
- x3p_percent    1   111.46 147.46
- teamChemistry  1   111.54 147.54
- trb            1   113.39 149.39
- fg             1   114.01 150.01
- fga            1   117.67 153.67
- tov            1   118.21 154.21
- pts            1   123.29 159.29
- fta            1   125.35 161.35
- ast            1   128.94 164.94
- x2p            1   130.67 166.67
- ft             1   136.84 172.84
- x3p            1   140.94 176.94
- stl            1   141.98 177.98
- x2pa           1   149.60 185.60
- x3pa           1   156.59 192.59

Step:  AIC=146.39
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + orb + drb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               110.39 146.39
- drb            1   112.56 146.56
- orb            1   112.71 146.71
- x3p_percent    1   113.69 147.69
- teamChemistry  1   113.69 147.69
- trb            1   114.55 148.55
- fg             1   115.77 149.77
- fga            1   118.31 152.31
- tov            1   121.20 155.20
- pts            1   123.86 157.86
- fta            1   125.57 159.57
- ast            1   130.07 164.07
- x2p            1   130.67 164.67
- ft             1   136.91 170.91
- x3p            1   141.01 175.01
- stl            1   144.71 178.71
- x2pa           1   150.53 184.53
- x3pa           1   156.83 190.83
Start:  AIC=148.89
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   102.94 146.94
- fg_percent     1   102.95 146.95
- x3p_percent    1   102.97 146.97
- e_fg_percent   1   103.06 147.06
- ast            1   103.20 147.20
- blk            1   103.48 147.49
- drb            1   103.93 147.93
- pf             1   104.48 148.48
<none>               102.89 148.89
- fg             1   105.46 149.46
- orb            1   105.58 149.58
- trb            1   105.62 149.62
- fga            1   106.57 150.57
- tov            1   107.89 151.88
- pts            1   109.19 153.19
- teamChemistry  1   110.97 154.97
- fta            1   115.51 159.51
- x3p            1   117.19 161.19
- x2p            1   118.15 162.15
- x2pa           1   118.28 162.28
- stl            1   122.48 166.49
- x3pa           1   122.80 166.80
- ft             1   125.34 169.34

Step:  AIC=146.94
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   102.97 144.97
- x3p_percent    1   103.09 145.09
- e_fg_percent   1   103.11 145.11
- ast            1   103.26 145.26
- blk            1   103.58 145.58
- drb            1   103.99 145.99
<none>               102.94 146.94
- pf             1   105.05 147.05
- orb            1   105.66 147.66
- trb            1   105.68 147.68
- fg             1   105.86 147.86
- fga            1   106.88 148.88
- tov            1   107.90 149.90
- pts            1   109.94 151.94
- teamChemistry  1   111.54 153.54
- fta            1   115.53 157.53
- x2p            1   118.23 160.23
- x2pa           1   118.57 160.57
- x3p            1   121.91 163.91
- stl            1   122.87 164.87
- ft             1   125.56 167.56
- x3pa           1   126.55 168.55

Step:  AIC=144.97
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    e_fg_percent + ft + fta + orb + drb + trb + ast + stl + blk + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   103.12 143.12
- ast            1   103.27 143.27
- blk            1   103.58 143.58
- drb            1   103.99 143.99
- e_fg_percent   1   104.04 144.04
<none>               102.97 144.97
- pf             1   105.06 145.06
- orb            1   105.67 145.66
- trb            1   105.70 145.70
- fg             1   105.88 145.88
- fga            1   106.88 146.88
- tov            1   107.90 147.90
- pts            1   110.52 150.52
- teamChemistry  1   111.79 151.79
- fta            1   115.54 155.54
- x2p            1   118.30 158.30
- x2pa           1   118.81 158.81
- x3p            1   121.93 161.93
- stl            1   124.01 164.01
- ft             1   125.88 165.88
- x3pa           1   126.66 166.66

Step:  AIC=143.12
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + drb + trb + ast + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- ast            1   103.47 141.47
- blk            1   103.68 141.68
- e_fg_percent   1   104.06 142.06
- drb            1   104.25 142.25
<none>               103.12 143.12
- pf             1   105.33 143.33
- trb            1   106.06 144.06
- orb            1   106.09 144.09
- fg             1   106.66 144.66
- fga            1   107.47 145.47
- tov            1   107.97 145.97
- pts            1   111.00 149.00
- teamChemistry  1   111.80 149.80
- fta            1   116.49 154.49
- x2p            1   119.42 157.42
- x2pa           1   119.61 157.62
- x3p            1   123.05 161.05
- stl            1   124.03 162.03
- ft             1   126.96 164.96
- x3pa           1   127.44 165.44

Step:  AIC=141.47
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + drb + trb + stl + blk + tov + pf + pts + 
    teamChemistry

                Df Deviance    AIC
- blk            1   104.36 140.35
- e_fg_percent   1   104.58 140.58
- drb            1   104.66 140.66
<none>               103.47 141.47
- pf             1   105.61 141.61
- trb            1   106.50 142.50
- orb            1   106.54 142.54
- fg             1   106.66 142.66
- fga            1   108.11 144.11
- tov            1   108.19 144.19
- pts            1   111.07 147.07
- teamChemistry  1   112.05 148.05
- fta            1   119.81 155.81
- x2p            1   120.39 156.39
- x2pa           1   121.49 157.49
- x3p            1   123.06 159.06
- stl            1   126.07 162.07
- x3pa           1   127.84 163.84
- ft             1   129.26 165.26

Step:  AIC=140.35
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + drb + trb + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   105.16 139.16
- e_fg_percent   1   105.23 139.23
<none>               104.36 140.35
- pf             1   106.67 140.67
- trb            1   106.77 140.77
- orb            1   106.85 140.85
- fg             1   107.69 141.69
- fga            1   108.26 142.26
- tov            1   108.67 142.68
- pts            1   111.19 145.19
- teamChemistry  1   113.53 147.53
- x2p            1   120.48 154.49
- fta            1   121.38 155.38
- x2pa           1   121.51 155.51
- x3p            1   123.13 157.13
- stl            1   126.45 160.45
- x3pa           1   127.98 161.98
- ft             1   131.20 165.20

Step:  AIC=139.16
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + e_fg_percent + 
    ft + fta + orb + trb + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   105.93 137.93
- pf             1   106.86 138.86
<none>               105.16 139.16
- fg             1   107.84 139.84
- fga            1   108.99 140.99
- tov            1   109.31 141.31
- pts            1   111.28 143.28
- teamChemistry  1   114.46 146.46
- x2p            1   120.50 152.50
- orb            1   121.67 153.67
- x2pa           1   121.94 153.94
- fta            1   122.36 154.36
- x3p            1   123.34 155.34
- stl            1   127.43 159.43
- x3pa           1   128.12 160.12
- ft             1   131.44 163.44
- trb            1   142.86 174.86

Step:  AIC=137.93
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   107.32 137.32
<none>               105.93 137.93
- fg             1   109.14 139.14
- fga            1   110.36 140.37
- tov            1   110.72 140.72
- pts            1   112.12 142.12
- teamChemistry  1   116.09 146.09
- x2p            1   120.71 150.71
- x2pa           1   122.14 152.15
- fta            1   122.59 152.59
- orb            1   122.91 152.91
- x3p            1   123.38 153.38
- x3pa           1   128.44 158.44
- stl            1   129.16 159.16
- ft             1   131.59 161.59
- trb            1   144.46 174.46

Step:  AIC=137.32
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               107.32 137.32
- fg             1   110.60 138.60
- fga            1   112.30 140.30
- pts            1   113.21 141.21
- tov            1   115.75 143.75
- teamChemistry  1   117.20 145.20
- x2p            1   122.80 150.80
- fta            1   123.36 151.36
- x3p            1   123.39 151.39
- orb            1   124.42 152.43
- x2pa           1   126.50 154.50
- stl            1   129.51 157.51
- x3pa           1   129.53 157.53
- ft             1   131.63 159.63
- trb            1   147.97 175.97
Start:  AIC=151.38
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   105.44 149.44
- fg_percent     1   105.59 149.59
- ast            1   105.61 149.61
- drb            1   106.17 150.17
- pf             1   106.73 150.73
- e_fg_percent   1   106.98 150.99
- orb            1   107.26 151.26
<none>               105.38 151.38
- trb            1   107.70 151.70
- x2p_percent    1   108.02 152.02
- teamChemistry  1   109.11 153.10
- fg             1   109.91 153.91
- x3p_percent    1   111.05 155.05
- pts            1   111.64 155.64
- fga            1   111.69 155.69
- x3p            1   113.29 157.29
- tov            1   115.37 159.37
- x3pa           1   119.58 163.58
- stl            1   123.42 167.42
- fta            1   126.71 170.71
- x2p            1   130.57 174.57
- ft             1   134.36 178.36
- x2pa           1   138.04 182.04

Step:  AIC=149.44
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   105.65 147.65
- ast            1   105.70 147.70
- drb            1   106.41 148.41
- pf             1   106.77 148.76
- e_fg_percent   1   106.98 148.99
<none>               105.44 149.44
- orb            1   107.66 149.66
- x2p_percent    1   108.04 150.04
- trb            1   108.18 150.18
- teamChemistry  1   109.15 151.15
- fg             1   110.05 152.05
- x3p_percent    1   111.08 153.07
- pts            1   112.66 154.66
- fga            1   112.67 154.67
- x3p            1   115.06 157.06
- tov            1   115.37 157.37
- x3pa           1   121.58 163.58
- stl            1   123.50 165.50
- fta            1   126.71 168.71
- x2p            1   132.73 174.73
- ft             1   134.37 176.37
- x2pa           1   140.43 182.43

Step:  AIC=147.65
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   105.89 145.88
- drb            1   106.65 146.65
- pf             1   106.90 146.90
<none>               105.65 147.65
- orb            1   107.85 147.85
- trb            1   108.43 148.43
- e_fg_percent   1   108.56 148.56
- teamChemistry  1   109.23 149.23
- x2p_percent    1   110.03 150.03
- fg             1   110.06 150.06
- x3p_percent    1   111.66 151.66
- pts            1   112.69 152.69
- fga            1   112.73 152.73
- x3p            1   115.06 155.06
- tov            1   115.41 155.41
- x3pa           1   121.59 161.59
- stl            1   125.03 165.03
- fta            1   127.19 167.19
- x2p            1   133.14 173.14
- ft             1   134.55 174.55
- x2pa           1   140.87 180.87

Step:  AIC=145.89
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   106.79 144.79
- pf             1   107.09 145.09
<none>               105.89 145.88
- orb            1   107.94 145.94
- trb            1   108.53 146.53
- e_fg_percent   1   108.70 146.70
- teamChemistry  1   109.43 147.43
- x2p_percent    1   110.10 148.10
- fg             1   111.22 149.22
- x3p_percent    1   111.72 149.72
- pts            1   112.76 150.76
- fga            1   112.76 150.76
- tov            1   115.47 153.47
- x3p            1   115.50 153.50
- x3pa           1   121.67 159.67
- stl            1   126.06 164.06
- fta            1   127.69 165.69
- x2p            1   133.27 171.27
- ft             1   135.12 173.12
- x2pa           1   141.19 179.19

Step:  AIC=144.79
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + trb + stl + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   108.23 144.23
<none>               106.79 144.79
- e_fg_percent   1   109.74 145.74
- fg             1   111.36 147.36
- teamChemistry  1   111.49 147.49
- x2p_percent    1   111.55 147.54
- x3p_percent    1   112.31 148.31
- pts            1   113.15 149.15
- fga            1   114.42 150.42
- orb            1   115.06 151.06
- tov            1   115.48 151.48
- x3p            1   115.76 151.76
- x3pa           1   123.69 159.69
- stl            1   127.68 163.68
- fta            1   130.07 166.07
- x2p            1   133.28 169.28
- ft             1   137.41 173.41
- trb            1   140.13 176.13
- x2pa           1   143.25 179.25

Step:  AIC=144.23
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + trb + stl + 
    tov + pts + teamChemistry

                Df Deviance    AIC
<none>               108.23 144.23
- e_fg_percent   1   110.51 144.51
- teamChemistry  1   112.05 146.05
- x2p_percent    1   112.32 146.32
- x3p_percent    1   113.30 147.30
- fg             1   113.62 147.62
- pts            1   115.14 149.14
- tov            1   115.65 149.65
- orb            1   116.48 150.48
- fga            1   116.65 150.65
- x3p            1   119.92 153.92
- x3pa           1   125.74 159.74
- fta            1   132.46 166.46
- stl            1   133.84 167.84
- x2p            1   134.69 168.69
- trb            1   140.84 174.84
- ft             1   142.48 176.48
- x2pa           1   143.52 177.52
Start:  AIC=169.43
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   123.43 167.43
- pf             1   123.47 167.47
- blk            1   123.53 167.53
- fg_percent     1   123.81 167.81
- e_fg_percent   1   124.63 168.63
- teamChemistry  1   124.73 168.73
- fg             1   124.88 168.88
<none>               123.43 169.43
- x2p_percent    1   126.33 170.32
- pts            1   127.68 171.68
- fga            1   127.75 171.75
- drb            1   127.92 171.92
- orb            1   129.23 173.23
- tov            1   129.47 173.47
- stl            1   129.72 173.72
- trb            1   129.82 173.82
- fta            1   130.43 174.43
- x3p_percent    1   131.28 175.28
- x3p            1   133.35 177.35
- ft             1   137.94 181.94
- x3pa           1   139.29 183.29
- x2p            1   139.50 183.50
- x2pa           1   154.17 198.17

Step:  AIC=167.43
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   123.47 165.47
- blk            1   123.54 165.54
- fg_percent     1   123.81 165.81
- e_fg_percent   1   124.63 166.63
- teamChemistry  1   124.73 166.73
- fg             1   125.17 167.17
<none>               123.43 167.43
- x2p_percent    1   126.34 168.34
- fga            1   127.85 169.85
- pts            1   128.01 170.01
- drb            1   128.04 170.04
- orb            1   129.40 171.40
- tov            1   129.47 171.47
- stl            1   129.77 171.77
- trb            1   129.93 171.93
- fta            1   130.48 172.48
- x3p_percent    1   131.34 173.34
- x3p            1   134.41 176.41
- ft             1   138.42 180.42
- x2p            1   139.69 181.69
- x3pa           1   140.57 182.57
- x2pa           1   154.83 196.83

Step:  AIC=165.47
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- blk            1   123.58 163.59
- fg_percent     1   123.83 163.82
- e_fg_percent   1   124.68 164.68
- teamChemistry  1   124.74 164.74
- fg             1   125.19 165.19
<none>               123.47 165.47
- x2p_percent    1   126.73 166.73
- fga            1   127.89 167.90
- pts            1   128.01 168.01
- drb            1   128.43 168.43
- orb            1   129.84 169.84
- stl            1   130.11 170.11
- trb            1   130.35 170.35
- fta            1   130.56 170.56
- tov            1   131.05 171.05
- x3p_percent    1   131.40 171.40
- x3p            1   134.51 174.51
- ft             1   139.71 179.71
- x2p            1   139.75 179.75
- x3pa           1   140.69 180.69
- x2pa           1   155.34 195.34

Step:  AIC=163.59
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   124.00 162.00
- teamChemistry  1   124.79 162.79
- e_fg_percent   1   124.81 162.81
- fg             1   125.31 163.31
<none>               123.58 163.59
- x2p_percent    1   126.74 164.74
- fga            1   128.36 166.36
- pts            1   128.38 166.38
- drb            1   128.60 166.60
- orb            1   130.06 168.06
- fta            1   130.56 168.56
- trb            1   130.59 168.59
- stl            1   130.64 168.64
- x3p_percent    1   131.50 169.50
- tov            1   131.56 169.56
- x3p            1   135.53 173.53
- ft             1   139.78 177.78
- x2p            1   140.06 178.06
- x3pa           1   142.49 180.49
- x2pa           1   155.69 193.69

Step:  AIC=162
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + tov + pts + teamChemistry

                Df Deviance    AIC
- teamChemistry  1   125.10 161.10
- fg             1   125.41 161.41
- e_fg_percent   1   125.54 161.54
<none>               124.00 162.00
- fga            1   128.38 164.38
- x2p_percent    1   128.51 164.51
- pts            1   128.58 164.58
- drb            1   128.96 164.96
- orb            1   130.35 166.35
- fta            1   130.90 166.90
- trb            1   130.97 166.97
- tov            1   131.85 167.85
- stl            1   132.35 168.35
- x3p_percent    1   132.85 168.85
- x3p            1   135.57 171.57
- ft             1   139.89 175.89
- x2p            1   140.12 176.12
- x3pa           1   142.58 178.58
- x2pa           1   156.34 192.34

Step:  AIC=161.1
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + tov + pts

               Df Deviance    AIC
- e_fg_percent  1   126.27 160.27
<none>              125.10 161.10
- fg            1   127.89 161.88
- x2p_percent   1   129.34 163.34
- pts           1   130.58 164.58
- fga           1   131.14 165.14
- drb           1   131.61 165.61
- fta           1   132.89 166.89
- orb           1   133.62 167.62
- stl           1   133.69 167.69
- trb           1   134.22 168.22
- x3p_percent   1   134.23 168.23
- tov           1   135.89 169.89
- x3p           1   137.30 171.30
- ft            1   142.48 176.48
- x3pa          1   144.19 178.19
- x2p           1   146.06 180.06
- x2pa          1   164.17 198.17

Step:  AIC=160.27
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + ft + fta + orb + drb + trb + stl + tov + pts

              Df Deviance    AIC
<none>             126.27 160.27
- fg           1   128.90 160.90
- x2p_percent  1   130.79 162.79
- pts          1   131.51 163.51
- fga          1   132.10 164.10
- drb          1   132.96 164.96
- fta          1   133.33 165.33
- x3p_percent  1   134.74 166.74
- orb          1   134.84 166.84
- stl          1   134.91 166.91
- trb          1   135.56 167.56
- tov          1   137.76 169.76
- x3p          1   138.84 170.84
- ft           1   143.00 175.00
- x3pa         1   146.40 178.40
- x2p          1   146.82 178.82
- x2pa         1   165.22 197.22
Start:  AIC=127.37
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- trb            1   81.367 125.37
- x3p_percent    1   81.379 125.38
- ast            1   81.399 125.40
- orb            1   81.478 125.48
- fg_percent     1   81.483 125.48
- pf             1   81.513 125.51
- e_fg_percent   1   81.713 125.71
- fg             1   81.749 125.75
- blk            1   81.855 125.86
- x2p_percent    1   81.882 125.88
- drb            1   81.914 125.91
- teamChemistry  1   83.340 127.34
<none>               81.366 127.37
- pts            1   85.519 129.52
- fga            1   86.637 130.64
- x3p            1   89.374 133.37
- tov            1   89.542 133.54
- fta            1   94.509 138.51
- x2p            1   98.875 142.88
- x3pa           1  101.671 145.67
- ft             1  102.313 146.31
- stl            1  116.476 160.48
- x2pa           1  118.802 162.80

Step:  AIC=125.37
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   81.380 123.38
- ast            1   81.399 123.40
- fg_percent     1   81.485 123.48
- pf             1   81.514 123.51
- e_fg_percent   1   81.715 123.72
- fg             1   81.773 123.77
- x2p_percent    1   81.901 123.90
- blk            1   81.926 123.93
<none>               81.367 125.37
- teamChemistry  1   83.443 125.44
- pts            1   85.619 127.62
- fga            1   86.709 128.71
- orb            1   88.050 130.05
- x3p            1   89.375 131.38
- tov            1   89.839 131.84
- fta            1   94.626 136.63
- x2p            1   99.255 141.25
- ft             1  102.342 144.34
- x3pa           1  102.657 144.66
- stl            1  116.858 158.86
- x2pa           1  118.824 160.82
- drb            1  126.560 168.56

Step:  AIC=123.38
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + ast + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   81.418 121.42
- fg_percent     1   81.486 121.49
- pf             1   81.528 121.53
- e_fg_percent   1   81.772 121.77
- fg             1   81.784 121.78
- x2p_percent    1   81.950 121.95
- blk            1   82.028 122.03
<none>               81.380 123.38
- teamChemistry  1   83.612 123.61
- pts            1   85.649 125.65
- fga            1   86.712 126.71
- orb            1   88.499 128.50
- x3p            1   89.429 129.43
- tov            1   90.039 130.04
- fta            1   94.658 134.66
- x2p            1   99.705 139.71
- ft             1  102.346 142.35
- x3pa           1  102.700 142.70
- x2pa           1  118.843 158.84
- stl            1  119.230 159.23
- drb            1  126.942 166.94

Step:  AIC=121.42
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + drb + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   81.525 119.53
- pf             1   81.545 119.55
- fg             1   81.785 119.78
- e_fg_percent   1   81.841 119.84
- blk            1   82.072 120.07
- x2p_percent    1   82.074 120.07
<none>               81.418 121.42
- teamChemistry  1   83.619 121.62
- pts            1   85.717 123.72
- fga            1   86.805 124.81
- orb            1   88.538 126.54
- x3p            1   89.588 127.59
- tov            1   90.074 128.07
- fta            1   96.014 134.01
- x2p            1  100.253 138.25
- x3pa           1  102.709 140.71
- ft             1  103.233 141.23
- x2pa           1  120.316 158.32
- stl            1  122.752 160.75
- drb            1  127.147 165.15

Step:  AIC=119.52
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + x2p_percent + 
    e_fg_percent + ft + fta + orb + drb + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- pf             1   81.602 117.60
- fg             1   81.802 117.80
- e_fg_percent   1   82.097 118.10
- blk            1   82.130 118.13
<none>               81.525 119.53
- teamChemistry  1   83.659 119.66
- x2p_percent    1   83.854 119.85
- pts            1   85.750 121.75
- fga            1   87.003 123.00
- orb            1   88.555 124.56
- x3p            1   89.616 125.62
- tov            1   90.181 126.18
- fta            1   96.022 132.02
- x2p            1  100.333 136.33
- ft             1  103.420 139.42
- x3pa           1  103.532 139.53
- x2pa           1  120.440 156.44
- stl            1  122.987 158.99
- drb            1  127.256 163.26

Step:  AIC=117.6
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + x2p_percent + 
    e_fg_percent + ft + fta + orb + drb + stl + blk + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- fg             1   81.867 115.87
- e_fg_percent   1   82.115 116.11
- blk            1   82.143 116.14
<none>               81.602 117.60
- teamChemistry  1   83.757 117.76
- x2p_percent    1   83.859 117.86
- pts            1   85.896 119.90
- fga            1   87.011 121.01
- orb            1   88.882 122.88
- x3p            1   90.695 124.69
- tov            1   91.584 125.58
- fta            1   97.359 131.36
- x2p            1  100.376 134.38
- x3pa           1  103.752 137.75
- ft             1  104.586 138.59
- x2pa           1  121.071 155.07
- stl            1  125.351 159.35
- drb            1  127.333 161.33

Step:  AIC=115.87
.outcome ~ fga + x3p + x3pa + x2p + x2pa + x2p_percent + e_fg_percent + 
    ft + fta + orb + drb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   82.232 114.23
- blk            1   82.353 114.35
<none>               81.867 115.87
- x2p_percent    1   84.075 116.08
- teamChemistry  1   84.633 116.63
- pts            1   85.927 117.93
- fga            1   88.382 120.38
- orb            1   90.724 122.72
- x3p            1   90.739 122.74
- tov            1   92.912 124.91
- fta            1   97.633 129.63
- x3pa           1  103.958 135.96
- ft             1  104.602 136.60
- x2p            1  110.297 142.30
- x2pa           1  123.885 155.88
- stl            1  125.370 157.37
- drb            1  127.405 159.41

Step:  AIC=114.23
.outcome ~ fga + x3p + x3pa + x2p + x2pa + x2p_percent + ft + 
    fta + orb + drb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- blk            1   82.931 112.93
<none>               82.232 114.23
- x2p_percent    1   84.919 114.92
- teamChemistry  1   85.239 115.24
- pts            1   86.264 116.26
- fga            1   88.781 118.78
- orb            1   90.868 120.87
- x3p            1   92.845 122.84
- tov            1   93.511 123.51
- fta            1   97.971 127.97
- ft             1  105.355 135.35
- x3pa           1  107.026 137.03
- x2p            1  111.496 141.50
- x2pa           1  124.636 154.64
- stl            1  125.564 155.56
- drb            1  127.912 157.91

Step:  AIC=112.93
.outcome ~ fga + x3p + x3pa + x2p + x2pa + x2p_percent + ft + 
    fta + orb + drb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               82.931 112.93
- x2p_percent    1   85.946 113.95
- teamChemistry  1   86.150 114.15
- pts            1   86.272 114.27
- fga            1   89.270 117.27
- orb            1   90.928 118.93
- x3p            1   92.893 120.89
- tov            1   93.679 121.68
- fta            1   98.516 126.52
- ft             1  105.574 133.57
- x3pa           1  107.681 135.68
- x2p            1  112.369 140.37
- stl            1  125.681 153.68
- x2pa           1  126.920 154.92
- drb            1  130.227 158.23
Start:  AIC=209.66
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   163.92 207.92
- fg             1   164.24 208.24
- pf             1   164.28 208.28
- drb            1   164.81 208.81
- e_fg_percent   1   165.16 209.16
- orb            1   165.36 209.36
- blk            1   165.64 209.64
<none>               163.66 209.66
- teamChemistry  1   165.76 209.76
- fg_percent     1   165.90 209.90
- ast            1   166.17 210.17
- fga            1   166.34 210.34
- tov            1   166.37 210.37
- trb            1   166.46 210.46
- x3p_percent    1   170.48 214.48
- fta            1   171.36 215.36
- stl            1   172.78 216.78
- pts            1   175.37 219.37
- x3p            1   178.10 222.10
- x2p            1   180.02 224.02
- ft             1   181.83 225.83
- x3pa           1   182.24 226.24
- x2pa           1   183.72 227.72

Step:  AIC=207.92
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg             1   164.72 206.72
- pf             1   164.89 206.89
- drb            1   165.06 207.06
- e_fg_percent   1   165.51 207.51
- orb            1   165.59 207.59
<none>               163.92 207.92
- blk            1   166.05 208.05
- teamChemistry  1   166.29 208.29
- ast            1   166.55 208.55
- tov            1   166.66 208.66
- trb            1   166.68 208.68
- fga            1   166.89 208.89
- fg_percent     1   167.71 209.71
- x3p_percent    1   170.58 212.58
- fta            1   171.37 213.37
- stl            1   173.83 215.83
- pts            1   176.02 218.02
- x2p            1   180.04 222.04
- x3p            1   181.80 223.80
- ft             1   182.11 224.11
- x2pa           1   183.88 225.88
- x3pa           1   185.53 227.53

Step:  AIC=206.72
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + drb + trb + ast + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   165.47 205.47
- pf             1   165.51 205.51
- orb            1   165.88 205.88
- e_fg_percent   1   166.55 206.55
- ast            1   166.61 206.61
<none>               164.72 206.72
- tov            1   166.90 206.90
- fga            1   166.90 206.90
- trb            1   166.90 206.90
- blk            1   166.99 206.99
- teamChemistry  1   167.41 207.41
- fg_percent     1   168.86 208.86
- x3p_percent    1   171.35 211.35
- fta            1   171.48 211.48
- stl            1   174.36 214.36
- pts            1   176.03 216.03
- ft             1   182.58 222.58
- x3p            1   183.16 223.16
- x2pa           1   184.19 224.19
- x2p            1   185.54 225.54
- x3pa           1   185.67 225.67

Step:  AIC=205.47
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + trb + ast + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   166.08 204.08
- e_fg_percent   1   167.28 205.28
- orb            1   167.34 205.34
<none>               165.47 205.47
- blk            1   167.73 205.73
- tov            1   167.82 205.82
- fga            1   167.94 205.94
- ast            1   167.96 205.96
- teamChemistry  1   168.56 206.56
- fg_percent     1   169.56 207.56
- x3p_percent    1   171.56 209.56
- fta            1   171.85 209.85
- stl            1   175.41 213.41
- pts            1   176.22 214.22
- ft             1   182.84 220.84
- x3p            1   183.67 221.67
- x2pa           1   184.75 222.75
- x2p            1   185.55 223.55
- x3pa           1   187.31 225.31
- trb            1   192.42 230.42

Step:  AIC=204.08
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + e_fg_percent + ft + fta + orb + trb + ast + stl + 
    blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   167.88 203.88
<none>               166.08 204.08
- blk            1   168.21 204.21
- orb            1   168.35 204.35
- fga            1   168.42 204.42
- ast            1   169.10 205.10
- teamChemistry  1   169.12 205.12
- fg_percent     1   169.99 205.99
- tov            1   171.17 207.17
- x3p_percent    1   171.98 207.98
- fta            1   172.03 208.03
- stl            1   175.54 211.54
- pts            1   177.73 213.73
- ft             1   182.84 218.84
- x3p            1   183.91 219.91
- x2pa           1   186.36 222.36
- x2p            1   187.03 223.03
- x3pa           1   187.68 223.68
- trb            1   194.87 230.87

Step:  AIC=203.88
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + orb + trb + ast + stl + blk + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- orb            1   169.73 203.73
<none>               167.88 203.88
- blk            1   169.96 203.96
- fga            1   170.15 204.15
- teamChemistry  1   170.23 204.23
- ast            1   171.54 205.54
- x3p_percent    1   172.42 206.42
- fg_percent     1   172.93 206.93
- tov            1   173.24 207.24
- fta            1   174.03 208.03
- stl            1   180.87 214.87
- pts            1   180.96 214.96
- ft             1   185.00 219.00
- x3p            1   186.65 220.65
- x2p            1   189.04 223.04
- x3pa           1   189.84 223.84
- x2pa           1   190.58 224.58
- trb            1   199.42 233.42

Step:  AIC=203.73
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- fga            1   171.21 203.21
- blk            1   171.47 203.47
<none>               169.73 203.73
- x3p_percent    1   173.52 205.52
- teamChemistry  1   173.92 205.92
- tov            1   174.41 206.41
- fg_percent     1   174.45 206.45
- ast            1   174.95 206.95
- fta            1   176.33 208.33
- pts            1   180.97 212.97
- stl            1   181.16 213.16
- ft             1   186.43 218.43
- x2p            1   189.31 221.31
- x3p            1   190.27 222.27
- x2pa           1   190.87 222.87
- x3pa           1   192.97 224.97
- trb            1   206.53 238.53

Step:  AIC=203.21
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- blk            1   172.26 202.26
<none>               171.21 203.21
- x3p_percent    1   174.65 204.65
- fg_percent     1   175.74 205.74
- tov            1   175.75 205.75
- teamChemistry  1   176.14 206.14
- fta            1   176.93 206.93
- ast            1   177.12 207.12
- stl            1   181.29 211.29
- pts            1   183.13 213.13
- ft             1   186.47 216.47
- x3p            1   190.54 220.54
- x2p            1   197.84 227.84
- x3pa           1   198.28 228.28
- trb            1   208.83 238.83
- x2pa           1   217.65 247.65

Step:  AIC=202.26
.outcome ~ fg_percent + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               172.26 202.26
- x3p_percent    1   175.60 203.60
- fg_percent     1   176.33 204.33
- tov            1   176.58 204.58
- teamChemistry  1   177.26 205.26
- fta            1   177.70 205.70
- ast            1   178.74 206.74
- stl            1   181.32 209.32
- pts            1   184.11 212.11
- ft             1   187.73 215.73
- x3p            1   190.82 218.82
- x2p            1   197.86 225.86
- x3pa           1   198.36 226.36
- trb            1   209.22 237.22
- x2pa           1   217.75 245.75
Start:  AIC=156.19
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   110.19 154.19
- e_fg_percent   1   110.28 154.28
- x2p_percent    1   110.51 154.51
- orb            1   110.57 154.57
- trb            1   110.59 154.59
- fg_percent     1   110.66 154.66
- x3p_percent    1   110.67 154.67
- ast            1   111.70 155.70
- pf             1   111.86 155.86
- blk            1   111.94 155.94
<none>               110.19 156.19
- teamChemistry  1   114.78 158.78
- fta            1   117.03 161.03
- fg             1   117.18 161.18
- pts            1   120.12 164.12
- tov            1   121.50 165.50
- fga            1   123.53 167.53
- ft             1   123.68 167.68
- x3p            1   130.64 174.64
- stl            1   131.12 175.12
- x2p            1   137.24 181.24
- x3pa           1   142.39 186.39
- x2pa           1   143.05 187.05

Step:  AIC=154.2
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   110.28 152.28
- x2p_percent    1   110.52 152.52
- fg_percent     1   110.67 152.67
- x3p_percent    1   110.67 152.68
- ast            1   111.77 153.77
- pf             1   111.87 153.87
- blk            1   111.94 153.94
<none>               110.19 154.19
- teamChemistry  1   115.08 157.08
- fta            1   117.25 159.25
- fg             1   117.27 159.27
- pts            1   120.32 162.32
- tov            1   121.64 163.64
- orb            1   123.54 165.54
- fga            1   123.67 165.67
- ft             1   124.09 166.09
- x3p            1   130.91 172.91
- stl            1   131.56 173.56
- x2p            1   138.39 180.39
- trb            1   142.33 184.33
- x3pa           1   142.52 184.52
- x2pa           1   143.17 185.17

Step:  AIC=152.28
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + trb + ast + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   110.65 150.65
- x3p_percent    1   110.69 150.69
- fg_percent     1   110.90 150.90
- pf             1   111.88 151.88
- ast            1   111.90 151.90
- blk            1   112.17 152.17
<none>               110.28 152.28
- teamChemistry  1   115.08 155.08
- fg             1   117.28 157.28
- fta            1   117.57 157.57
- pts            1   120.52 160.52
- tov            1   121.68 161.68
- orb            1   123.56 163.56
- fga            1   123.67 163.67
- ft             1   124.45 164.45
- x3p            1   131.19 171.19
- stl            1   133.61 173.61
- x2p            1   138.43 178.43
- x3pa           1   142.74 182.74
- trb            1   142.87 182.87
- x2pa           1   143.56 183.56

Step:  AIC=150.65
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + trb + ast + stl + blk + tov + 
    pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   110.96 148.96
- x3p_percent    1   111.58 149.58
- ast            1   112.02 150.01
- blk            1   112.36 150.35
- pf             1   112.42 150.42
<none>               110.65 150.65
- teamChemistry  1   115.27 153.27
- fg             1   117.41 155.41
- fta            1   118.38 156.38
- pts            1   120.58 158.58
- tov            1   121.85 159.85
- orb            1   123.75 161.75
- fga            1   123.76 161.76
- ft             1   124.57 162.57
- x3p            1   133.66 171.66
- stl            1   133.66 171.66
- x2p            1   138.51 176.51
- trb            1   142.89 180.89
- x2pa           1   144.02 182.02
- x3pa           1   144.98 182.98

Step:  AIC=148.96
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + orb + trb + ast + stl + blk + tov + pf + pts + 
    teamChemistry

                Df Deviance    AIC
- x3p_percent    1   111.86 147.86
- ast            1   112.38 148.38
- blk            1   112.61 148.60
- pf             1   112.81 148.81
<none>               110.96 148.96
- teamChemistry  1   115.98 151.98
- fg             1   117.90 153.90
- fta            1   118.47 154.47
- pts            1   121.47 157.47
- orb            1   124.05 160.05
- fga            1   124.10 160.10
- tov            1   124.53 160.53
- ft             1   124.64 160.65
- x3p            1   134.30 170.30
- stl            1   136.78 172.78
- x2p            1   138.51 174.51
- trb            1   143.82 179.82
- x2pa           1   144.04 180.04
- x3pa           1   145.02 181.02

Step:  AIC=147.86
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   113.20 147.20
- blk            1   113.32 147.32
<none>               111.86 147.86
- pf             1   114.00 148.00
- teamChemistry  1   117.47 151.47
- fg             1   118.26 152.26
- fta            1   118.66 152.66
- pts            1   122.22 156.22
- fga            1   124.13 158.13
- orb            1   124.54 158.54
- ft             1   124.93 158.93
- tov            1   126.58 160.58
- x3p            1   134.31 168.31
- stl            1   138.21 172.21
- x2p            1   138.55 172.55
- x2pa           1   144.10 178.10
- trb            1   145.14 179.14
- x3pa           1   145.17 179.17

Step:  AIC=147.2
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   114.42 146.42
- pf             1   114.75 146.75
<none>               113.20 147.20
- fg             1   118.26 150.26
- teamChemistry  1   118.55 150.55
- fta            1   119.69 151.69
- pts            1   122.83 154.83
- fga            1   124.97 156.97
- orb            1   125.21 157.21
- ft             1   125.40 157.40
- tov            1   126.85 158.85
- x3p            1   134.37 166.37
- x2p            1   138.76 170.76
- stl            1   141.33 173.33
- x2pa           1   144.59 176.59
- trb            1   145.15 177.15
- x3pa           1   145.26 177.26

Step:  AIC=146.42
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + stl + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   115.86 145.86
<none>               114.42 146.42
- fg             1   119.49 149.49
- teamChemistry  1   120.82 150.82
- fta            1   121.44 151.44
- pts            1   123.24 153.24
- fga            1   125.19 155.19
- orb            1   126.27 156.27
- ft             1   127.14 157.14
- tov            1   127.68 157.68
- x3p            1   134.51 164.51
- x2p            1   139.51 169.51
- stl            1   141.48 171.48
- x2pa           1   144.81 174.81
- trb            1   145.16 175.16
- x3pa           1   145.35 175.35

Step:  AIC=145.86
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               115.86 145.86
- fg             1   121.10 149.10
- teamChemistry  1   121.88 149.88
- fta            1   122.91 150.91
- pts            1   124.97 152.97
- orb            1   126.76 154.76
- fga            1   127.58 155.58
- tov            1   127.83 155.83
- ft             1   129.88 157.88
- x3p            1   138.37 166.37
- x2p            1   140.59 168.59
- trb            1   145.52 173.52
- x2pa           1   145.81 173.81
- stl            1   146.86 174.86
- x3pa           1   147.62 175.62
Start:  AIC=155.73
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   109.76 153.76
- ast            1   110.23 154.23
- x2p_percent    1   111.10 155.10
<none>               109.73 155.73
- e_fg_percent   1   112.02 156.02
- fg             1   112.04 156.04
- blk            1   113.21 157.21
- x3p_percent    1   114.11 158.11
- teamChemistry  1   115.28 159.28
- fta            1   115.55 159.55
- fg_percent     1   116.20 160.20
- drb            1   116.38 160.38
- fga            1   116.54 160.54
- orb            1   116.92 160.92
- tov            1   118.09 162.09
- trb            1   119.03 163.03
- pts            1   120.60 164.60
- ft             1   122.63 166.63
- x3p            1   126.49 170.49
- stl            1   131.40 175.40
- x3pa           1   131.66 175.66
- x2p            1   136.30 180.30
- x2pa           1   144.10 188.10

Step:  AIC=153.76
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- ast            1   110.26 152.26
- x2p_percent    1   111.11 153.11
<none>               109.76 153.76
- fg             1   112.04 154.04
- e_fg_percent   1   112.06 154.06
- blk            1   113.24 155.24
- x3p_percent    1   114.28 156.28
- teamChemistry  1   115.28 157.28
- fta            1   115.58 157.58
- fg_percent     1   116.22 158.22
- drb            1   116.38 158.38
- fga            1   116.69 158.69
- orb            1   116.94 158.94
- trb            1   119.05 161.05
- tov            1   119.16 161.16
- pts            1   120.92 162.92
- ft             1   122.80 164.80
- x3p            1   127.61 169.61
- x3pa           1   132.66 174.66
- stl            1   132.69 174.69
- x2p            1   136.30 178.30
- x2pa           1   144.10 186.10

Step:  AIC=152.26
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   111.50 151.50
<none>               110.26 152.26
- e_fg_percent   1   112.44 152.44
- fg             1   113.11 153.11
- blk            1   114.07 154.07
- x3p_percent    1   114.80 154.80
- fta            1   116.01 156.01
- drb            1   116.44 156.44
- fg_percent     1   116.54 156.54
- teamChemistry  1   116.61 156.61
- orb            1   116.96 156.96
- fga            1   117.57 157.57
- trb            1   119.10 159.10
- tov            1   119.21 159.21
- pts            1   121.71 161.71
- ft             1   123.47 163.47
- x3p            1   129.38 169.38
- stl            1   132.70 172.70
- x3pa           1   134.93 174.93
- x2p            1   137.14 177.14
- x2pa           1   146.70 186.70

Step:  AIC=151.5
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               111.50 151.50
- e_fg_percent   1   113.66 151.66
- fg             1   113.72 151.72
- blk            1   115.21 153.21
- x3p_percent    1   116.40 154.40
- fg_percent     1   116.55 154.55
- teamChemistry  1   117.47 155.47
- drb            1   118.14 156.14
- fga            1   118.15 156.15
- fta            1   118.70 156.71
- orb            1   118.77 156.77
- tov            1   119.60 157.60
- trb            1   120.93 158.93
- pts            1   122.41 160.41
- ft             1   126.11 164.10
- x3p            1   129.80 167.80
- stl            1   133.04 171.04
- x3pa           1   135.51 173.51
- x2p            1   137.47 175.47
- x2pa           1   148.93 186.93
Start:  AIC=161.99
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   116.03 160.03
- fg_percent     1   116.56 160.56
- pf             1   117.29 161.29
- fg             1   117.48 161.48
- x2p_percent    1   117.55 161.55
- x3p_percent    1   117.86 161.86
<none>               115.99 161.99
- ast            1   118.07 162.07
- drb            1   118.94 162.94
- teamChemistry  1   119.04 163.04
- orb            1   119.81 163.81
- blk            1   119.88 163.88
- trb            1   120.90 164.90
- fga            1   124.93 168.93
- tov            1   126.53 170.53
- x2p            1   130.58 174.58
- fta            1   131.35 175.35
- pts            1   137.04 181.04
- stl            1   138.62 182.62
- ft             1   141.74 185.74
- x2pa           1   143.79 187.79
- x3p            1   146.05 190.05
- x3pa           1   155.49 199.49

Step:  AIC=160.03
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + drb + trb + ast + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   117.02 159.02
- pf             1   117.30 159.29
- fg             1   117.56 159.56
- x2p_percent    1   117.63 159.63
<none>               116.03 160.03
- ast            1   118.20 160.20
- drb            1   119.25 161.25
- teamChemistry  1   119.27 161.27
- x3p_percent    1   119.47 161.47
- blk            1   120.05 162.05
- orb            1   120.18 162.18
- trb            1   121.38 163.38
- fga            1   125.30 167.30
- tov            1   126.61 168.61
- x2p            1   130.93 172.93
- fta            1   132.40 174.40
- pts            1   139.82 181.82
- stl            1   141.10 183.10
- ft             1   143.28 185.28
- x2pa           1   145.58 187.58
- x3p            1   146.60 188.60
- x3pa           1   155.61 197.61

Step:  AIC=159.02
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + ft + fta + orb + drb + trb + ast + stl + blk + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   117.88 157.88
- fg             1   118.28 158.28
<none>               117.02 159.02
- pf             1   119.46 159.46
- ast            1   119.60 159.60
- teamChemistry  1   119.61 159.61
- drb            1   120.65 160.65
- blk            1   120.88 160.88
- orb            1   121.77 161.77
- trb            1   122.91 162.91
- x3p_percent    1   123.12 163.12
- fga            1   125.51 165.51
- tov            1   129.03 169.03
- x2p            1   131.46 171.46
- fta            1   134.43 174.43
- pts            1   140.81 180.81
- stl            1   141.45 181.45
- ft             1   143.45 183.45
- x2pa           1   146.24 186.24
- x3p            1   147.51 187.51
- x3pa           1   159.75 199.75

Step:  AIC=157.88
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + orb + drb + trb + ast + stl + blk + tov + pf + 
    pts + teamChemistry

                Df Deviance    AIC
- fg             1   119.22 157.22
<none>               117.88 157.88
- teamChemistry  1   120.00 158.00
- pf             1   120.28 158.28
- ast            1   120.95 158.95
- drb            1   121.37 159.37
- blk            1   121.39 159.39
- orb            1   122.49 160.49
- trb            1   123.59 161.59
- x3p_percent    1   125.17 163.18
- fga            1   126.35 164.35
- tov            1   129.43 167.43
- x2p            1   134.52 172.52
- fta            1   135.88 173.88
- pts            1   141.01 179.01
- stl            1   141.74 179.74
- ft             1   145.07 183.07
- x3p            1   148.34 186.34
- x2pa           1   151.22 189.22
- x3pa           1   160.87 198.87

Step:  AIC=157.22
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + ft + 
    fta + orb + drb + trb + ast + stl + blk + tov + pf + pts + 
    teamChemistry

                Df Deviance    AIC
<none>               119.22 157.22
- ast            1   121.27 157.27
- drb            1   121.51 157.51
- pf             1   121.67 157.67
- teamChemistry  1   121.85 157.85
- orb            1   122.52 158.52
- blk            1   122.92 158.92
- trb            1   123.60 159.60
- x3p_percent    1   126.48 162.48
- fga            1   127.17 163.17
- tov            1   129.43 165.43
- fta            1   135.89 171.89
- stl            1   142.08 178.08
- pts            1   143.05 179.05
- x2p            1   144.97 180.97
- ft             1   146.86 182.86
- x3p            1   152.95 188.95
- x2pa           1   153.38 189.38
- x3pa           1   161.68 197.68
Start:  AIC=165.83
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   119.84 163.84
- fg             1   119.88 163.88
- e_fg_percent   1   120.23 164.23
- x2p_percent    1   120.33 164.33
- ast            1   120.55 164.55
- drb            1   120.60 164.60
- orb            1   120.78 164.78
- blk            1   120.94 164.94
- fg_percent     1   121.32 165.32
- trb            1   121.63 165.63
<none>               119.83 165.83
- fga            1   122.64 166.64
- tov            1   123.44 167.44
- x3p_percent    1   124.02 168.01
- pts            1   127.54 171.54
- stl            1   130.39 174.39
- fta            1   130.51 174.51
- teamChemistry  1   132.53 176.53
- x3p            1   133.52 177.52
- x2p            1   135.19 179.19
- x3pa           1   138.63 182.63
- ft             1   140.59 184.59
- x2pa           1   145.59 189.59

Step:  AIC=163.84
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- fg             1   119.88 161.88
- e_fg_percent   1   120.25 162.25
- x2p_percent    1   120.33 162.33
- ast            1   120.56 162.56
- drb            1   120.60 162.60
- orb            1   120.79 162.79
- blk            1   120.95 162.95
- fg_percent     1   121.32 163.32
- trb            1   121.64 163.64
<none>               119.84 163.84
- fga            1   122.65 164.65
- x3p_percent    1   124.06 166.06
- tov            1   124.36 166.36
- pts            1   127.57 169.57
- fta            1   130.52 172.52
- stl            1   130.64 172.64
- teamChemistry  1   132.61 174.61
- x3p            1   133.74 175.74
- x2p            1   135.22 177.22
- x3pa           1   138.63 180.63
- ft             1   140.66 182.66
- x2pa           1   146.23 188.23

Step:  AIC=161.88
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + x2p_percent + e_fg_percent + ft + fta + orb + drb + 
    trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   120.28 160.28
- x2p_percent    1   120.34 160.34
- drb            1   120.61 160.61
- ast            1   120.75 160.75
- orb            1   120.82 160.82
- blk            1   121.00 161.00
- fg_percent     1   121.32 161.32
- trb            1   121.71 161.71
<none>               119.88 161.88
- fga            1   123.60 163.60
- x3p_percent    1   124.07 164.07
- tov            1   124.75 164.75
- pts            1   128.03 168.03
- fta            1   130.58 170.58
- stl            1   130.68 170.68
- teamChemistry  1   133.09 173.09
- x3p            1   137.06 177.06
- x3pa           1   140.59 180.59
- ft             1   141.44 181.44
- x2pa           1   148.57 188.57
- x2p            1   149.50 189.50

Step:  AIC=160.27
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + x2p_percent + ft + fta + orb + drb + trb + ast + stl + 
    blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   120.65 158.65
- ast            1   121.02 159.02
- drb            1   121.21 159.21
- orb            1   121.45 159.45
- blk            1   121.61 159.60
- fg_percent     1   121.96 159.96
<none>               120.28 160.28
- trb            1   122.48 160.48
- fga            1   123.68 161.68
- x3p_percent    1   125.06 163.06
- tov            1   125.83 163.83
- pts            1   128.40 166.40
- fta            1   130.94 168.94
- stl            1   132.86 170.86
- teamChemistry  1   133.09 171.09
- x3p            1   137.16 175.16
- x3pa           1   140.59 178.59
- ft             1   141.70 179.70
- x2pa           1   149.19 187.19
- x2p            1   149.70 187.70

Step:  AIC=158.65
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + orb + drb + trb + ast + stl + blk + tov + 
    pts + teamChemistry

                Df Deviance    AIC
- ast            1   121.36 157.35
- drb            1   121.65 157.65
- blk            1   121.70 157.70
- orb            1   121.90 157.90
<none>               120.65 158.65
- trb            1   122.90 158.90
- fg_percent     1   123.42 159.42
- fga            1   123.77 159.77
- tov            1   125.83 161.83
- x3p_percent    1   127.42 163.42
- pts            1   128.40 164.40
- fta            1   132.76 168.76
- stl            1   132.90 168.90
- teamChemistry  1   133.12 169.12
- x3p            1   139.67 175.67
- x3pa           1   142.85 178.85
- ft             1   143.31 179.31
- x2pa           1   150.86 186.86
- x2p            1   151.43 187.43

Step:  AIC=157.35
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + orb + drb + trb + stl + blk + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- blk            1   122.11 156.11
- drb            1   122.16 156.16
- orb            1   122.38 156.38
- trb            1   123.33 157.33
<none>               121.36 157.35
- fg_percent     1   123.70 157.70
- fga            1   123.98 157.98
- tov            1   126.54 160.54
- x3p_percent    1   128.43 162.43
- pts            1   129.05 163.05
- fta            1   132.76 166.76
- stl            1   132.92 166.92
- teamChemistry  1   134.43 168.43
- x3p            1   140.33 174.33
- x3pa           1   143.25 177.25
- ft             1   143.41 177.41
- x2pa           1   150.87 184.87
- x2p            1   152.70 186.70

Step:  AIC=156.11
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + orb + drb + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- drb            1   122.84 154.84
- orb            1   123.03 155.03
- trb            1   123.88 155.88
- fga            1   124.09 156.09
<none>               122.11 156.11
- fg_percent     1   124.62 156.62
- tov            1   126.82 158.82
- x3p_percent    1   128.74 160.74
- pts            1   129.06 161.06
- stl            1   133.06 165.06
- fta            1   133.36 165.36
- teamChemistry  1   135.57 167.57
- x3p            1   140.38 172.38
- x3pa           1   143.31 175.31
- ft             1   143.76 175.76
- x2pa           1   151.05 183.05
- x2p            1   152.75 184.75

Step:  AIC=154.85
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + orb + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- orb            1   123.59 153.59
<none>               122.84 154.84
- fg_percent     1   125.27 155.27
- fga            1   126.15 156.15
- tov            1   127.24 157.24
- x3p_percent    1   128.77 158.77
- pts            1   129.24 159.24
- fta            1   133.83 163.83
- stl            1   134.46 164.46
- teamChemistry  1   137.39 167.39
- x3p            1   140.85 170.85
- ft             1   143.84 173.84
- x3pa           1   146.35 176.35
- trb            1   147.60 177.60
- x2p            1   153.18 183.18
- x2pa           1   153.55 183.55

Step:  AIC=153.59
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               123.59 153.59
- fg_percent     1   125.95 153.95
- fga            1   126.42 154.42
- tov            1   127.53 155.53
- x3p_percent    1   128.97 156.97
- pts            1   129.24 157.24
- stl            1   134.64 162.64
- fta            1   136.03 164.03
- x3p            1   141.89 169.89
- teamChemistry  1   141.94 169.94
- ft             1   145.89 173.89
- x3pa           1   147.62 175.62
- x2p            1   153.24 181.24
- x2pa           1   153.59 181.59
- trb            1   153.64 181.64
Start:  AIC=171.88
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   126.00 170.00
- ast            1   126.09 170.09
<none>               125.88 171.88
- fg_percent     1   128.06 172.06
- teamChemistry  1   128.38 172.38
- drb            1   128.40 172.40
- fg             1   130.28 174.28
- orb            1   130.39 174.39
- pf             1   130.59 174.59
- x3p_percent    1   130.67 174.67
- blk            1   130.91 174.91
- trb            1   131.12 175.12
- pts            1   131.47 175.47
- e_fg_percent   1   131.80 175.80
- fta            1   136.09 180.09
- x3p            1   137.33 181.33
- fga            1   138.13 182.13
- tov            1   143.40 187.40
- ft             1   143.41 187.41
- x3pa           1   146.14 190.14
- x2p            1   151.37 195.37
- stl            1   160.46 204.46
- x2pa           1   164.04 208.04

Step:  AIC=169.99
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   126.31 168.31
<none>               126.00 170.00
- drb            1   128.46 170.46
- fg_percent     1   128.52 170.52
- teamChemistry  1   128.79 170.79
- orb            1   130.45 172.45
- blk            1   130.99 172.99
- x3p_percent    1   131.08 173.08
- trb            1   131.17 173.17
- pf             1   131.35 173.35
- pts            1   131.49 173.49
- e_fg_percent   1   131.84 173.84
- fg             1   132.28 174.28
- fta            1   136.80 178.80
- fga            1   139.24 181.24
- x3p            1   141.56 183.56
- ft             1   143.74 185.74
- tov            1   145.16 187.16
- x3pa           1   151.40 193.40
- x2p            1   151.69 193.69
- stl            1   161.28 203.28
- x2pa           1   164.39 206.39

Step:  AIC=168.31
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
<none>               126.31 168.31
- teamChemistry  1   128.85 168.85
- fg_percent     1   128.91 168.91
- drb            1   129.22 169.22
- x3p_percent    1   131.35 171.35
- orb            1   131.38 171.38
- pts            1   131.81 171.81
- pf             1   131.94 171.94
- blk            1   132.13 172.13
- trb            1   132.20 172.20
- e_fg_percent   1   132.31 172.31
- fg             1   132.39 172.39
- fta            1   138.94 178.94
- fga            1   139.34 179.34
- x3p            1   141.57 181.57
- ft             1   145.28 185.28
- tov            1   145.44 185.44
- x3pa           1   151.44 191.44
- x2p            1   152.35 192.35
- stl            1   164.98 204.98
- x2pa           1   165.69 205.69
Start:  AIC=162.37
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   116.38 160.38
- drb            1   116.54 160.54
- orb            1   116.88 160.88
- e_fg_percent   1   117.00 161.00
- trb            1   117.48 161.48
- blk            1   117.98 161.99
- teamChemistry  1   118.34 162.34
<none>               116.37 162.37
- pf             1   118.49 162.49
- fg_percent     1   118.77 162.77
- x3p_percent    1   118.86 162.86
- fg             1   118.95 162.95
- x2p_percent    1   124.56 168.56
- fga            1   124.92 168.92
- pts            1   125.26 169.26
- tov            1   127.05 171.05
- x3p            1   130.62 174.62
- fta            1   133.78 177.78
- stl            1   140.87 184.87
- ft             1   141.97 185.97
- x3pa           1   144.20 188.20
- x2p            1   148.19 192.19
- x2pa           1   167.03 211.03

Step:  AIC=160.38
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   116.55 158.55
- orb            1   116.88 158.88
- e_fg_percent   1   117.01 159.01
- trb            1   117.48 159.48
- blk            1   118.08 160.08
<none>               116.38 160.38
- teamChemistry  1   118.39 160.38
- pf             1   118.51 160.51
- fg_percent     1   118.84 160.84
- x3p_percent    1   118.86 160.86
- fg             1   119.69 161.69
- fga            1   124.98 166.98
- x2p_percent    1   125.14 167.14
- pts            1   125.28 167.28
- tov            1   127.06 169.06
- x3p            1   132.20 174.20
- fta            1   134.26 176.26
- ft             1   142.00 184.00
- stl            1   142.17 184.17
- x3pa           1   144.80 186.80
- x2p            1   148.27 190.27
- x2pa           1   167.47 209.47

Step:  AIC=158.55
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    trb + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   117.14 157.14
- blk            1   118.11 158.11
- teamChemistry  1   118.39 158.39
<none>               116.55 158.55
- fg_percent     1   118.86 158.86
- x3p_percent    1   118.89 158.90
- pf             1   118.90 158.90
- fg             1   119.72 159.72
- orb            1   121.68 161.68
- fga            1   125.02 165.02
- x2p_percent    1   125.14 165.14
- pts            1   125.36 165.36
- tov            1   127.27 167.27
- x3p            1   132.36 172.36
- fta            1   134.44 174.44
- stl            1   142.18 182.18
- ft             1   142.22 182.22
- x3pa           1   144.81 184.81
- x2p            1   149.70 189.70
- trb            1   155.07 195.07
- x2pa           1   167.69 207.69

Step:  AIC=157.14
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + trb + stl + blk + 
    tov + pf + pts + teamChemistry

                Df Deviance    AIC
- blk            1   118.27 156.27
- teamChemistry  1   118.75 156.75
- fg_percent     1   119.10 157.10
<none>               117.14 157.14
- pf             1   119.72 157.72
- fg             1   120.28 158.28
- orb            1   122.20 160.20
- x3p_percent    1   123.80 161.80
- fga            1   125.14 163.14
- pts            1   125.40 163.40
- x2p_percent    1   126.81 164.81
- tov            1   127.59 165.59
- x3p            1   132.66 170.66
- fta            1   134.54 172.54
- ft             1   142.25 180.25
- stl            1   142.29 180.29
- x3pa           1   144.83 182.83
- x2p            1   149.70 187.70
- trb            1   156.32 194.32
- x2pa           1   169.73 207.73

Step:  AIC=156.27
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + trb + stl + tov + 
    pf + pts + teamChemistry

                Df Deviance    AIC
- teamChemistry  1   120.02 156.02
<none>               118.27 156.27
- fg_percent     1   120.37 156.37
- pf             1   120.47 156.47
- fg             1   121.01 157.01
- orb            1   123.17 159.17
- fga            1   125.14 161.14
- pts            1   125.73 161.73
- x3p_percent    1   126.90 162.90
- tov            1   127.78 163.78
- x2p_percent    1   128.34 164.34
- x3p            1   132.85 168.85
- fta            1   137.48 173.48
- stl            1   142.82 178.82
- ft             1   144.74 180.74
- x3pa           1   145.13 181.13
- x2p            1   149.84 185.84
- trb            1   157.83 193.83
- x2pa           1   171.03 207.03

Step:  AIC=156.02
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + trb + stl + tov + 
    pf + pts

              Df Deviance    AIC
<none>             120.02 156.02
- fg_percent   1   122.35 156.35
- pf           1   122.57 156.57
- fg           1   122.70 156.70
- orb          1   123.77 157.77
- fga          1   125.86 159.86
- pts          1   125.88 159.88
- x3p_percent  1   127.16 161.16
- x2p_percent  1   129.48 163.48
- tov          1   131.26 165.26
- x3p          1   132.91 166.91
- fta          1   138.56 172.56
- stl          1   142.97 176.97
- ft           1   145.18 179.18
- x3pa         1   145.35 179.35
- x2p          1   149.99 183.99
- trb          1   158.44 192.44
- x2pa         1   171.91 205.91
Start:  AIC=157.61
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- drb            1   111.67 155.67
- pf             1   111.67 155.67
- fg_percent     1   111.83 155.83
- orb            1   111.83 155.83
- fg             1   112.33 156.33
- blk            1   112.33 156.34
- trb            1   112.34 156.34
- x2p_percent    1   112.38 156.38
- e_fg_percent   1   112.45 156.45
<none>               111.61 157.61
- teamChemistry  1   113.99 157.99
- ast            1   114.20 158.20
- x3p_percent    1   114.34 158.34
- tov            1   118.00 162.00
- fga            1   119.56 163.56
- pts            1   123.09 167.09
- fta            1   123.40 167.40
- x3p            1   127.71 171.71
- x2p            1   129.44 173.44
- ft             1   134.27 178.27
- stl            1   135.50 179.50
- x3pa           1   140.53 184.53
- x2pa           1   151.24 195.24

Step:  AIC=155.67
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   111.72 153.72
- fg_percent     1   111.92 153.93
- fg             1   112.34 154.34
- x2p_percent    1   112.40 154.40
- blk            1   112.49 154.49
- e_fg_percent   1   112.56 154.56
<none>               111.67 155.67
- x3p_percent    1   114.34 156.34
- ast            1   114.42 156.42
- teamChemistry  1   114.59 156.59
- orb            1   114.92 156.92
- tov            1   118.11 160.11
- fga            1   119.67 161.67
- pts            1   123.11 165.11
- fta            1   123.50 165.50
- x3p            1   127.72 169.72
- x2p            1   129.70 171.70
- ft             1   134.68 176.68
- stl            1   135.73 177.73
- x3pa           1   140.62 182.62
- x2pa           1   151.29 193.29
- trb            1   152.22 194.22

Step:  AIC=153.72
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   111.97 151.97
- x2p_percent    1   112.40 152.40
- fg             1   112.42 152.42
- blk            1   112.54 152.54
- e_fg_percent   1   112.56 152.56
<none>               111.72 153.72
- x3p_percent    1   114.36 154.35
- ast            1   114.42 154.42
- teamChemistry  1   114.69 154.69
- orb            1   114.95 154.95
- tov            1   119.62 159.62
- fga            1   120.15 160.15
- pts            1   123.31 163.31
- fta            1   124.39 164.39
- x3p            1   128.80 168.80
- x2p            1   130.04 170.04
- stl            1   136.78 176.78
- ft             1   137.32 177.32
- x3pa           1   140.94 180.94
- x2pa           1   151.48 191.48
- trb            1   152.29 192.29

Step:  AIC=151.98
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + e_fg_percent + ft + fta + orb + trb + ast + 
    stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- fg             1   112.55 150.55
- e_fg_percent   1   112.69 150.69
- blk            1   112.78 150.78
- x2p_percent    1   113.26 151.26
<none>               111.97 151.97
- x3p_percent    1   114.40 152.40
- teamChemistry  1   114.80 152.80
- ast            1   115.02 153.02
- orb            1   115.04 153.04
- tov            1   119.64 157.63
- fga            1   120.18 158.18
- pts            1   123.50 161.50
- fta            1   124.52 162.52
- x3p            1   129.04 167.04
- x2p            1   130.05 168.05
- stl            1   137.21 175.21
- ft             1   137.48 175.48
- x3pa           1   141.77 179.77
- trb            1   152.75 190.75
- x2pa           1   152.92 190.92

Step:  AIC=150.55
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + x2p_percent + 
    e_fg_percent + ft + fta + orb + trb + ast + stl + blk + tov + 
    pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   113.41 149.41
- blk            1   113.47 149.47
- x2p_percent    1   114.07 150.07
<none>               112.55 150.55
- x3p_percent    1   114.94 150.94
- orb            1   115.04 151.04
- ast            1   115.06 151.06
- teamChemistry  1   115.78 151.78
- tov            1   119.88 155.88
- fga            1   121.27 157.27
- pts            1   123.57 159.57
- fta            1   124.86 160.86
- x3p            1   129.54 165.54
- stl            1   137.26 173.26
- ft             1   137.66 173.66
- x2p            1   140.97 176.97
- x3pa           1   141.83 177.83
- trb            1   152.90 188.90
- x2pa           1   154.67 190.67

Step:  AIC=149.41
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + x2p_percent + 
    ft + fta + orb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- blk            1   113.91 147.91
- x2p_percent    1   114.34 148.34
- x3p_percent    1   115.03 149.03
- orb            1   115.16 149.16
<none>               113.41 149.41
- ast            1   116.56 150.56
- teamChemistry  1   116.71 150.71
- tov            1   121.55 155.55
- fga            1   122.61 156.60
- fta            1   124.86 158.86
- pts            1   126.68 160.68
- ft             1   137.89 171.89
- stl            1   139.43 173.43
- x3p            1   140.25 174.25
- x2p            1   141.54 175.54
- trb            1   155.32 189.32
- x2pa           1   155.43 189.43
- x3pa           1   155.89 189.89

Step:  AIC=147.91
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + x2p_percent + 
    ft + fta + orb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   114.81 146.81
- x3p_percent    1   115.27 147.27
- orb            1   115.66 147.66
<none>               113.91 147.91
- ast            1   116.64 148.63
- teamChemistry  1   116.88 148.88
- tov            1   122.53 154.53
- fga            1   124.79 156.79
- fta            1   125.47 157.47
- pts            1   128.37 160.37
- ft             1   138.24 170.24
- stl            1   141.62 173.62
- x3p            1   142.36 174.36
- x2p            1   143.95 175.95
- x2pa           1   158.03 190.03
- trb            1   159.16 191.16
- x3pa           1   159.37 191.37

Step:  AIC=146.81
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + ft + 
    fta + orb + trb + ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   115.93 145.93
- orb            1   116.38 146.38
<none>               114.81 146.81
- ast            1   117.46 147.46
- teamChemistry  1   118.67 148.67
- tov            1   124.32 154.32
- fta            1   125.47 155.47
- fga            1   125.65 155.65
- pts            1   129.79 159.79
- ft             1   138.25 168.25
- x3p            1   142.61 172.61
- x2p            1   143.95 173.95
- stl            1   144.52 174.52
- x2pa           1   158.13 188.13
- x3pa           1   159.43 189.43
- trb            1   160.12 190.12

Step:  AIC=145.93
.outcome ~ fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + trb + 
    ast + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- orb            1   116.95 144.95
<none>               115.93 145.93
- teamChemistry  1   119.64 147.64
- ast            1   119.85 147.85
- fta            1   126.58 154.57
- tov            1   128.06 156.06
- fga            1   129.20 157.20
- pts            1   133.65 161.65
- ft             1   140.24 168.24
- x3p            1   145.06 173.06
- x2p            1   146.60 174.60
- stl            1   150.85 178.85
- x2pa           1   164.28 192.28
- x3pa           1   165.64 193.64
- trb            1   166.52 194.52

Step:  AIC=144.95
.outcome ~ fga + x3p + x3pa + x2p + x2pa + ft + fta + trb + ast + 
    stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               116.95 144.95
- ast            1   121.93 147.93
- teamChemistry  1   122.30 148.30
- fta            1   128.07 154.07
- tov            1   128.49 154.49
- fga            1   129.22 155.22
- pts            1   134.01 160.01
- ft             1   141.37 167.37
- x3p            1   145.51 171.51
- x2p            1   146.62 172.62
- stl            1   151.60 177.60
- x2pa           1   164.51 190.51
- x3pa           1   166.46 192.46
- trb            1   173.58 199.58
Start:  AIC=160.33
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   114.36 158.35
- ast            1   114.37 158.37
- x2p_percent    1   114.41 158.41
- e_fg_percent   1   114.48 158.49
- fg_percent     1   114.55 158.55
- x3p_percent    1   114.84 158.84
<none>               114.33 160.33
- fga            1   116.91 160.91
- teamChemistry  1   117.40 161.40
- blk            1   118.24 162.24
- fg             1   118.43 162.43
- pts            1   118.74 162.74
- drb            1   119.74 163.74
- tov            1   120.10 164.10
- orb            1   120.35 164.35
- trb            1   121.79 165.79
- fta            1   124.63 168.63
- stl            1   134.26 178.26
- x2p            1   135.99 179.99
- x3p            1   137.38 181.38
- x2pa           1   138.03 182.03
- ft             1   139.23 183.23
- x3pa           1   140.52 184.52

Step:  AIC=158.35
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- ast            1   114.39 156.39
- x2p_percent    1   114.46 156.46
- e_fg_percent   1   114.50 156.50
- fg_percent     1   114.56 156.56
- x3p_percent    1   114.86 156.86
<none>               114.36 158.35
- fga            1   116.94 158.94
- teamChemistry  1   117.46 159.46
- blk            1   118.24 160.24
- fg             1   118.43 160.43
- pts            1   118.74 160.74
- drb            1   119.75 161.75
- orb            1   120.36 162.36
- tov            1   121.75 163.75
- trb            1   121.80 163.79
- fta            1   124.92 166.92
- stl            1   135.04 177.04
- x2p            1   136.24 178.24
- x2pa           1   138.37 180.37
- x3p            1   139.02 181.02
- ft             1   139.30 181.30
- x3pa           1   141.81 183.81

Step:  AIC=156.39
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   114.51 154.51
- e_fg_percent   1   114.56 154.56
- fg_percent     1   114.62 154.62
- x3p_percent    1   114.90 154.90
<none>               114.39 156.39
- fga            1   116.95 156.95
- teamChemistry  1   117.47 157.47
- blk            1   118.27 158.27
- pts            1   118.78 158.78
- fg             1   118.78 158.78
- drb            1   119.85 159.85
- orb            1   120.49 160.49
- tov            1   121.81 161.81
- trb            1   121.90 161.90
- fta            1   125.00 165.00
- x2p            1   136.26 176.26
- stl            1   136.38 176.38
- x2pa           1   138.38 178.38
- ft             1   139.30 179.30
- x3p            1   139.56 179.56
- x3pa           1   142.09 182.09

Step:  AIC=154.51
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   114.71 152.71
- x3p_percent    1   114.91 152.91
- fg_percent     1   115.11 153.11
<none>               114.51 154.51
- fga            1   117.26 155.26
- teamChemistry  1   117.52 155.52
- blk            1   118.38 156.38
- pts            1   118.79 156.79
- fg             1   119.01 157.01
- drb            1   120.14 158.15
- orb            1   120.81 158.81
- trb            1   122.20 160.20
- tov            1   122.78 160.78
- fta            1   125.00 163.00
- x2p            1   136.31 174.31
- stl            1   136.68 174.68
- x2pa           1   138.48 176.48
- ft             1   139.39 177.39
- x3p            1   141.10 179.10
- x3pa           1   144.28 182.28

Step:  AIC=152.71
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + stl + blk + tov + 
    pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   114.91 150.91
- fg_percent     1   116.52 152.52
<none>               114.71 152.71
- fga            1   117.32 153.32
- teamChemistry  1   117.52 153.52
- blk            1   118.57 154.57
- pts            1   118.86 154.85
- fg             1   119.12 155.12
- drb            1   120.39 156.39
- orb            1   121.03 157.03
- trb            1   122.51 158.51
- tov            1   123.61 159.61
- fta            1   125.40 161.40
- x2p            1   136.34 172.34
- stl            1   137.27 173.27
- x2pa           1   138.87 174.87
- ft             1   139.44 175.44
- x3p            1   141.45 177.45
- x3pa           1   144.60 180.60

Step:  AIC=150.91
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x2p + x2pa + 
    ft + fta + orb + drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   116.80 150.80
<none>               114.91 150.91
- fga            1   117.42 151.42
- teamChemistry  1   117.99 151.99
- blk            1   118.68 152.68
- pts            1   118.91 152.91
- fg             1   119.24 153.24
- drb            1   120.42 154.42
- orb            1   121.06 155.06
- trb            1   122.53 156.53
- tov            1   124.55 158.55
- fta            1   125.42 159.42
- x2p            1   136.40 170.40
- stl            1   138.44 172.44
- x2pa           1   138.93 172.93
- ft             1   139.50 173.50
- x3p            1   141.45 175.45
- x3pa           1   144.61 178.61

Step:  AIC=150.8
.outcome ~ fg + fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + 
    drb + trb + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               116.80 150.80
- fga            1   119.62 151.62
- blk            1   120.55 152.55
- teamChemistry  1   120.70 152.70
- pts            1   120.97 152.97
- drb            1   121.20 153.20
- fg             1   121.40 153.40
- orb            1   121.77 153.77
- trb            1   123.18 155.18
- fta            1   125.76 157.76
- tov            1   127.70 159.71
- x2p            1   137.18 169.18
- ft             1   139.66 171.66
- x2pa           1   140.15 172.15
- x3p            1   142.78 174.78
- stl            1   144.43 176.43
- x3pa           1   145.78 177.78
Start:  AIC=177.51
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   131.51 175.51
- fg_percent     1   131.58 175.58
- ast            1   131.68 175.68
- x2p_percent    1   132.16 176.16
- teamChemistry  1   132.19 176.19
- fg             1   132.34 176.34
- x3p_percent    1   133.00 177.00
<none>               131.51 177.51
- tov            1   133.67 177.67
- fga            1   133.67 177.67
- x3p            1   134.36 178.36
- pf             1   135.76 179.76
- x3pa           1   135.77 179.77
- drb            1   135.79 179.79
- orb            1   137.19 181.19
- pts            1   137.46 181.46
- trb            1   138.05 182.05
- blk            1   139.77 183.77
- x2p            1   141.17 185.17
- fta            1   145.85 189.85
- x2pa           1   147.17 191.17
- ft             1   148.72 192.72
- stl            1   178.41 222.41

Step:  AIC=175.51
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + drb + trb + ast + 
    stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- ast            1   131.68 173.68
- fg_percent     1   131.95 173.95
- x2p_percent    1   132.18 174.18
- teamChemistry  1   132.21 174.21
- fg             1   132.38 174.38
<none>               131.51 175.51
- tov            1   133.68 175.68
- fga            1   133.69 175.69
- x3p_percent    1   133.95 175.95
- x3p            1   134.37 176.37
- pf             1   135.78 177.78
- x3pa           1   135.81 177.81
- drb            1   135.82 177.82
- orb            1   137.24 179.24
- pts            1   137.48 179.48
- trb            1   138.08 180.08
- blk            1   139.84 181.84
- x2p            1   141.24 183.24
- fta            1   146.32 188.32
- x2pa           1   147.35 189.35
- ft             1   149.03 191.03
- stl            1   178.44 220.44

Step:  AIC=173.68
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + ft + fta + orb + drb + trb + stl + 
    blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   132.17 172.17
- teamChemistry  1   132.28 172.28
- fg             1   132.38 172.38
- x2p_percent    1   132.41 172.41
<none>               131.68 173.68
- fga            1   133.71 173.71
- tov            1   133.87 173.87
- x3p_percent    1   134.16 174.16
- x3p            1   134.38 174.38
- x3pa           1   135.83 175.83
- drb            1   136.47 176.47
- pf             1   136.52 176.52
- pts            1   137.48 177.48
- orb            1   137.92 177.92
- trb            1   138.78 178.78
- blk            1   140.33 180.33
- x2p            1   141.24 181.24
- fta            1   147.00 187.00
- x2pa           1   147.37 187.37
- ft             1   149.18 189.18
- stl            1   180.91 220.91

Step:  AIC=172.17
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    x2p_percent + ft + fta + orb + drb + trb + stl + blk + tov + 
    pf + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   132.41 170.41
- teamChemistry  1   132.74 170.74
- fg             1   132.89 170.89
<none>               132.17 172.17
- x3p_percent    1   134.18 172.18
- tov            1   134.41 172.41
- fga            1   134.42 172.42
- x3p            1   135.87 173.87
- drb            1   137.06 175.06
- pf             1   137.41 175.41
- x3pa           1   137.66 175.66
- pts            1   138.21 176.21
- orb            1   138.50 176.50
- trb            1   139.39 177.39
- x2p            1   141.64 179.64
- blk            1   141.79 179.79
- fta            1   147.06 185.06
- x2pa           1   147.79 185.79
- ft             1   149.32 187.32
- stl            1   181.19 219.19

Step:  AIC=170.41
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + orb + drb + trb + stl + blk + tov + pf + pts + 
    teamChemistry

                Df Deviance    AIC
- teamChemistry  1   133.01 169.01
- fg             1   133.12 169.12
- x3p_percent    1   134.21 170.21
<none>               132.41 170.41
- fga            1   134.55 170.55
- tov            1   134.81 170.81
- x3p            1   136.07 172.07
- drb            1   137.13 173.13
- x3pa           1   137.81 173.81
- pf             1   137.92 173.92
- pts            1   138.30 174.30
- orb            1   138.54 174.54
- trb            1   139.44 175.44
- blk            1   141.79 177.79
- x2p            1   141.79 177.79
- fta            1   147.17 183.17
- x2pa           1   148.40 184.40
- ft             1   149.35 185.35
- stl            1   183.80 219.80

Step:  AIC=169.01
.outcome ~ fg + fga + x3p + x3pa + x3p_percent + x2p + x2pa + 
    ft + fta + orb + drb + trb + stl + blk + tov + pf + pts

              Df Deviance    AIC
- fg           1   133.84 167.84
- x3p_percent  1   134.72 168.72
<none>             133.01 169.01
- fga          1   135.18 169.18
- tov          1   136.62 170.62
- x3p          1   136.63 170.63
- pf           1   138.06 172.06
- drb          1   138.28 172.28
- x3pa         1   138.31 172.31
- pts          1   139.05 173.05
- orb          1   139.98 173.98
- trb          1   140.88 174.88
- blk          1   142.37 176.37
- x2p          1   142.64 176.64
- fta          1   147.55 181.55
- x2pa         1   149.32 183.32
- ft           1   149.75 183.75
- stl          1   186.12 220.12

Step:  AIC=167.84
.outcome ~ fga + x3p + x3pa + x3p_percent + x2p + x2pa + ft + 
    fta + orb + drb + trb + stl + blk + tov + pf + pts

              Df Deviance    AIC
- fga          1   135.20 167.20
- x3p_percent  1   135.40 167.40
<none>             133.84 167.84
- x3p          1   136.70 168.70
- tov          1   137.04 169.04
- drb          1   138.29 170.29
- pf           1   138.34 170.34
- x3pa         1   138.56 170.56
- pts          1   139.07 171.07
- orb          1   140.03 172.03
- trb          1   140.91 172.91
- blk          1   143.09 175.09
- x2p          1   145.91 177.91
- fta          1   147.88 179.88
- x2pa         1   149.85 181.85
- ft           1   151.27 183.27
- stl          1   186.19 218.19

Step:  AIC=167.2
.outcome ~ x3p + x3pa + x3p_percent + x2p + x2pa + ft + fta + 
    orb + drb + trb + stl + blk + tov + pf + pts

              Df Deviance    AIC
- x3p_percent  1   136.19 166.19
- x3p          1   136.83 166.83
<none>             135.20 167.20
- x3pa         1   138.74 168.74
- tov          1   139.05 169.05
- pf           1   139.46 169.46
- pts          1   139.71 169.71
- drb          1   140.85 170.85
- orb          1   142.42 172.42
- trb          1   143.26 173.26
- blk          1   143.33 173.33
- fta          1   148.60 178.60
- x2p          1   149.07 179.07
- ft           1   151.38 181.38
- x2pa         1   165.71 195.71
- stl          1   186.39 216.39

Step:  AIC=166.19
.outcome ~ x3p + x3pa + x2p + x2pa + ft + fta + orb + drb + trb + 
    stl + blk + tov + pf + pts

       Df Deviance    AIC
- x3p   1   137.51 165.51
<none>      136.19 166.19
- x3pa  1   139.49 167.49
- pf    1   140.26 168.26
- pts   1   140.41 168.41
- tov   1   140.56 168.56
- drb   1   141.09 169.09
- orb   1   142.56 170.56
- trb   1   143.41 171.41
- blk   1   143.86 171.86
- fta   1   149.04 177.04
- x2p   1   149.19 177.19
- ft    1   152.02 180.02
- x2pa  1   165.91 193.91
- stl   1   191.06 219.06

Step:  AIC=165.51
.outcome ~ x3pa + x2p + x2pa + ft + fta + orb + drb + trb + stl + 
    blk + tov + pf + pts

       Df Deviance    AIC
<none>      137.51 165.51
- pts   1   140.56 166.56
- x3pa  1   140.58 166.58
- drb   1   141.53 167.53
- pf    1   141.77 167.77
- tov   1   142.36 168.36
- orb   1   143.09 169.09
- trb   1   143.72 169.72
- blk   1   144.61 170.61
- x2p   1   149.84 175.84
- fta   1   150.96 176.96
- ft    1   153.60 179.60
- x2pa  1   166.31 192.31
- stl   1   191.06 217.06
Start:  AIC=184.85
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pf + pts + teamChemistry

                Df Deviance    AIC
- pf             1   138.89 182.89
- x2p_percent    1   138.99 182.99
- e_fg_percent   1   139.05 183.05
- fg_percent     1   139.14 183.14
- ast            1   139.48 183.48
- blk            1   139.84 183.84
- drb            1   140.24 184.24
- x3p_percent    1   140.45 184.45
<none>               138.85 184.85
- fg             1   140.87 184.87
- orb            1   140.94 184.94
- trb            1   141.84 185.84
- teamChemistry  1   143.30 187.30
- tov            1   145.95 189.95
- fga            1   146.22 190.22
- pts            1   147.72 191.72
- fta            1   153.08 197.08
- x3p            1   153.92 197.92
- x2p            1   157.84 201.84
- ft             1   161.85 205.85
- stl            1   161.94 205.94
- x3pa           1   163.77 207.77
- x2pa           1   171.02 215.02

Step:  AIC=182.89
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + x2p_percent + e_fg_percent + ft + fta + orb + 
    drb + trb + ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- x2p_percent    1   139.01 181.01
- e_fg_percent   1   139.08 181.08
- fg_percent     1   139.19 181.19
- ast            1   139.52 181.52
- blk            1   139.88 181.88
- drb            1   140.30 182.30
- x3p_percent    1   140.47 182.47
<none>               138.89 182.89
- fg             1   141.00 183.00
- orb            1   141.00 183.00
- trb            1   141.91 183.91
- teamChemistry  1   143.33 185.33
- fga            1   146.57 188.57
- tov            1   146.94 188.94
- pts            1   147.85 189.85
- fta            1   153.43 195.43
- x3p            1   154.84 196.84
- x2p            1   157.90 199.90
- ft             1   163.04 205.04
- stl            1   163.60 205.60
- x3pa           1   164.27 206.27
- x2pa           1   171.08 213.08

Step:  AIC=181.01
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + e_fg_percent + ft + fta + orb + drb + trb + 
    ast + stl + blk + tov + pts + teamChemistry

                Df Deviance    AIC
- e_fg_percent   1   139.21 179.21
- fg_percent     1   139.66 179.66
- ast            1   139.72 179.72
- blk            1   140.05 180.05
- drb            1   140.38 180.38
- x3p_percent    1   140.47 180.47
<none>               139.01 181.01
- orb            1   141.07 181.07
- fg             1   141.34 181.34
- trb            1   141.98 181.98
- teamChemistry  1   143.65 183.65
- fga            1   147.25 187.25
- tov            1   147.59 187.59
- pts            1   148.28 188.28
- fta            1   153.55 193.55
- x3p            1   157.97 197.97
- x2p            1   158.10 198.10
- ft             1   163.05 203.05
- stl            1   164.08 204.08
- x3pa           1   169.12 209.12
- x2pa           1   171.09 211.09

Step:  AIC=179.21
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + ast + stl + blk + 
    tov + pts + teamChemistry

                Df Deviance    AIC
- ast            1   139.97 177.97
- blk            1   140.32 178.32
- drb            1   140.61 178.61
- x3p_percent    1   140.82 178.82
- fg_percent     1   140.97 178.97
<none>               139.21 179.21
- orb            1   141.29 179.29
- fg             1   141.43 179.43
- trb            1   142.24 180.24
- teamChemistry  1   143.66 181.66
- fga            1   147.30 185.30
- tov            1   147.77 185.77
- pts            1   148.72 186.72
- fta            1   153.89 191.89
- x2p            1   158.12 196.12
- x3p            1   158.36 196.36
- ft             1   163.49 201.49
- stl            1   165.70 203.70
- x3pa           1   169.34 207.34
- x2pa           1   172.10 210.10

Step:  AIC=177.97
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + stl + blk + tov + 
    pts + teamChemistry

                Df Deviance    AIC
- blk            1   141.34 177.34
- drb            1   141.58 177.58
- fg             1   141.62 177.62
- x3p_percent    1   141.66 177.66
- fg_percent     1   141.90 177.90
<none>               139.97 177.97
- orb            1   142.32 178.32
- trb            1   143.27 179.27
- teamChemistry  1   144.04 180.04
- fga            1   147.88 183.88
- tov            1   148.32 184.32
- pts            1   149.10 185.10
- fta            1   155.35 191.35
- x3p            1   158.39 194.39
- x2p            1   158.91 194.91
- ft             1   164.17 200.17
- stl            1   168.95 204.95
- x3pa           1   169.40 205.40
- x2pa           1   172.88 208.88

Step:  AIC=177.34
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + drb + trb + stl + tov + pts + 
    teamChemistry

                Df Deviance    AIC
- drb            1   142.73 176.73
- fg             1   142.89 176.89
- x3p_percent    1   142.91 176.91
- fg_percent     1   142.94 176.94
<none>               141.34 177.34
- orb            1   143.40 177.40
- trb            1   144.23 178.23
- teamChemistry  1   145.84 179.84
- fga            1   148.11 182.11
- tov            1   148.91 182.91
- pts            1   149.33 183.33
- fta            1   156.69 190.69
- x3p            1   158.54 192.54
- x2p            1   159.12 193.12
- ft             1   165.44 199.44
- stl            1   168.97 202.97
- x3pa           1   169.42 203.42
- x2pa           1   172.89 206.89

Step:  AIC=176.73
.outcome ~ fg + fga + fg_percent + x3p + x3pa + x3p_percent + 
    x2p + x2pa + ft + fta + orb + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- fg             1   143.51 175.51
- x3p_percent    1   143.84 175.84
- fg_percent     1   144.39 176.39
<none>               142.73 176.73
- orb            1   146.41 178.41
- teamChemistry  1   148.20 180.20
- tov            1   149.21 181.21
- fga            1   149.34 181.34
- pts            1   149.76 181.76
- fta            1   157.51 189.51
- x3p            1   158.68 190.68
- x2p            1   159.12 191.12
- ft             1   165.94 197.94
- x3pa           1   170.79 202.79
- stl            1   171.26 203.26
- x2pa           1   173.65 205.65
- trb            1   174.04 206.04

Step:  AIC=175.51
.outcome ~ fga + fg_percent + x3p + x3pa + x3p_percent + x2p + 
    x2pa + ft + fta + orb + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- x3p_percent    1   144.54 174.54
- fg_percent     1   145.19 175.19
<none>               143.51 175.51
- orb            1   146.44 176.44
- tov            1   149.22 179.22
- teamChemistry  1   149.55 179.55
- pts            1   149.91 179.91
- fga            1   150.06 180.06
- fta            1   157.53 187.53
- x3p            1   158.79 188.79
- ft             1   166.29 196.29
- x2p            1   167.24 197.24
- x3pa           1   170.79 200.79
- stl            1   171.86 201.86
- trb            1   174.04 204.04
- x2pa           1   175.09 205.09

Step:  AIC=174.54
.outcome ~ fga + fg_percent + x3p + x3pa + x2p + x2pa + ft + 
    fta + orb + trb + stl + tov + pts + teamChemistry

                Df Deviance    AIC
- fg_percent     1   146.22 174.22
<none>               144.54 174.54
- orb            1   147.12 175.12
- pts            1   151.01 179.01
- teamChemistry  1   151.24 179.24
- tov            1   151.31 179.31
- fga            1   151.37 179.37
- fta            1   158.17 186.17
- x3p            1   159.30 187.30
- ft             1   167.11 195.11
- x2p            1   168.02 196.02
- x3pa           1   171.62 199.62
- stl            1   174.78 202.78
- trb            1   175.48 203.48
- x2pa           1   176.17 204.17

Step:  AIC=174.23
.outcome ~ fga + x3p + x3pa + x2p + x2pa + ft + fta + orb + trb + 
    stl + tov + pts + teamChemistry

                Df Deviance    AIC
<none>               146.22 174.22
- orb            1   148.71 174.71
- fga            1   153.11 179.11
- pts            1   153.19 179.19
- tov            1   153.81 179.81
- teamChemistry  1   154.65 180.65
- fta            1   158.91 184.91
- x3p            1   160.18 186.18
- ft             1   167.69 193.69
- x2p            1   168.18 194.18
- x3pa           1   172.17 198.17
- x2pa           1   176.48 202.48
- trb            1   178.03 204.03
- stl            1   178.54 204.54
7.323 sec elapsed
[1] "Running lda"
0.282 sec elapsed
[1] "Running lda2"
0.314 sec elapsed
[1] "Running polr"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :5     NA's   :5    
<simpleError: Stopping>
0.9 sec elapsed
[1] "Running qda"
0.286 sec elapsed
[1] "Running hda"
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.89183962854 
Iteration 2 Log Likelihood:  -6463.56692518399 
Iteration 3 Log Likelihood:  -6463.56692518399 
Iteration 4 Log Likelihood:  -6463.56692518399 
Iteration 5 Log Likelihood:  -6463.56692518399 
Iteration 6 Log Likelihood:  -6463.56692518399 
Iteration 7 Log Likelihood:  -6463.56692518399 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6515.88352879722 
Iteration 2 Log Likelihood:  -5623.86997130328 
Iteration 3 Log Likelihood:  -5623.86997130328 
Iteration 4 Log Likelihood:  -5623.86997130328 
Iteration 5 Log Likelihood:  -5623.86997130328 
Iteration 6 Log Likelihood:  -5623.86997130328 
Iteration 7 Log Likelihood:  -5623.86997130328 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6511.12453547686 
Iteration 2 Log Likelihood:  -891.041242076587 
Iteration 3 Log Likelihood:  -891.041242076641 
Iteration 4 Log Likelihood:  -891.041242076629 
Iteration 5 Log Likelihood:  -891.041242076619 
Iteration 6 Log Likelihood:  -891.041242076578 
Iteration 7 Log Likelihood:  -891.041242076644 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.25949730912 
Iteration 2 Log Likelihood:  -6463.92960983043 
Iteration 3 Log Likelihood:  -6463.92960892578 
Iteration 4 Log Likelihood:  -6463.92960801822 
Iteration 5 Log Likelihood:  -6463.92960710773 
Iteration 6 Log Likelihood:  -6463.92960619431 
Iteration 7 Log Likelihood:  -6463.92960527793 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.17860164654 
Iteration 2 Log Likelihood:  -5623.94525150329 
Iteration 3 Log Likelihood:  -5623.94524766434 
Iteration 4 Log Likelihood:  -5623.9452437908 
Iteration 5 Log Likelihood:  -5623.94523987485 
Iteration 6 Log Likelihood:  -5623.94523591587 
Iteration 7 Log Likelihood:  -5623.94523191323 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6511.25843652596 
Iteration 2 Log Likelihood:  -888.465823090165 
Iteration 3 Log Likelihood:  -888.454778200048 
Iteration 4 Log Likelihood:  -888.433354827175 
Iteration 5 Log Likelihood:  -888.390857154137 
Iteration 6 Log Likelihood:  -888.305753549969 
Iteration 7 Log Likelihood:  -888.138681004991 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.87117266979 
Iteration 2 Log Likelihood:  -6463.54715166041 
Iteration 3 Log Likelihood:  -6463.54706770881 
Iteration 4 Log Likelihood:  -6463.54698109621 
Iteration 5 Log Likelihood:  -6463.54689169513 
Iteration 6 Log Likelihood:  -6463.5467993701 
Iteration 7 Log Likelihood:  -6463.54670397686 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6515.83844028236 
Iteration 2 Log Likelihood:  -5623.86072700156 
Iteration 3 Log Likelihood:  -5623.86025469899 
Iteration 4 Log Likelihood:  -5623.85972174936 
Iteration 5 Log Likelihood:  -5623.85911578245 
Iteration 6 Log Likelihood:  -5623.85842163985 
Iteration 7 Log Likelihood:  -5623.85761967773 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6511.02612308893 
Iteration 2 Log Likelihood:  -890.773106593129 
Iteration 3 Log Likelihood:  -884.024387799606 
Iteration 4 Log Likelihood:  -845.752846326759 
Iteration 5 Log Likelihood:  -817.094011107592 
Iteration 6 Log Likelihood:  -790.568843875268 
Iteration 7 Log Likelihood:  -784.14858356484 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.89183962854 
Iteration 2 Log Likelihood:  -6463.56692518399 
Iteration 3 Log Likelihood:  -6463.56692518399 
Iteration 4 Log Likelihood:  -6463.56692518399 
Iteration 5 Log Likelihood:  -6463.56692518399 
Iteration 6 Log Likelihood:  -6463.56692518399 
Iteration 7 Log Likelihood:  -6463.56692518399 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6515.88352879722 
Iteration 2 Log Likelihood:  -5623.86997130328 
Iteration 3 Log Likelihood:  -5623.86997130328 
Iteration 4 Log Likelihood:  -5623.86997130328 
Iteration 5 Log Likelihood:  -5623.86997130328 
Iteration 6 Log Likelihood:  -5623.86997130328 
Iteration 7 Log Likelihood:  -5623.86997130328 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6511.12453547686 
Iteration 2 Log Likelihood:  -891.041242076582 
Iteration 3 Log Likelihood:  -891.04124207664 
Iteration 4 Log Likelihood:  -891.041242076632 
Iteration 5 Log Likelihood:  -891.0412420766 
Iteration 6 Log Likelihood:  -891.041242076588 
Iteration 7 Log Likelihood:  -891.041242076576 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.25788420959 
Iteration 2 Log Likelihood:  -6463.92838457342 
Iteration 3 Log Likelihood:  -6463.92836868659 
Iteration 4 Log Likelihood:  -6463.92835258679 
Iteration 5 Log Likelihood:  -6463.92833625984 
Iteration 6 Log Likelihood:  -6463.92831970179 
Iteration 7 Log Likelihood:  -6463.92830290861 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.15334466802 
Iteration 2 Log Likelihood:  -5623.94360102997 
Iteration 3 Log Likelihood:  -5623.94352340059 
Iteration 4 Log Likelihood:  -5623.94344287371 
Iteration 5 Log Likelihood:  -5623.94335842574 
Iteration 6 Log Likelihood:  -5623.9432698197 
Iteration 7 Log Likelihood:  -5623.9431768006 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6511.18745064507 
Iteration 2 Log Likelihood:  -887.957785301375 
Iteration 3 Log Likelihood:  -887.615418509172 
Iteration 4 Log Likelihood:  -887.215014516758 
Iteration 5 Log Likelihood:  -886.833006107532 
Iteration 6 Log Likelihood:  -886.493292684918 
Iteration 7 Log Likelihood:  -886.148484307786 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.85605738836 
Iteration 2 Log Likelihood:  -6463.53395679968 
Iteration 3 Log Likelihood:  -6463.53225250215 
Iteration 4 Log Likelihood:  -6463.53029997265 
Iteration 5 Log Likelihood:  -6463.52805213302 
Iteration 6 Log Likelihood:  -6463.52545219206 
Iteration 7 Log Likelihood:  -6463.52242997309 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6515.59903207667 
Iteration 2 Log Likelihood:  -5623.80618354411 
Iteration 3 Log Likelihood:  -5623.7692620939 
Iteration 4 Log Likelihood:  -5623.69302021544 
Iteration 5 Log Likelihood:  -5623.50148746653 
Iteration 6 Log Likelihood:  -5622.86011728235 
Iteration 7 Log Likelihood:  -5619.9351323949 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6510.34477662035 
Iteration 2 Log Likelihood:  -875.155265380072 
Iteration 3 Log Likelihood:  -858.877145347117 
Iteration 4 Log Likelihood:  -825.052898194193 
Iteration 5 Log Likelihood:  -798.029691421758 
Iteration 6 Log Likelihood:  -774.79819767677 
Iteration 7 Log Likelihood:  -756.171663772152 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.52051895523 
Iteration 2 Log Likelihood:  -6489.86364515028 
Iteration 3 Log Likelihood:  -6489.86364515028 
Iteration 4 Log Likelihood:  -6489.86364515028 
Iteration 5 Log Likelihood:  -6489.86364515028 
Iteration 6 Log Likelihood:  -6489.86364515028 
Iteration 7 Log Likelihood:  -6489.86364515028 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.1559847528 
Iteration 2 Log Likelihood:  -5644.63871203072 
Iteration 3 Log Likelihood:  -5644.63871203072 
Iteration 4 Log Likelihood:  -5644.63871203072 
Iteration 5 Log Likelihood:  -5644.63871203072 
Iteration 6 Log Likelihood:  -5644.63871203072 
Iteration 7 Log Likelihood:  -5644.63871203072 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.90774338586 
Iteration 2 Log Likelihood:  -905.525506946976 
Iteration 3 Log Likelihood:  -905.525506947063 
Iteration 4 Log Likelihood:  -905.52550694708 
Iteration 5 Log Likelihood:  -905.525506946984 
Iteration 6 Log Likelihood:  -905.525506946964 
Iteration 7 Log Likelihood:  -905.525506946985 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.74982106075 
Iteration 2 Log Likelihood:  -6490.10463258525 
Iteration 3 Log Likelihood:  -6490.10463172128 
Iteration 4 Log Likelihood:  -6490.10463085657 
Iteration 5 Log Likelihood:  -6490.10462999112 
Iteration 6 Log Likelihood:  -6490.10462912493 
Iteration 7 Log Likelihood:  -6490.10462825801 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.41026355594 
Iteration 2 Log Likelihood:  -5644.97538904347 
Iteration 3 Log Likelihood:  -5644.97537639363 
Iteration 4 Log Likelihood:  -5644.97536358971 
Iteration 5 Log Likelihood:  -5644.97535062982 
Iteration 6 Log Likelihood:  -5644.97533751207 
Iteration 7 Log Likelihood:  -5644.97532423452 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.21662988572 
Iteration 2 Log Likelihood:  -905.955540569387 
Iteration 3 Log Likelihood:  -905.905360924032 
Iteration 4 Log Likelihood:  -905.809920572435 
Iteration 5 Log Likelihood:  -905.630562896774 
Iteration 6 Log Likelihood:  -905.311790109734 
Iteration 7 Log Likelihood:  -904.820310467979 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.50773831288 
Iteration 2 Log Likelihood:  -6489.84870560205 
Iteration 3 Log Likelihood:  -6489.84863410115 
Iteration 4 Log Likelihood:  -6489.84856205069 
Iteration 5 Log Likelihood:  -6489.84848945165 
Iteration 6 Log Likelihood:  -6489.84841630455 
Iteration 7 Log Likelihood:  -6489.84834260947 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.1188048205 
Iteration 2 Log Likelihood:  -5644.61523149554 
Iteration 3 Log Likelihood:  -5644.61412108852 
Iteration 4 Log Likelihood:  -5644.61288211625 
Iteration 5 Log Likelihood:  -5644.61149943691 
Iteration 6 Log Likelihood:  -5644.60995537199 
Iteration 7 Log Likelihood:  -5644.60822900682 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.77534104102 
Iteration 2 Log Likelihood:  -902.026697635892 
Iteration 3 Log Likelihood:  -878.632388393546 
Iteration 4 Log Likelihood:  -865.720956856789 
Iteration 5 Log Likelihood:  -832.21577039614 
Iteration 6 Log Likelihood:  -816.429894308339 
Iteration 7 Log Likelihood:  -815.972061405899 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.52051895523 
Iteration 2 Log Likelihood:  -6489.86364515028 
Iteration 3 Log Likelihood:  -6489.86364515028 
Iteration 4 Log Likelihood:  -6489.86364515028 
Iteration 5 Log Likelihood:  -6489.86364515028 
Iteration 6 Log Likelihood:  -6489.86364515028 
Iteration 7 Log Likelihood:  -6489.86364515028 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.1559847528 
Iteration 2 Log Likelihood:  -5644.63871203071 
Iteration 3 Log Likelihood:  -5644.63871203072 
Iteration 4 Log Likelihood:  -5644.63871203072 
Iteration 5 Log Likelihood:  -5644.63871203071 
Iteration 6 Log Likelihood:  -5644.63871203072 
Iteration 7 Log Likelihood:  -5644.63871203072 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.90774338586 
Iteration 2 Log Likelihood:  -905.525506947082 
Iteration 3 Log Likelihood:  -905.525506946993 
Iteration 4 Log Likelihood:  -905.525506946949 
Iteration 5 Log Likelihood:  -905.525506946989 
Iteration 6 Log Likelihood:  -905.525506947055 
Iteration 7 Log Likelihood:  -905.525506947012 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.74981656784 
Iteration 2 Log Likelihood:  -6490.10462737449 
Iteration 3 Log Likelihood:  -6490.10462649448 
Iteration 4 Log Likelihood:  -6490.10462561577 
Iteration 5 Log Likelihood:  -6490.10462473621 
Iteration 6 Log Likelihood:  -6490.10462385578 
Iteration 7 Log Likelihood:  -6490.1046229745 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.40231559421 
Iteration 2 Log Likelihood:  -5644.97522203638 
Iteration 3 Log Likelihood:  -5644.9752027224 
Iteration 4 Log Likelihood:  -5644.97518311719 
Iteration 5 Log Likelihood:  -5644.97516309489 
Iteration 6 Log Likelihood:  -5644.97514264402 
Iteration 7 Log Likelihood:  -5644.97512175273 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.18719177319 
Iteration 2 Log Likelihood:  -905.595870501875 
Iteration 3 Log Likelihood:  -905.168017995431 
Iteration 4 Log Likelihood:  -904.498724745981 
Iteration 5 Log Likelihood:  -903.721377205448 
Iteration 6 Log Likelihood:  -902.990183377859 
Iteration 7 Log Likelihood:  -902.295634659096 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.50769761837 
Iteration 2 Log Likelihood:  -6489.84865668336 
Iteration 3 Log Likelihood:  -6489.84858379218 
Iteration 4 Log Likelihood:  -6489.84851043357 
Iteration 5 Log Likelihood:  -6489.84843642738 
Iteration 6 Log Likelihood:  -6489.84836176752 
Iteration 7 Log Likelihood:  -6489.8482864471 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.04698010259 
Iteration 2 Log Likelihood:  -5644.61519581544 
Iteration 3 Log Likelihood:  -5644.61406500227 
Iteration 4 Log Likelihood:  -5644.61281310244 
Iteration 5 Log Likelihood:  -5644.611413051 
Iteration 6 Log Likelihood:  -5644.60984529748 
Iteration 7 Log Likelihood:  -5644.60808622972 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.50961100099 
Iteration 2 Log Likelihood:  -890.187226836441 
Iteration 3 Log Likelihood:  -843.171394673872 
Iteration 4 Log Likelihood:  -813.780651646231 
Iteration 5 Log Likelihood:  -805.924851822185 
Iteration 6 Log Likelihood:  -790.964068095301 
Iteration 7 Log Likelihood:  -785.612839532515 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6626.70341415213 
Iteration 2 Log Likelihood:  -6568.96722446594 
Iteration 3 Log Likelihood:  -6568.96722446594 
Iteration 4 Log Likelihood:  -6568.96722446594 
Iteration 5 Log Likelihood:  -6568.96722446594 
Iteration 6 Log Likelihood:  -6568.96722446594 
Iteration 7 Log Likelihood:  -6568.96722446594 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6625.95744973163 
Iteration 2 Log Likelihood:  -5707.97614718416 
Iteration 3 Log Likelihood:  -5707.97614718416 
Iteration 4 Log Likelihood:  -5707.97614718417 
Iteration 5 Log Likelihood:  -5707.97614718417 
Iteration 6 Log Likelihood:  -5707.97614718417 
Iteration 7 Log Likelihood:  -5707.97614718417 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6624.16264068184 
Iteration 2 Log Likelihood:  -941.298814875752 
Iteration 3 Log Likelihood:  -941.298814875807 
Iteration 4 Log Likelihood:  -941.298814875735 
Iteration 5 Log Likelihood:  -941.298814875746 
Iteration 6 Log Likelihood:  -941.298814875746 
Iteration 7 Log Likelihood:  -941.298814875738 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6626.60823322378 
Iteration 2 Log Likelihood:  -6568.86585388093 
Iteration 3 Log Likelihood:  -6568.86585075005 
Iteration 4 Log Likelihood:  -6568.86584760559 
Iteration 5 Log Likelihood:  -6568.86584444743 
Iteration 6 Log Likelihood:  -6568.86584127548 
Iteration 7 Log Likelihood:  -6568.86583808963 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6625.86341699205 
Iteration 2 Log Likelihood:  -5707.89740283711 
Iteration 3 Log Likelihood:  -5707.89733802517 
Iteration 4 Log Likelihood:  -5707.89727162267 
Iteration 5 Log Likelihood:  -5707.89720356072 
Iteration 6 Log Likelihood:  -5707.89713376801 
Iteration 7 Log Likelihood:  -5707.89706216897 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6624.07358284941 
Iteration 2 Log Likelihood:  -941.226497839942 
Iteration 3 Log Likelihood:  -940.870477678239 
Iteration 4 Log Likelihood:  -940.264415038142 
Iteration 5 Log Likelihood:  -939.418864894362 
Iteration 6 Log Likelihood:  -938.451872420398 
Iteration 7 Log Likelihood:  -937.53953818394 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6626.69659204945 
Iteration 2 Log Likelihood:  -6568.96008905746 
Iteration 3 Log Likelihood:  -6568.95982323775 
Iteration 4 Log Likelihood:  -6568.95954640658 
Iteration 5 Log Likelihood:  -6568.95925778608 
Iteration 6 Log Likelihood:  -6568.95895652804 
Iteration 7 Log Likelihood:  -6568.95864170482 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6625.90772198199 
Iteration 2 Log Likelihood:  -5707.93914190569 
Iteration 3 Log Likelihood:  -5707.93176844903 
Iteration 4 Log Likelihood:  -5707.92189213991 
Iteration 5 Log Likelihood:  -5707.90787246311 
Iteration 6 Log Likelihood:  -5707.88640178979 
Iteration 7 Log Likelihood:  -5707.84999573501 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6624.03004319968 
Iteration 2 Log Likelihood:  -933.246597440221 
Iteration 3 Log Likelihood:  -903.656897034452 
Iteration 4 Log Likelihood:  -823.582981700156 
Iteration 5 Log Likelihood:  -811.650520052201 
Iteration 6 Log Likelihood:  -811.484640585615 
Iteration 7 Log Likelihood:  -811.345921022494 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6626.70341415213 
Iteration 2 Log Likelihood:  -6568.96722446594 
Iteration 3 Log Likelihood:  -6568.96722446594 
Iteration 4 Log Likelihood:  -6568.96722446594 
Iteration 5 Log Likelihood:  -6568.96722446594 
Iteration 6 Log Likelihood:  -6568.96722446594 
Iteration 7 Log Likelihood:  -6568.96722446594 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6625.95744973163 
Iteration 2 Log Likelihood:  -5707.97614718416 
Iteration 3 Log Likelihood:  -5707.97614718416 
Iteration 4 Log Likelihood:  -5707.97614718416 
Iteration 5 Log Likelihood:  -5707.97614718416 
Iteration 6 Log Likelihood:  -5707.97614718417 
Iteration 7 Log Likelihood:  -5707.97614718417 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6624.16264068184 
Iteration 2 Log Likelihood:  -941.298814875778 
Iteration 3 Log Likelihood:  -941.298814875716 
Iteration 4 Log Likelihood:  -941.298814875683 
Iteration 5 Log Likelihood:  -941.298814875757 
Iteration 6 Log Likelihood:  -941.298814875796 
Iteration 7 Log Likelihood:  -941.298814875696 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6626.60660571315 
Iteration 2 Log Likelihood:  -6568.8644496535 
Iteration 3 Log Likelihood:  -6568.86443270189 
Iteration 4 Log Likelihood:  -6568.86441555989 
Iteration 5 Log Likelihood:  -6568.86439822208 
Iteration 6 Log Likelihood:  -6568.8643806853 
Iteration 7 Log Likelihood:  -6568.86436294635 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6625.84550201521 
Iteration 2 Log Likelihood:  -5707.89663690633 
Iteration 3 Log Likelihood:  -5707.89655010523 
Iteration 4 Log Likelihood:  -5707.89646119039 
Iteration 5 Log Likelihood:  -5707.89636985817 
Iteration 6 Log Likelihood:  -5707.89627600623 
Iteration 7 Log Likelihood:  -5707.89617952647 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6624.02311910123 
Iteration 2 Log Likelihood:  -941.049559400297 
Iteration 3 Log Likelihood:  -940.511210630689 
Iteration 4 Log Likelihood:  -939.586580485077 
Iteration 5 Log Likelihood:  -938.277232009769 
Iteration 6 Log Likelihood:  -936.818902036814 
Iteration 7 Log Likelihood:  -935.551188717657 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6626.68193623392 
Iteration 2 Log Likelihood:  -6568.94637672561 
Iteration 3 Log Likelihood:  -6568.94482351617 
Iteration 4 Log Likelihood:  -6568.94309531933 
Iteration 5 Log Likelihood:  -6568.94116335923 
Iteration 6 Log Likelihood:  -6568.93899298054 
Iteration 7 Log Likelihood:  -6568.93654187578 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6625.74639344323 
Iteration 2 Log Likelihood:  -5707.92086028901 
Iteration 3 Log Likelihood:  -5707.90662222246 
Iteration 4 Log Likelihood:  -5707.88613485116 
Iteration 5 Log Likelihood:  -5707.85451470707 
Iteration 6 Log Likelihood:  -5707.80103057031 
Iteration 7 Log Likelihood:  -5707.69818723175 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6623.57503398756 
Iteration 2 Log Likelihood:  -922.324522069673 
Iteration 3 Log Likelihood:  -873.370873224887 
Iteration 4 Log Likelihood:  -797.028720278008 
Iteration 5 Log Likelihood:  -784.156271737548 
Iteration 6 Log Likelihood:  -781.06648386406 
Iteration 7 Log Likelihood:  -780.536264273765 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6470.18662197052 
Iteration 2 Log Likelihood:  -6415.84232931265 
Iteration 3 Log Likelihood:  -6415.84232931265 
Iteration 4 Log Likelihood:  -6415.84232931265 
Iteration 5 Log Likelihood:  -6415.84232931265 
Iteration 6 Log Likelihood:  -6415.84232931265 
Iteration 7 Log Likelihood:  -6415.84232931265 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6467.74294414215 
Iteration 2 Log Likelihood:  -5581.71190057209 
Iteration 3 Log Likelihood:  -5581.71190057209 
Iteration 4 Log Likelihood:  -5581.71190057208 
Iteration 5 Log Likelihood:  -5581.71190057208 
Iteration 6 Log Likelihood:  -5581.71190057209 
Iteration 7 Log Likelihood:  -5581.71190057208 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6461.97024075177 
Iteration 2 Log Likelihood:  -998.085421150425 
Iteration 3 Log Likelihood:  -998.085421150436 
Iteration 4 Log Likelihood:  -998.085421150467 
Iteration 5 Log Likelihood:  -998.085421150443 
Iteration 6 Log Likelihood:  -998.085421150443 
Iteration 7 Log Likelihood:  -998.08542115043 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6470.56662767173 
Iteration 2 Log Likelihood:  -6416.20437432266 
Iteration 3 Log Likelihood:  -6416.20436367532 
Iteration 4 Log Likelihood:  -6416.20435299246 
Iteration 5 Log Likelihood:  -6416.20434227371 
Iteration 6 Log Likelihood:  -6416.20433151873 
Iteration 7 Log Likelihood:  -6416.20432072719 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6468.11797920325 
Iteration 2 Log Likelihood:  -5581.93844712732 
Iteration 3 Log Likelihood:  -5581.93841079735 
Iteration 4 Log Likelihood:  -5581.93837408507 
Iteration 5 Log Likelihood:  -5581.93833698119 
Iteration 6 Log Likelihood:  -5581.93829947812 
Iteration 7 Log Likelihood:  -5581.93826156806 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6462.34833900317 
Iteration 2 Log Likelihood:  -998.314692043326 
Iteration 3 Log Likelihood:  -998.306246682671 
Iteration 4 Log Likelihood:  -998.290133175546 
Iteration 5 Log Likelihood:  -998.259733705143 
Iteration 6 Log Likelihood:  -998.203708423672 
Iteration 7 Log Likelihood:  -998.104601652094 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6470.07676920135 
Iteration 2 Log Likelihood:  -6415.76144574807 
Iteration 3 Log Likelihood:  -6415.76053523238 
Iteration 4 Log Likelihood:  -6415.75959381744 
Iteration 5 Log Likelihood:  -6415.75861892141 
Iteration 6 Log Likelihood:  -6415.75760779404 
Iteration 7 Log Likelihood:  -6415.75655750039 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6467.34947157973 
Iteration 2 Log Likelihood:  -5581.65421764213 
Iteration 3 Log Likelihood:  -5581.65006610827 
Iteration 4 Log Likelihood:  -5581.64538917766 
Iteration 5 Log Likelihood:  -5581.64007462309 
Iteration 6 Log Likelihood:  -5581.63397752629 
Iteration 7 Log Likelihood:  -5581.62690700169 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6461.04995820504 
Iteration 2 Log Likelihood:  -992.41461722123 
Iteration 3 Log Likelihood:  -966.724254222545 
Iteration 4 Log Likelihood:  -933.549012748151 
Iteration 5 Log Likelihood:  -912.149745647193 
Iteration 6 Log Likelihood:  -909.608351194857 
Iteration 7 Log Likelihood:  -909.600055378909 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6470.18662197052 
Iteration 2 Log Likelihood:  -6415.84232931265 
Iteration 3 Log Likelihood:  -6415.84232931265 
Iteration 4 Log Likelihood:  -6415.84232931265 
Iteration 5 Log Likelihood:  -6415.84232931265 
Iteration 6 Log Likelihood:  -6415.84232931265 
Iteration 7 Log Likelihood:  -6415.84232931265 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6467.74294414215 
Iteration 2 Log Likelihood:  -5581.71190057209 
Iteration 3 Log Likelihood:  -5581.71190057208 
Iteration 4 Log Likelihood:  -5581.71190057208 
Iteration 5 Log Likelihood:  -5581.71190057208 
Iteration 6 Log Likelihood:  -5581.71190057208 
Iteration 7 Log Likelihood:  -5581.71190057209 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6461.97024075177 
Iteration 2 Log Likelihood:  -998.085421150417 
Iteration 3 Log Likelihood:  -998.085421150402 
Iteration 4 Log Likelihood:  -998.085421150463 
Iteration 5 Log Likelihood:  -998.085421150452 
Iteration 6 Log Likelihood:  -998.085421150501 
Iteration 7 Log Likelihood:  -998.085421150483 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6470.56257398282 
Iteration 2 Log Likelihood:  -6416.20110964876 
Iteration 3 Log Likelihood:  -6416.20108350109 
Iteration 4 Log Likelihood:  -6416.20105725078 
Iteration 5 Log Likelihood:  -6416.20103089674 
Iteration 6 Log Likelihood:  -6416.2010044383 
Iteration 7 Log Likelihood:  -6416.20097787475 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6468.10927285168 
Iteration 2 Log Likelihood:  -5581.93608149722 
Iteration 3 Log Likelihood:  -5581.93596303411 
Iteration 4 Log Likelihood:  -5581.93584160958 
Iteration 5 Log Likelihood:  -5581.9357167408 
Iteration 6 Log Likelihood:  -5581.93558829913 
Iteration 7 Log Likelihood:  -5581.93545614989 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6462.33392589963 
Iteration 2 Log Likelihood:  -998.309992152731 
Iteration 3 Log Likelihood:  -998.293652732086 
Iteration 4 Log Likelihood:  -998.257417524626 
Iteration 5 Log Likelihood:  -998.177475532425 
Iteration 6 Log Likelihood:  -998.004962840942 
Iteration 7 Log Likelihood:  -997.655304072152 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6470.04016569525 
Iteration 2 Log Likelihood:  -6415.73066996576 
Iteration 3 Log Likelihood:  -6415.72843403763 
Iteration 4 Log Likelihood:  -6415.72611357951 
Iteration 5 Log Likelihood:  -6415.72370307856 
Iteration 6 Log Likelihood:  -6415.72119653541 
Iteration 7 Log Likelihood:  -6415.71858737804 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6467.27078753667 
Iteration 2 Log Likelihood:  -5581.62034059872 
Iteration 3 Log Likelihood:  -5581.60447124805 
Iteration 4 Log Likelihood:  -5581.58345127613 
Iteration 5 Log Likelihood:  -5581.55469517968 
Iteration 6 Log Likelihood:  -5581.51379399928 
Iteration 7 Log Likelihood:  -5581.45271360608 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6460.91958200957 
Iteration 2 Log Likelihood:  -991.394300504142 
Iteration 3 Log Likelihood:  -949.204623438047 
Iteration 4 Log Likelihood:  -910.940409253628 
Iteration 5 Log Likelihood:  -895.840027306969 
Iteration 6 Log Likelihood:  -894.014871563951 
Iteration 7 Log Likelihood:  -893.502624459662 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6547.02206940889 
Iteration 2 Log Likelihood:  -6490.64674132345 
Iteration 3 Log Likelihood:  -6490.64674132345 
Iteration 4 Log Likelihood:  -6490.64674132345 
Iteration 5 Log Likelihood:  -6490.64674132345 
Iteration 6 Log Likelihood:  -6490.64674132346 
Iteration 7 Log Likelihood:  -6490.64674132345 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.54465722081 
Iteration 2 Log Likelihood:  -5635.396097088 
Iteration 3 Log Likelihood:  -5635.396097088 
Iteration 4 Log Likelihood:  -5635.396097088 
Iteration 5 Log Likelihood:  -5635.396097088 
Iteration 6 Log Likelihood:  -5635.396097088 
Iteration 7 Log Likelihood:  -5635.396097088 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6542.04075122189 
Iteration 2 Log Likelihood:  -848.956522946696 
Iteration 3 Log Likelihood:  -848.956522946669 
Iteration 4 Log Likelihood:  -848.956522946628 
Iteration 5 Log Likelihood:  -848.956522946745 
Iteration 6 Log Likelihood:  -848.956522946646 
Iteration 7 Log Likelihood:  -848.956522946653 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6543.18550751938 
Iteration 2 Log Likelihood:  -6486.90433061713 
Iteration 3 Log Likelihood:  -6486.90426532433 
Iteration 4 Log Likelihood:  -6486.90420022697 
Iteration 5 Log Likelihood:  -6486.9041353163 
Iteration 6 Log Likelihood:  -6486.90407058359 
Iteration 7 Log Likelihood:  -6486.90400602005 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.61624081713 
Iteration 2 Log Likelihood:  -5632.19384208168 
Iteration 3 Log Likelihood:  -5632.19348336499 
Iteration 4 Log Likelihood:  -5632.19312419669 
Iteration 5 Log Likelihood:  -5632.19276440965 
Iteration 6 Log Likelihood:  -5632.19240384554 
Iteration 7 Log Likelihood:  -5632.19204233569 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6537.89698080656 
Iteration 2 Log Likelihood:  -847.084213111818 
Iteration 3 Log Likelihood:  -847.054200588505 
Iteration 4 Log Likelihood:  -846.987969367079 
Iteration 5 Log Likelihood:  -846.846523991689 
Iteration 6 Log Likelihood:  -846.56680332289 
Iteration 7 Log Likelihood:  -846.09445065768 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6546.86431577704 
Iteration 2 Log Likelihood:  -6490.50088853892 
Iteration 3 Log Likelihood:  -6490.49554275256 
Iteration 4 Log Likelihood:  -6490.49023591663 
Iteration 5 Log Likelihood:  -6490.48489896518 
Iteration 6 Log Likelihood:  -6490.47945875827 
Iteration 7 Log Likelihood:  -6490.47383749177 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.38011726336 
Iteration 2 Log Likelihood:  -5635.25497628757 
Iteration 3 Log Likelihood:  -5635.2231741771 
Iteration 4 Log Likelihood:  -5635.18788066596 
Iteration 5 Log Likelihood:  -5635.14597632885 
Iteration 6 Log Likelihood:  -5635.09222152582 
Iteration 7 Log Likelihood:  -5635.0170695006 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.85301731991 
Iteration 2 Log Likelihood:  -845.972441013397 
Iteration 3 Log Likelihood:  -821.537976401204 
Iteration 4 Log Likelihood:  -794.476087857294 
Iteration 5 Log Likelihood:  -772.365467479796 
Iteration 6 Log Likelihood:  -761.134525262705 
Iteration 7 Log Likelihood:  -758.046338897197 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6547.02206940889 
Iteration 2 Log Likelihood:  -6490.64674132346 
Iteration 3 Log Likelihood:  -6490.64674132345 
Iteration 4 Log Likelihood:  -6490.64674132345 
Iteration 5 Log Likelihood:  -6490.64674132345 
Iteration 6 Log Likelihood:  -6490.64674132345 
Iteration 7 Log Likelihood:  -6490.64674132345 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.54465722081 
Iteration 2 Log Likelihood:  -5635.396097088 
Iteration 3 Log Likelihood:  -5635.396097088 
Iteration 4 Log Likelihood:  -5635.396097088 
Iteration 5 Log Likelihood:  -5635.396097088 
Iteration 6 Log Likelihood:  -5635.396097088 
Iteration 7 Log Likelihood:  -5635.396097088 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6542.04075122189 
Iteration 2 Log Likelihood:  -848.956522946656 
Iteration 3 Log Likelihood:  -848.956522946632 
Iteration 4 Log Likelihood:  -848.956522946661 
Iteration 5 Log Likelihood:  -848.956522946649 
Iteration 6 Log Likelihood:  -848.956522946615 
Iteration 7 Log Likelihood:  -848.956522946628 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6543.17319760903 
Iteration 2 Log Likelihood:  -6486.89068444812 
Iteration 3 Log Likelihood:  -6486.89051614684 
Iteration 4 Log Likelihood:  -6486.89034775035 
Iteration 5 Log Likelihood:  -6486.8901792534 
Iteration 6 Log Likelihood:  -6486.89001065358 
Iteration 7 Log Likelihood:  -6486.88984194817 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.61581386342 
Iteration 2 Log Likelihood:  -5632.18730733576 
Iteration 3 Log Likelihood:  -5632.18679902919 
Iteration 4 Log Likelihood:  -5632.18628889276 
Iteration 5 Log Likelihood:  -5632.18577670759 
Iteration 6 Log Likelihood:  -5632.18526234402 
Iteration 7 Log Likelihood:  -5632.18474565874 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6537.89313380471 
Iteration 2 Log Likelihood:  -846.949518946151 
Iteration 3 Log Likelihood:  -846.824269419315 
Iteration 4 Log Likelihood:  -846.614273053285 
Iteration 5 Log Likelihood:  -846.278931679798 
Iteration 6 Log Likelihood:  -845.770939716124 
Iteration 7 Log Likelihood:  -845.054080831431 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6546.75072976865 
Iteration 2 Log Likelihood:  -6490.36826215993 
Iteration 3 Log Likelihood:  -6490.35410024252 
Iteration 4 Log Likelihood:  -6490.33981041898 
Iteration 5 Log Likelihood:  -6490.32533188781 
Iteration 6 Log Likelihood:  -6490.3105802501 
Iteration 7 Log Likelihood:  -6490.29544665866 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.37615457807 
Iteration 2 Log Likelihood:  -5635.19290766447 
Iteration 3 Log Likelihood:  -5635.14822573109 
Iteration 4 Log Likelihood:  -5635.09910766594 
Iteration 5 Log Likelihood:  -5635.04229192178 
Iteration 6 Log Likelihood:  -5634.97210724974 
Iteration 7 Log Likelihood:  -5634.87826667035 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.81707979932 
Iteration 2 Log Likelihood:  -842.507728893512 
Iteration 3 Log Likelihood:  -789.455504896671 
Iteration 4 Log Likelihood:  -741.729703212219 
Iteration 5 Log Likelihood:  -708.695299931128 
Iteration 6 Log Likelihood:  -697.040737955816 
Iteration 7 Log Likelihood:  -694.8528309859 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.59366181274 
Iteration 2 Log Likelihood:  -6472.83831655605 
Iteration 3 Log Likelihood:  -6472.83831655605 
Iteration 4 Log Likelihood:  -6472.83831655605 
Iteration 5 Log Likelihood:  -6472.83831655605 
Iteration 6 Log Likelihood:  -6472.83831655605 
Iteration 7 Log Likelihood:  -6472.83831655605 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.85890284306 
Iteration 2 Log Likelihood:  -5632.35491852838 
Iteration 3 Log Likelihood:  -5632.35491852838 
Iteration 4 Log Likelihood:  -5632.35491852838 
Iteration 5 Log Likelihood:  -5632.35491852838 
Iteration 6 Log Likelihood:  -5632.35491852838 
Iteration 7 Log Likelihood:  -5632.35491852838 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.74172449943 
Iteration 2 Log Likelihood:  -953.258502511866 
Iteration 3 Log Likelihood:  -953.258502511871 
Iteration 4 Log Likelihood:  -953.258502511876 
Iteration 5 Log Likelihood:  -953.258502511846 
Iteration 6 Log Likelihood:  -953.258502511906 
Iteration 7 Log Likelihood:  -953.258502511855 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6524.01277002187 
Iteration 2 Log Likelihood:  -6469.35051449912 
Iteration 3 Log Likelihood:  -6469.35000470733 
Iteration 4 Log Likelihood:  -6469.34948879823 
Iteration 5 Log Likelihood:  -6469.34896619974 
Iteration 6 Log Likelihood:  -6469.34843633006 
Iteration 7 Log Likelihood:  -6469.34789859733 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.08941210654 
Iteration 2 Log Likelihood:  -5629.31778597437 
Iteration 3 Log Likelihood:  -5629.31650361826 
Iteration 4 Log Likelihood:  -5629.31519488258 
Iteration 5 Log Likelihood:  -5629.31385282775 
Iteration 6 Log Likelihood:  -5629.31247003727 
Iteration 7 Log Likelihood:  -5629.31103853382 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.64520467968 
Iteration 2 Log Likelihood:  -951.506982793842 
Iteration 3 Log Likelihood:  -951.234717016375 
Iteration 4 Log Likelihood:  -950.67738144763 
Iteration 5 Log Likelihood:  -949.667305144525 
Iteration 6 Log Likelihood:  -948.227441780258 
Iteration 7 Log Likelihood:  -946.782871712051 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6526.25565191989 
Iteration 2 Log Likelihood:  -6471.62168536778 
Iteration 3 Log Likelihood:  -6471.57026409217 
Iteration 4 Log Likelihood:  -6471.50634319795 
Iteration 5 Log Likelihood:  -6471.42442940724 
Iteration 6 Log Likelihood:  -6471.31814993753 
Iteration 7 Log Likelihood:  -6471.18068711073 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.37159791454 
Iteration 2 Log Likelihood:  -5631.06256614796 
Iteration 3 Log Likelihood:  -5630.80624771816 
Iteration 4 Log Likelihood:  -5630.1899895053 
Iteration 5 Log Likelihood:  -5628.37933473426 
Iteration 6 Log Likelihood:  -5623.69769288513 
Iteration 7 Log Likelihood:  -5620.00649044035 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.58684173451 
Iteration 2 Log Likelihood:  -900.997208180526 
Iteration 3 Log Likelihood:  -850.105116627726 
Iteration 4 Log Likelihood:  -848.885777673129 
Iteration 5 Log Likelihood:  -848.700561613997 
Iteration 6 Log Likelihood:  -848.342348877836 
Iteration 7 Log Likelihood:  -847.863006225829 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.59366181274 
Iteration 2 Log Likelihood:  -6472.83831655604 
Iteration 3 Log Likelihood:  -6472.83831655604 
Iteration 4 Log Likelihood:  -6472.83831655605 
Iteration 5 Log Likelihood:  -6472.83831655605 
Iteration 6 Log Likelihood:  -6472.83831655605 
Iteration 7 Log Likelihood:  -6472.83831655605 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.85890284306 
Iteration 2 Log Likelihood:  -5632.35491852838 
Iteration 3 Log Likelihood:  -5632.35491852838 
Iteration 4 Log Likelihood:  -5632.35491852838 
Iteration 5 Log Likelihood:  -5632.35491852838 
Iteration 6 Log Likelihood:  -5632.35491852838 
Iteration 7 Log Likelihood:  -5632.35491852838 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.74172449943 
Iteration 2 Log Likelihood:  -953.258502511976 
Iteration 3 Log Likelihood:  -953.258502511904 
Iteration 4 Log Likelihood:  -953.258502511823 
Iteration 5 Log Likelihood:  -953.258502511922 
Iteration 6 Log Likelihood:  -953.258502511901 
Iteration 7 Log Likelihood:  -953.258502511949 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.94573485691 
Iteration 2 Log Likelihood:  -6469.2857374707 
Iteration 3 Log Likelihood:  -6469.28406780802 
Iteration 4 Log Likelihood:  -6469.28237461572 
Iteration 5 Log Likelihood:  -6469.28065718713 
Iteration 6 Log Likelihood:  -6469.27891476668 
Iteration 7 Log Likelihood:  -6469.27714656441 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.03903993908 
Iteration 2 Log Likelihood:  -5629.25770935091 
Iteration 3 Log Likelihood:  -5629.25283531297 
Iteration 4 Log Likelihood:  -5629.24769329297 
Iteration 5 Log Likelihood:  -5629.24224412437 
Iteration 6 Log Likelihood:  -5629.23644186241 
Iteration 7 Log Likelihood:  -5629.23023241878 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.60812898799 
Iteration 2 Log Likelihood:  -951.475194319849 
Iteration 3 Log Likelihood:  -951.119580109365 
Iteration 4 Log Likelihood:  -950.338122221979 
Iteration 5 Log Likelihood:  -948.897621059685 
Iteration 6 Log Likelihood:  -946.933127872597 
Iteration 7 Log Likelihood:  -945.067808779561 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.65059953143 
Iteration 2 Log Likelihood:  -6470.95156303401 
Iteration 3 Log Likelihood:  -6470.79234853566 
Iteration 4 Log Likelihood:  -6470.60625639111 
Iteration 5 Log Likelihood:  -6470.38733673346 
Iteration 6 Log Likelihood:  -6470.13268242982 
Iteration 7 Log Likelihood:  -6469.84641630197 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.91698858248 
Iteration 2 Log Likelihood:  -5630.26652295228 
Iteration 3 Log Likelihood:  -5629.40680187093 
Iteration 4 Log Likelihood:  -5627.31725536621 
Iteration 5 Log Likelihood:  -5622.92354661394 
Iteration 6 Log Likelihood:  -5619.41464412098 
Iteration 7 Log Likelihood:  -5618.68041396388 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.25221120855 
Iteration 2 Log Likelihood:  -899.704421331284 
Iteration 3 Log Likelihood:  -830.819966283382 
Iteration 4 Log Likelihood:  -822.14151060457 
Iteration 5 Log Likelihood:  -820.233472247881 
Iteration 6 Log Likelihood:  -819.63840881299 
Iteration 7 Log Likelihood:  -819.10129748005 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6613.03995016823 
Iteration 2 Log Likelihood:  -6555.28965095842 
Iteration 3 Log Likelihood:  -6555.28965095842 
Iteration 4 Log Likelihood:  -6555.28965095842 
Iteration 5 Log Likelihood:  -6555.28965095842 
Iteration 6 Log Likelihood:  -6555.28965095842 
Iteration 7 Log Likelihood:  -6555.28965095842 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.29296800933 
Iteration 2 Log Likelihood:  -5693.03320519138 
Iteration 3 Log Likelihood:  -5693.03320519138 
Iteration 4 Log Likelihood:  -5693.03320519138 
Iteration 5 Log Likelihood:  -5693.03320519138 
Iteration 6 Log Likelihood:  -5693.03320519138 
Iteration 7 Log Likelihood:  -5693.03320519138 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6610.51179941332 
Iteration 2 Log Likelihood:  -889.547112789265 
Iteration 3 Log Likelihood:  -889.547112789167 
Iteration 4 Log Likelihood:  -889.547112789258 
Iteration 5 Log Likelihood:  -889.547112789342 
Iteration 6 Log Likelihood:  -889.547112789249 
Iteration 7 Log Likelihood:  -889.547112789288 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6615.56086761156 
Iteration 2 Log Likelihood:  -6557.72852455152 
Iteration 3 Log Likelihood:  -6557.72851324773 
Iteration 4 Log Likelihood:  -6557.72850188239 
Iteration 5 Log Likelihood:  -6557.72849045486 
Iteration 6 Log Likelihood:  -6557.7284789645 
Iteration 7 Log Likelihood:  -6557.72846741067 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.71993187952 
Iteration 2 Log Likelihood:  -5694.40802339244 
Iteration 3 Log Likelihood:  -5694.40793184 
Iteration 4 Log Likelihood:  -5694.40783899192 
Iteration 5 Log Likelihood:  -5694.40774476151 
Iteration 6 Log Likelihood:  -5694.40764910669 
Iteration 7 Log Likelihood:  -5694.40755198321 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.72055246208 
Iteration 2 Log Likelihood:  -886.300086128423 
Iteration 3 Log Likelihood:  -886.135168804185 
Iteration 4 Log Likelihood:  -885.838510974739 
Iteration 5 Log Likelihood:  -885.369276648054 
Iteration 6 Log Likelihood:  -884.75332906734 
Iteration 7 Log Likelihood:  -884.118188186156 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.82566751012 
Iteration 2 Log Likelihood:  -6555.08948325966 
Iteration 3 Log Likelihood:  -6555.08835018145 
Iteration 4 Log Likelihood:  -6555.08715021227 
Iteration 5 Log Likelihood:  -6555.08587626625 
Iteration 6 Log Likelihood:  -6555.08452041077 
Iteration 7 Log Likelihood:  -6555.08307374101 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6611.98663115531 
Iteration 2 Log Likelihood:  -5692.88588795975 
Iteration 3 Log Likelihood:  -5692.87419864572 
Iteration 4 Log Likelihood:  -5692.85964660111 
Iteration 5 Log Likelihood:  -5692.84061549527 
Iteration 6 Log Likelihood:  -5692.81410882762 
Iteration 7 Log Likelihood:  -5692.77409932626 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6610.05820488649 
Iteration 2 Log Likelihood:  -878.363676264934 
Iteration 3 Log Likelihood:  -840.115284377878 
Iteration 4 Log Likelihood:  -824.189832294583 
Iteration 5 Log Likelihood:  -809.396955263863 
Iteration 6 Log Likelihood:  -808.132173865588 
Iteration 7 Log Likelihood:  -807.918074746268 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6613.03995016823 
Iteration 2 Log Likelihood:  -6555.28965095842 
Iteration 3 Log Likelihood:  -6555.28965095842 
Iteration 4 Log Likelihood:  -6555.28965095842 
Iteration 5 Log Likelihood:  -6555.28965095842 
Iteration 6 Log Likelihood:  -6555.28965095842 
Iteration 7 Log Likelihood:  -6555.28965095842 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.29296800933 
Iteration 2 Log Likelihood:  -5693.03320519138 
Iteration 3 Log Likelihood:  -5693.03320519138 
Iteration 4 Log Likelihood:  -5693.03320519138 
Iteration 5 Log Likelihood:  -5693.03320519138 
Iteration 6 Log Likelihood:  -5693.03320519138 
Iteration 7 Log Likelihood:  -5693.03320519138 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6610.51179941332 
Iteration 2 Log Likelihood:  -889.547112789208 
Iteration 3 Log Likelihood:  -889.547112789252 
Iteration 4 Log Likelihood:  -889.547112789416 
Iteration 5 Log Likelihood:  -889.547112789348 
Iteration 6 Log Likelihood:  -889.547112789381 
Iteration 7 Log Likelihood:  -889.547112789305 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6615.55410038012 
Iteration 2 Log Likelihood:  -6557.72249727932 
Iteration 3 Log Likelihood:  -6557.72246141892 
Iteration 4 Log Likelihood:  -6557.72242527484 
Iteration 5 Log Likelihood:  -6557.72238884327 
Iteration 6 Log Likelihood:  -6557.72235212075 
Iteration 7 Log Likelihood:  -6557.72231510374 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.69966608938 
Iteration 2 Log Likelihood:  -5694.40453533956 
Iteration 3 Log Likelihood:  -5694.40436859951 
Iteration 4 Log Likelihood:  -5694.40419898915 
Iteration 5 Log Likelihood:  -5694.40402624705 
Iteration 6 Log Likelihood:  -5694.40385027985 
Iteration 7 Log Likelihood:  -5694.40367098984 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.67982236763 
Iteration 2 Log Likelihood:  -886.110912332958 
Iteration 3 Log Likelihood:  -885.838029539556 
Iteration 4 Log Likelihood:  -885.407231786102 
Iteration 5 Log Likelihood:  -884.788709544689 
Iteration 6 Log Likelihood:  -884.021236430403 
Iteration 7 Log Likelihood:  -883.245302873226 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.76089965266 
Iteration 2 Log Likelihood:  -6555.02930981617 
Iteration 3 Log Likelihood:  -6555.02559593128 
Iteration 4 Log Likelihood:  -6555.02156587551 
Iteration 5 Log Likelihood:  -6555.01717881075 
Iteration 6 Log Likelihood:  -6555.01238745546 
Iteration 7 Log Likelihood:  -6555.00713681398 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6611.79130615097 
Iteration 2 Log Likelihood:  -5692.83401474876 
Iteration 3 Log Likelihood:  -5692.81004654239 
Iteration 4 Log Likelihood:  -5692.77924346499 
Iteration 5 Log Likelihood:  -5692.73777147445 
Iteration 6 Log Likelihood:  -5692.67856680856 
Iteration 7 Log Likelihood:  -5692.58760472755 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.66265586443 
Iteration 2 Log Likelihood:  -871.452529251206 
Iteration 3 Log Likelihood:  -821.519576644368 
Iteration 4 Log Likelihood:  -793.873178819843 
Iteration 5 Log Likelihood:  -788.113369761457 
Iteration 6 Log Likelihood:  -786.787201501869 
Iteration 7 Log Likelihood:  -785.777806852957 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6600.2971625875 
Iteration 2 Log Likelihood:  -6542.75046696874 
Iteration 3 Log Likelihood:  -6542.75046696874 
Iteration 4 Log Likelihood:  -6542.75046696874 
Iteration 5 Log Likelihood:  -6542.75046696874 
Iteration 6 Log Likelihood:  -6542.75046696874 
Iteration 7 Log Likelihood:  -6542.75046696874 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6599.40949430672 
Iteration 2 Log Likelihood:  -5684.01288951535 
Iteration 3 Log Likelihood:  -5684.01288951535 
Iteration 4 Log Likelihood:  -5684.01288951535 
Iteration 5 Log Likelihood:  -5684.01288951535 
Iteration 6 Log Likelihood:  -5684.01288951535 
Iteration 7 Log Likelihood:  -5684.01288951535 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6597.29034241358 
Iteration 2 Log Likelihood:  -894.233295545722 
Iteration 3 Log Likelihood:  -894.233295545756 
Iteration 4 Log Likelihood:  -894.233295545799 
Iteration 5 Log Likelihood:  -894.233295545758 
Iteration 6 Log Likelihood:  -894.233295545718 
Iteration 7 Log Likelihood:  -894.233295545778 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6600.26494219265 
Iteration 2 Log Likelihood:  -6542.71790753597 
Iteration 3 Log Likelihood:  -6542.71790478973 
Iteration 4 Log Likelihood:  -6542.71790204264 
Iteration 5 Log Likelihood:  -6542.71789929463 
Iteration 6 Log Likelihood:  -6542.71789654573 
Iteration 7 Log Likelihood:  -6542.71789379592 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6599.37483348226 
Iteration 2 Log Likelihood:  -5683.97618243261 
Iteration 3 Log Likelihood:  -5683.97615862372 
Iteration 4 Log Likelihood:  -5683.97613445713 
Iteration 5 Log Likelihood:  -5683.97610992741 
Iteration 6 Log Likelihood:  -5683.97608502936 
Iteration 7 Log Likelihood:  -5683.97605975773 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6597.24281246416 
Iteration 2 Log Likelihood:  -894.16931970871 
Iteration 3 Log Likelihood:  -894.150085031666 
Iteration 4 Log Likelihood:  -894.103803863321 
Iteration 5 Log Likelihood:  -893.990041782366 
Iteration 6 Log Likelihood:  -893.71767160848 
Iteration 7 Log Likelihood:  -893.147906978143 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6600.28841665984 
Iteration 2 Log Likelihood:  -6542.73841212556 
Iteration 3 Log Likelihood:  -6542.73819002244 
Iteration 4 Log Likelihood:  -6542.73796731303 
Iteration 5 Log Likelihood:  -6542.73774403437 
Iteration 6 Log Likelihood:  -6542.737520225 
Iteration 7 Log Likelihood:  -6542.73729592034 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6599.38954886175 
Iteration 2 Log Likelihood:  -5684.00107102776 
Iteration 3 Log Likelihood:  -5683.99928779353 
Iteration 4 Log Likelihood:  -5683.99725275717 
Iteration 5 Log Likelihood:  -5683.99492797321 
Iteration 6 Log Likelihood:  -5683.99226917721 
Iteration 7 Log Likelihood:  -5683.98922418913 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6597.18032861241 
Iteration 2 Log Likelihood:  -893.820963692892 
Iteration 3 Log Likelihood:  -885.881846624736 
Iteration 4 Log Likelihood:  -827.562968300292 
Iteration 5 Log Likelihood:  -788.681095201228 
Iteration 6 Log Likelihood:  -784.633139509679 
Iteration 7 Log Likelihood:  -784.571354596762 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6600.2971625875 
Iteration 2 Log Likelihood:  -6542.75046696874 
Iteration 3 Log Likelihood:  -6542.75046696874 
Iteration 4 Log Likelihood:  -6542.75046696874 
Iteration 5 Log Likelihood:  -6542.75046696874 
Iteration 6 Log Likelihood:  -6542.75046696874 
Iteration 7 Log Likelihood:  -6542.75046696874 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6599.40949430672 
Iteration 2 Log Likelihood:  -5684.01288951535 
Iteration 3 Log Likelihood:  -5684.01288951535 
Iteration 4 Log Likelihood:  -5684.01288951534 
Iteration 5 Log Likelihood:  -5684.01288951535 
Iteration 6 Log Likelihood:  -5684.01288951535 
Iteration 7 Log Likelihood:  -5684.01288951534 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6597.29034241358 
Iteration 2 Log Likelihood:  -894.233295545769 
Iteration 3 Log Likelihood:  -894.233295545775 
Iteration 4 Log Likelihood:  -894.233295545761 
Iteration 5 Log Likelihood:  -894.233295545768 
Iteration 6 Log Likelihood:  -894.233295545728 
Iteration 7 Log Likelihood:  -894.233295545677 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6600.26293865132 
Iteration 2 Log Likelihood:  -6542.71656931201 
Iteration 3 Log Likelihood:  -6542.71655767248 
Iteration 4 Log Likelihood:  -6542.71654598156 
Iteration 5 Log Likelihood:  -6542.71653423368 
Iteration 6 Log Likelihood:  -6542.71652242855 
Iteration 7 Log Likelihood:  -6542.71651056586 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6599.36441775667 
Iteration 2 Log Likelihood:  -5683.97415898943 
Iteration 3 Log Likelihood:  -5683.97407748555 
Iteration 4 Log Likelihood:  -5683.97399384229 
Iteration 5 Log Likelihood:  -5683.97390792258 
Iteration 6 Log Likelihood:  -5683.97381964628 
Iteration 7 Log Likelihood:  -5683.97372892949 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6597.21827687029 
Iteration 2 Log Likelihood:  -894.153547305763 
Iteration 3 Log Likelihood:  -894.120150603027 
Iteration 4 Log Likelihood:  -894.045960419065 
Iteration 5 Log Likelihood:  -893.877291881435 
Iteration 6 Log Likelihood:  -893.50111371074 
Iteration 7 Log Likelihood:  -892.768207609965 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6600.27038347711 
Iteration 2 Log Likelihood:  -6542.72556815779 
Iteration 3 Log Likelihood:  -6542.72457255461 
Iteration 4 Log Likelihood:  -6542.72353302304 
Iteration 5 Log Likelihood:  -6542.72244689433 
Iteration 6 Log Likelihood:  -6542.72131172561 
Iteration 7 Log Likelihood:  -6542.7201248673 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6599.2957558986 
Iteration 2 Log Likelihood:  -5683.9718854632 
Iteration 3 Log Likelihood:  -5683.96137803181 
Iteration 4 Log Likelihood:  -5683.94729644646 
Iteration 5 Log Likelihood:  -5683.92783261936 
Iteration 6 Log Likelihood:  -5683.89990191161 
Iteration 7 Log Likelihood:  -5683.85795813512 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6596.95918706562 
Iteration 2 Log Likelihood:  -892.996857756058 
Iteration 3 Log Likelihood:  -873.506758209949 
Iteration 4 Log Likelihood:  -815.122594420338 
Iteration 5 Log Likelihood:  -772.55127683963 
Iteration 6 Log Likelihood:  -760.882478925097 
Iteration 7 Log Likelihood:  -756.45383527807 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6502.99227473664 
Iteration 2 Log Likelihood:  -6451.52249098329 
Iteration 3 Log Likelihood:  -6451.52249098329 
Iteration 4 Log Likelihood:  -6451.52249098329 
Iteration 5 Log Likelihood:  -6451.52249098329 
Iteration 6 Log Likelihood:  -6451.52249098329 
Iteration 7 Log Likelihood:  -6451.52249098328 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6500.75672037932 
Iteration 2 Log Likelihood:  -5643.59217447293 
Iteration 3 Log Likelihood:  -5643.59217447293 
Iteration 4 Log Likelihood:  -5643.59217447293 
Iteration 5 Log Likelihood:  -5643.59217447293 
Iteration 6 Log Likelihood:  -5643.59217447293 
Iteration 7 Log Likelihood:  -5643.59217447293 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6495.38492442128 
Iteration 2 Log Likelihood:  -1178.50960229288 
Iteration 3 Log Likelihood:  -1178.50960229285 
Iteration 4 Log Likelihood:  -1178.5096022929 
Iteration 5 Log Likelihood:  -1178.50960229283 
Iteration 6 Log Likelihood:  -1178.50960229291 
Iteration 7 Log Likelihood:  -1178.50960229289 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6504.54500131622 
Iteration 2 Log Likelihood:  -6453.06108746733 
Iteration 3 Log Likelihood:  -6453.06094733288 
Iteration 4 Log Likelihood:  -6453.06080532331 
Iteration 5 Log Likelihood:  -6453.06066137742 
Iteration 6 Log Likelihood:  -6453.06051543243 
Iteration 7 Log Likelihood:  -6453.06036742392 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6502.2733387324 
Iteration 2 Log Likelihood:  -5644.94795693325 
Iteration 3 Log Likelihood:  -5644.94677764294 
Iteration 4 Log Likelihood:  -5644.94554806061 
Iteration 5 Log Likelihood:  -5644.94426277631 
Iteration 6 Log Likelihood:  -5644.94291571988 
Iteration 7 Log Likelihood:  -5644.94150004129 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6496.82855731885 
Iteration 2 Log Likelihood:  -1178.33455683313 
Iteration 3 Log Likelihood:  -1178.30085600629 
Iteration 4 Log Likelihood:  -1178.22399574833 
Iteration 5 Log Likelihood:  -1178.06496837069 
Iteration 6 Log Likelihood:  -1177.79406958636 
Iteration 7 Log Likelihood:  -1177.44892938707 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6502.29004997868 
Iteration 2 Log Likelihood:  -6450.81938384394 
Iteration 3 Log Likelihood:  -6450.8053106684 
Iteration 4 Log Likelihood:  -6450.78883515294 
Iteration 5 Log Likelihood:  -6450.76921485289 
Iteration 6 Log Likelihood:  -6450.74548976616 
Iteration 7 Log Likelihood:  -6450.71640900798 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6499.90949989112 
Iteration 2 Log Likelihood:  -5642.74227503689 
Iteration 3 Log Likelihood:  -5642.51451253307 
Iteration 4 Log Likelihood:  -5641.92749198215 
Iteration 5 Log Likelihood:  -5639.62055508 
Iteration 6 Log Likelihood:  -5630.73651618472 
Iteration 7 Log Likelihood:  -5626.19434905564 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6494.28972950588 
Iteration 2 Log Likelihood:  -1170.71562403294 
Iteration 3 Log Likelihood:  -1131.36380420645 
Iteration 4 Log Likelihood:  -1088.0513493453 
Iteration 5 Log Likelihood:  -1079.60159570216 
Iteration 6 Log Likelihood:  -1079.25627631629 
Iteration 7 Log Likelihood:  -1079.2473620252 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6502.99227473664 
Iteration 2 Log Likelihood:  -6451.52249098329 
Iteration 3 Log Likelihood:  -6451.52249098329 
Iteration 4 Log Likelihood:  -6451.52249098329 
Iteration 5 Log Likelihood:  -6451.52249098329 
Iteration 6 Log Likelihood:  -6451.52249098329 
Iteration 7 Log Likelihood:  -6451.52249098329 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6500.75672037932 
Iteration 2 Log Likelihood:  -5643.59217447293 
Iteration 3 Log Likelihood:  -5643.59217447293 
Iteration 4 Log Likelihood:  -5643.59217447293 
Iteration 5 Log Likelihood:  -5643.59217447293 
Iteration 6 Log Likelihood:  -5643.59217447293 
Iteration 7 Log Likelihood:  -5643.59217447293 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6495.38492442128 
Iteration 2 Log Likelihood:  -1178.50960229288 
Iteration 3 Log Likelihood:  -1178.50960229287 
Iteration 4 Log Likelihood:  -1178.50960229289 
Iteration 5 Log Likelihood:  -1178.5096022929 
Iteration 6 Log Likelihood:  -1178.50960229287 
Iteration 7 Log Likelihood:  -1178.5096022929 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6504.50245427304 
Iteration 2 Log Likelihood:  -6453.02210231083 
Iteration 3 Log Likelihood:  -6453.02161269024 
Iteration 4 Log Likelihood:  -6453.02111345071 
Iteration 5 Log Likelihood:  -6453.02060429214 
Iteration 6 Log Likelihood:  -6453.02008491273 
Iteration 7 Log Likelihood:  -6453.01955500127 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6502.18138203929 
Iteration 2 Log Likelihood:  -5644.91675569125 
Iteration 3 Log Likelihood:  -5644.91456730865 
Iteration 4 Log Likelihood:  -5644.91228072802 
Iteration 5 Log Likelihood:  -5644.90988520654 
Iteration 6 Log Likelihood:  -5644.90736935361 
Iteration 7 Log Likelihood:  -5644.90472030026 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6496.67416291279 
Iteration 2 Log Likelihood:  -1177.8823882989 
Iteration 3 Log Likelihood:  -1177.48265597556 
Iteration 4 Log Likelihood:  -1176.92048757691 
Iteration 5 Log Likelihood:  -1176.27153981914 
Iteration 6 Log Likelihood:  -1175.63621678124 
Iteration 7 Log Likelihood:  -1175.10015324608 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6501.90290082363 
Iteration 2 Log Likelihood:  -6450.43509973865 
Iteration 3 Log Likelihood:  -6450.38266676717 
Iteration 4 Log Likelihood:  -6450.31846553414 
Iteration 5 Log Likelihood:  -6450.23896278499 
Iteration 6 Log Likelihood:  -6450.13978547144 
Iteration 7 Log Likelihood:  -6450.01589988813 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6499.06775162883 
Iteration 2 Log Likelihood:  -5642.28171028824 
Iteration 3 Log Likelihood:  -5641.78062642037 
Iteration 4 Log Likelihood:  -5640.47670476238 
Iteration 5 Log Likelihood:  -5636.44332296758 
Iteration 6 Log Likelihood:  -5628.79460494393 
Iteration 7 Log Likelihood:  -5625.37782308678 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6492.86673214327 
Iteration 2 Log Likelihood:  -1155.8919042292 
Iteration 3 Log Likelihood:  -1093.17747248068 
Iteration 4 Log Likelihood:  -1068.94468351805 
Iteration 5 Log Likelihood:  -1063.35737031001 
Iteration 6 Log Likelihood:  -1056.74391934562 
Iteration 7 Log Likelihood:  -1053.56570027304 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6543.13267713308 
Iteration 2 Log Likelihood:  -6486.67064947066 
Iteration 3 Log Likelihood:  -6486.67064947066 
Iteration 4 Log Likelihood:  -6486.67064947066 
Iteration 5 Log Likelihood:  -6486.67064947066 
Iteration 6 Log Likelihood:  -6486.67064947066 
Iteration 7 Log Likelihood:  -6486.67064947066 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.8743323736 
Iteration 2 Log Likelihood:  -5628.63037962631 
Iteration 3 Log Likelihood:  -5628.63037962631 
Iteration 4 Log Likelihood:  -5628.63037962631 
Iteration 5 Log Likelihood:  -5628.63037962631 
Iteration 6 Log Likelihood:  -5628.63037962631 
Iteration 7 Log Likelihood:  -5628.63037962631 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6538.89599540886 
Iteration 2 Log Likelihood:  -817.056607684673 
Iteration 3 Log Likelihood:  -817.056607684688 
Iteration 4 Log Likelihood:  -817.05660768464 
Iteration 5 Log Likelihood:  -817.056607684692 
Iteration 6 Log Likelihood:  -817.056607684639 
Iteration 7 Log Likelihood:  -817.056607684688 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6543.23200871064 
Iteration 2 Log Likelihood:  -6486.76696232958 
Iteration 3 Log Likelihood:  -6486.766879899 
Iteration 4 Log Likelihood:  -6486.76679804091 
Iteration 5 Log Likelihood:  -6486.76671674095 
Iteration 6 Log Likelihood:  -6486.76663598463 
Iteration 7 Log Likelihood:  -6486.76655575733 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.98023838516 
Iteration 2 Log Likelihood:  -5628.69887039361 
Iteration 3 Log Likelihood:  -5628.69850928417 
Iteration 4 Log Likelihood:  -5628.69815344803 
Iteration 5 Log Likelihood:  -5628.69780270322 
Iteration 6 Log Likelihood:  -5628.69745686234 
Iteration 7 Log Likelihood:  -5628.69711573295 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6539.00949520139 
Iteration 2 Log Likelihood:  -817.042682512943 
Iteration 3 Log Likelihood:  -817.007137938672 
Iteration 4 Log Likelihood:  -816.942348434077 
Iteration 5 Log Likelihood:  -816.826636413703 
Iteration 6 Log Likelihood:  -816.628287581121 
Iteration 7 Log Likelihood:  -816.312236003559 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6542.78625896306 
Iteration 2 Log Likelihood:  -6486.33447965123 
Iteration 3 Log Likelihood:  -6486.32827224917 
Iteration 4 Log Likelihood:  -6486.32229335962 
Iteration 5 Log Likelihood:  -6486.31643458828 
Iteration 6 Log Likelihood:  -6486.31058110557 
Iteration 7 Log Likelihood:  -6486.30461095868 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.56084137858 
Iteration 2 Log Likelihood:  -5628.28939844288 
Iteration 3 Log Likelihood:  -5628.26412549538 
Iteration 4 Log Likelihood:  -5628.24019871786 
Iteration 5 Log Likelihood:  -5628.21633393153 
Iteration 6 Log Likelihood:  -5628.19115205638 
Iteration 7 Log Likelihood:  -5628.16299224327 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6538.58942796755 
Iteration 2 Log Likelihood:  -816.070708029978 
Iteration 3 Log Likelihood:  -799.690335326208 
Iteration 4 Log Likelihood:  -740.77167104496 
Iteration 5 Log Likelihood:  -727.055352383225 
Iteration 6 Log Likelihood:  -725.689170734679 
Iteration 7 Log Likelihood:  -724.991306521775 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6543.13267713308 
Iteration 2 Log Likelihood:  -6486.67064947066 
Iteration 3 Log Likelihood:  -6486.67064947066 
Iteration 4 Log Likelihood:  -6486.67064947066 
Iteration 5 Log Likelihood:  -6486.67064947066 
Iteration 6 Log Likelihood:  -6486.67064947066 
Iteration 7 Log Likelihood:  -6486.67064947066 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.8743323736 
Iteration 2 Log Likelihood:  -5628.63037962631 
Iteration 3 Log Likelihood:  -5628.63037962631 
Iteration 4 Log Likelihood:  -5628.63037962631 
Iteration 5 Log Likelihood:  -5628.63037962631 
Iteration 6 Log Likelihood:  -5628.63037962631 
Iteration 7 Log Likelihood:  -5628.63037962631 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6538.89599540886 
Iteration 2 Log Likelihood:  -817.056607684702 
Iteration 3 Log Likelihood:  -817.056607684602 
Iteration 4 Log Likelihood:  -817.056607684649 
Iteration 5 Log Likelihood:  -817.056607684661 
Iteration 6 Log Likelihood:  -817.056607684609 
Iteration 7 Log Likelihood:  -817.056607684691 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6543.21588683869 
Iteration 2 Log Likelihood:  -6486.75094921234 
Iteration 3 Log Likelihood:  -6486.75064519282 
Iteration 4 Log Likelihood:  -6486.75033884663 
Iteration 5 Log Likelihood:  -6486.75003012417 
Iteration 6 Log Likelihood:  -6486.74971897331 
Iteration 7 Log Likelihood:  -6486.7494053398 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.97497044961 
Iteration 2 Log Likelihood:  -5628.68521747543 
Iteration 3 Log Likelihood:  -5628.6844127635 
Iteration 4 Log Likelihood:  -5628.68359909961 
Iteration 5 Log Likelihood:  -5628.68277533255 
Iteration 6 Log Likelihood:  -5628.68194020651 
Iteration 7 Log Likelihood:  -5628.68109234471 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6539.00902525874 
Iteration 2 Log Likelihood:  -816.965281644771 
Iteration 3 Log Likelihood:  -816.853206072777 
Iteration 4 Log Likelihood:  -816.653897371063 
Iteration 5 Log Likelihood:  -816.331800106526 
Iteration 6 Log Likelihood:  -815.869868089896 
Iteration 7 Log Likelihood:  -815.277567054457 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6542.64093712284 
Iteration 2 Log Likelihood:  -6486.17365787584 
Iteration 3 Log Likelihood:  -6486.14695222685 
Iteration 4 Log Likelihood:  -6486.11783219337 
Iteration 5 Log Likelihood:  -6486.0856259897 
Iteration 6 Log Likelihood:  -6486.0494177187 
Iteration 7 Log Likelihood:  -6486.00797933902 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6541.51340102613 
Iteration 2 Log Likelihood:  -5628.14567605894 
Iteration 3 Log Likelihood:  -5628.07330413384 
Iteration 4 Log Likelihood:  -5627.97679620048 
Iteration 5 Log Likelihood:  -5627.82320602543 
Iteration 6 Log Likelihood:  -5627.52150336897 
Iteration 7 Log Likelihood:  -5626.77883593488 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6538.58519794471 
Iteration 2 Log Likelihood:  -815.689366918224 
Iteration 3 Log Likelihood:  -792.882715200351 
Iteration 4 Log Likelihood:  -716.071918264412 
Iteration 5 Log Likelihood:  -688.301760611291 
Iteration 6 Log Likelihood:  -671.835226759465 
Iteration 7 Log Likelihood:  -666.877151973822 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.89041225018 
Iteration 2 Log Likelihood:  -6468.65387779645 
Iteration 3 Log Likelihood:  -6468.65387779645 
Iteration 4 Log Likelihood:  -6468.65387779645 
Iteration 5 Log Likelihood:  -6468.65387779645 
Iteration 6 Log Likelihood:  -6468.65387779645 
Iteration 7 Log Likelihood:  -6468.65387779645 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.35458493808 
Iteration 2 Log Likelihood:  -5629.99891624771 
Iteration 3 Log Likelihood:  -5629.99891624771 
Iteration 4 Log Likelihood:  -5629.99891624771 
Iteration 5 Log Likelihood:  -5629.99891624771 
Iteration 6 Log Likelihood:  -5629.99891624771 
Iteration 7 Log Likelihood:  -5629.99891624771 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.68099758974 
Iteration 2 Log Likelihood:  -1037.03797959499 
Iteration 3 Log Likelihood:  -1037.03797959498 
Iteration 4 Log Likelihood:  -1037.037979595 
Iteration 5 Log Likelihood:  -1037.03797959498 
Iteration 6 Log Likelihood:  -1037.03797959492 
Iteration 7 Log Likelihood:  -1037.03797959494 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.80475327603 
Iteration 2 Log Likelihood:  -6467.53699200045 
Iteration 3 Log Likelihood:  -6467.53697016984 
Iteration 4 Log Likelihood:  -6467.53694831437 
Iteration 5 Log Likelihood:  -6467.53692643316 
Iteration 6 Log Likelihood:  -6467.53690452532 
Iteration 7 Log Likelihood:  -6467.53688258992 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.24593328358 
Iteration 2 Log Likelihood:  -5628.69137225336 
Iteration 3 Log Likelihood:  -5628.69119823072 
Iteration 4 Log Likelihood:  -5628.69102316104 
Iteration 5 Log Likelihood:  -5628.69084703233 
Iteration 6 Log Likelihood:  -5628.69066983146 
Iteration 7 Log Likelihood:  -5628.69049154368 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.51144683547 
Iteration 2 Log Likelihood:  -1034.57800251865 
Iteration 3 Log Likelihood:  -1034.51806084372 
Iteration 4 Log Likelihood:  -1034.39283956055 
Iteration 5 Log Likelihood:  -1034.15363323588 
Iteration 6 Log Likelihood:  -1033.76154417864 
Iteration 7 Log Likelihood:  -1033.2376068071 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.81523363899 
Iteration 2 Log Likelihood:  -6468.5706738112 
Iteration 3 Log Likelihood:  -6468.56887100016 
Iteration 4 Log Likelihood:  -6468.5670392936 
Iteration 5 Log Likelihood:  -6468.56517178903 
Iteration 6 Log Likelihood:  -6468.56326104513 
Iteration 7 Log Likelihood:  -6468.56129903442 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.29827845108 
Iteration 2 Log Likelihood:  -5629.91440924052 
Iteration 3 Log Likelihood:  -5629.89944023238 
Iteration 4 Log Likelihood:  -5629.88343748347 
Iteration 5 Log Likelihood:  -5629.86604938166 
Iteration 6 Log Likelihood:  -5629.84670909103 
Iteration 7 Log Likelihood:  -5629.82452026257 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.62655362646 
Iteration 2 Log Likelihood:  -1034.00426140868 
Iteration 3 Log Likelihood:  -1014.85364236392 
Iteration 4 Log Likelihood:  -988.44640041356 
Iteration 5 Log Likelihood:  -971.625052442277 
Iteration 6 Log Likelihood:  -950.606710440776 
Iteration 7 Log Likelihood:  -931.784972497619 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.89041225018 
Iteration 2 Log Likelihood:  -6468.65387779645 
Iteration 3 Log Likelihood:  -6468.65387779645 
Iteration 4 Log Likelihood:  -6468.65387779645 
Iteration 5 Log Likelihood:  -6468.65387779645 
Iteration 6 Log Likelihood:  -6468.65387779645 
Iteration 7 Log Likelihood:  -6468.65387779645 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.35458493808 
Iteration 2 Log Likelihood:  -5629.99891624771 
Iteration 3 Log Likelihood:  -5629.99891624771 
Iteration 4 Log Likelihood:  -5629.99891624771 
Iteration 5 Log Likelihood:  -5629.99891624771 
Iteration 6 Log Likelihood:  -5629.99891624771 
Iteration 7 Log Likelihood:  -5629.99891624771 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.68099758974 
Iteration 2 Log Likelihood:  -1037.03797959506 
Iteration 3 Log Likelihood:  -1037.03797959498 
Iteration 4 Log Likelihood:  -1037.03797959499 
Iteration 5 Log Likelihood:  -1037.03797959499 
Iteration 6 Log Likelihood:  -1037.03797959499 
Iteration 7 Log Likelihood:  -1037.037979595 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.79578548765 
Iteration 2 Log Likelihood:  -6467.52869255368 
Iteration 3 Log Likelihood:  -6467.52865450306 
Iteration 4 Log Likelihood:  -6467.52861640486 
Iteration 5 Log Likelihood:  -6467.52857825776 
Iteration 6 Log Likelihood:  -6467.52854006082 
Iteration 7 Log Likelihood:  -6467.52850181311 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.22576389469 
Iteration 2 Log Likelihood:  -5628.68501410992 
Iteration 3 Log Likelihood:  -5628.68470724486 
Iteration 4 Log Likelihood:  -5628.68439555879 
Iteration 5 Log Likelihood:  -5628.68407865059 
Iteration 6 Log Likelihood:  -5628.68375632117 
Iteration 7 Log Likelihood:  -5628.68342835939 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6517.47662001999 
Iteration 2 Log Likelihood:  -1034.56313378421 
Iteration 3 Log Likelihood:  -1034.48785238538 
Iteration 4 Log Likelihood:  -1034.32856777056 
Iteration 5 Log Likelihood:  -1034.00661624337 
Iteration 6 Log Likelihood:  -1033.40881271871 
Iteration 7 Log Likelihood:  -1032.43487572812 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.7342015575 
Iteration 2 Log Likelihood:  -6468.49449620798 
Iteration 3 Log Likelihood:  -6468.49135394934 
Iteration 4 Log Likelihood:  -6468.48816536403 
Iteration 5 Log Likelihood:  -6468.48492314261 
Iteration 6 Log Likelihood:  -6468.48161942567 
Iteration 7 Log Likelihood:  -6468.47824573063 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6522.11616248245 
Iteration 2 Log Likelihood:  -5629.83759970539 
Iteration 3 Log Likelihood:  -5629.80448156257 
Iteration 4 Log Likelihood:  -5629.76309069602 
Iteration 5 Log Likelihood:  -5629.70848291665 
Iteration 6 Log Likelihood:  -5629.63147018629 
Iteration 7 Log Likelihood:  -5629.51374562426 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.31221150718 
Iteration 2 Log Likelihood:  -1027.94879268318 
Iteration 3 Log Likelihood:  -973.580318562633 
Iteration 4 Log Likelihood:  -941.922353721166 
Iteration 5 Log Likelihood:  -925.333960687797 
Iteration 6 Log Likelihood:  -898.346369436367 
Iteration 7 Log Likelihood:  -890.51554114188 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6534.62641953565 
Iteration 2 Log Likelihood:  -6478.63447049534 
Iteration 3 Log Likelihood:  -6478.63447049534 
Iteration 4 Log Likelihood:  -6478.63447049534 
Iteration 5 Log Likelihood:  -6478.63447049534 
Iteration 6 Log Likelihood:  -6478.63447049534 
Iteration 7 Log Likelihood:  -6478.63447049533 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6532.93452168223 
Iteration 2 Log Likelihood:  -5631.58055105463 
Iteration 3 Log Likelihood:  -5631.58055105463 
Iteration 4 Log Likelihood:  -5631.58055105463 
Iteration 5 Log Likelihood:  -5631.58055105463 
Iteration 6 Log Likelihood:  -5631.58055105463 
Iteration 7 Log Likelihood:  -5631.58055105463 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6528.88475243594 
Iteration 2 Log Likelihood:  -932.432118598167 
Iteration 3 Log Likelihood:  -932.432118598157 
Iteration 4 Log Likelihood:  -932.432118598083 
Iteration 5 Log Likelihood:  -932.432118598066 
Iteration 6 Log Likelihood:  -932.432118598062 
Iteration 7 Log Likelihood:  -932.432118598073 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6534.11995412632 
Iteration 2 Log Likelihood:  -6478.15356511172 
Iteration 3 Log Likelihood:  -6478.15353005364 
Iteration 4 Log Likelihood:  -6478.15349492468 
Iteration 5 Log Likelihood:  -6478.15345972316 
Iteration 6 Log Likelihood:  -6478.15342444733 
Iteration 7 Log Likelihood:  -6478.15338909544 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6532.38182715829 
Iteration 2 Log Likelihood:  -5631.18340253114 
Iteration 3 Log Likelihood:  -5631.18325097863 
Iteration 4 Log Likelihood:  -5631.18309782819 
Iteration 5 Log Likelihood:  -5631.18294302486 
Iteration 6 Log Likelihood:  -5631.18278650916 
Iteration 7 Log Likelihood:  -5631.18262821833 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6528.23390294804 
Iteration 2 Log Likelihood:  -931.97847715304 
Iteration 3 Log Likelihood:  -931.966517099344 
Iteration 4 Log Likelihood:  -931.941127856337 
Iteration 5 Log Likelihood:  -931.887948427784 
Iteration 6 Log Likelihood:  -931.780066215977 
Iteration 7 Log Likelihood:  -931.575147960736 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6534.52880184236 
Iteration 2 Log Likelihood:  -6478.55873253337 
Iteration 3 Log Likelihood:  -6478.55582117694 
Iteration 4 Log Likelihood:  -6478.55283445086 
Iteration 5 Log Likelihood:  -6478.54975733881 
Iteration 6 Log Likelihood:  -6478.54657285441 
Iteration 7 Log Likelihood:  -6478.54326186668 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6532.61047408557 
Iteration 2 Log Likelihood:  -5631.49378027601 
Iteration 3 Log Likelihood:  -5631.47836207805 
Iteration 4 Log Likelihood:  -5631.46005217276 
Iteration 5 Log Likelihood:  -5631.43749285947 
Iteration 6 Log Likelihood:  -5631.40849611141 
Iteration 7 Log Likelihood:  -5631.36933709671 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6528.1218787407 
Iteration 2 Log Likelihood:  -926.098126725616 
Iteration 3 Log Likelihood:  -898.86858725503 
Iteration 4 Log Likelihood:  -878.446719236976 
Iteration 5 Log Likelihood:  -872.585838266951 
Iteration 6 Log Likelihood:  -857.893513860054 
Iteration 7 Log Likelihood:  -853.296388764353 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6534.62641953565 
Iteration 2 Log Likelihood:  -6478.63447049534 
Iteration 3 Log Likelihood:  -6478.63447049533 
Iteration 4 Log Likelihood:  -6478.63447049534 
Iteration 5 Log Likelihood:  -6478.63447049534 
Iteration 6 Log Likelihood:  -6478.63447049534 
Iteration 7 Log Likelihood:  -6478.63447049533 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6532.93452168223 
Iteration 2 Log Likelihood:  -5631.58055105463 
Iteration 3 Log Likelihood:  -5631.58055105463 
Iteration 4 Log Likelihood:  -5631.58055105463 
Iteration 5 Log Likelihood:  -5631.58055105463 
Iteration 6 Log Likelihood:  -5631.58055105463 
Iteration 7 Log Likelihood:  -5631.58055105463 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6528.88475243594 
Iteration 2 Log Likelihood:  -932.432118598144 
Iteration 3 Log Likelihood:  -932.432118598075 
Iteration 4 Log Likelihood:  -932.432118598177 
Iteration 5 Log Likelihood:  -932.432118598153 
Iteration 6 Log Likelihood:  -932.432118598133 
Iteration 7 Log Likelihood:  -932.432118598089 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6534.11638058469 
Iteration 2 Log Likelihood:  -6478.15011218325 
Iteration 3 Log Likelihood:  -6478.15002357735 
Iteration 4 Log Likelihood:  -6478.14993397149 
Iteration 5 Log Likelihood:  -6478.14984335503 
Iteration 6 Log Likelihood:  -6478.14975171421 
Iteration 7 Log Likelihood:  -6478.14965903514 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6532.38175027661 
Iteration 2 Log Likelihood:  -5631.17917308069 
Iteration 3 Log Likelihood:  -5631.1787706033 
Iteration 4 Log Likelihood:  -5631.17835260019 
Iteration 5 Log Likelihood:  -5631.17791787338 
Iteration 6 Log Likelihood:  -5631.17746558058 
Iteration 7 Log Likelihood:  -5631.17699482959 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6528.23240396198 
Iteration 2 Log Likelihood:  -931.967749564353 
Iteration 3 Log Likelihood:  -931.944323773972 
Iteration 4 Log Likelihood:  -931.895652562408 
Iteration 5 Log Likelihood:  -931.796232723331 
Iteration 6 Log Likelihood:  -931.600037467571 
Iteration 7 Log Likelihood:  -931.237821365064 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6534.49660554491 
Iteration 2 Log Likelihood:  -6478.52377988884 
Iteration 3 Log Likelihood:  -6478.51579973572 
Iteration 4 Log Likelihood:  -6478.50698507438 
Iteration 5 Log Likelihood:  -6478.4972397131 
Iteration 6 Log Likelihood:  -6478.48645864628 
Iteration 7 Log Likelihood:  -6478.47452615141 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6532.60978096324 
Iteration 2 Log Likelihood:  -5631.45521796619 
Iteration 3 Log Likelihood:  -5631.41741292379 
Iteration 4 Log Likelihood:  -5631.36458011527 
Iteration 5 Log Likelihood:  -5631.28805831526 
Iteration 6 Log Likelihood:  -5631.17090952509 
Iteration 7 Log Likelihood:  -5630.97632157555 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6528.10835192402 
Iteration 2 Log Likelihood:  -925.318114150448 
Iteration 3 Log Likelihood:  -881.232841079486 
Iteration 4 Log Likelihood:  -830.516978807381 
Iteration 5 Log Likelihood:  -817.899795439878 
Iteration 6 Log Likelihood:  -797.664178083584 
Iteration 7 Log Likelihood:  -794.987138005879 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.02396769791 
Iteration 2 Log Likelihood:  -6461.53703407961 
Iteration 3 Log Likelihood:  -6461.53703407961 
Iteration 4 Log Likelihood:  -6461.53703407961 
Iteration 5 Log Likelihood:  -6461.53703407961 
Iteration 6 Log Likelihood:  -6461.53703407961 
Iteration 7 Log Likelihood:  -6461.53703407961 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6513.85426220285 
Iteration 2 Log Likelihood:  -5627.685815142 
Iteration 3 Log Likelihood:  -5627.685815142 
Iteration 4 Log Likelihood:  -5627.685815142 
Iteration 5 Log Likelihood:  -5627.685815142 
Iteration 6 Log Likelihood:  -5627.685815142 
Iteration 7 Log Likelihood:  -5627.685815142 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6508.66943018046 
Iteration 2 Log Likelihood:  -1018.99520871928 
Iteration 3 Log Likelihood:  -1018.99520871925 
Iteration 4 Log Likelihood:  -1018.99520871927 
Iteration 5 Log Likelihood:  -1018.99520871931 
Iteration 6 Log Likelihood:  -1018.99520871927 
Iteration 7 Log Likelihood:  -1018.99520871923 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.13332405106 
Iteration 2 Log Likelihood:  -6461.65080737515 
Iteration 3 Log Likelihood:  -6461.65066718279 
Iteration 4 Log Likelihood:  -6461.65052636344 
Iteration 5 Log Likelihood:  -6461.65038487928 
Iteration 6 Log Likelihood:  -6461.65024269215 
Iteration 7 Log Likelihood:  -6461.65009976358 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6513.92975796207 
Iteration 2 Log Likelihood:  -5627.77380209702 
Iteration 3 Log Likelihood:  -5627.7729375374 
Iteration 4 Log Likelihood:  -5627.77207023643 
Iteration 5 Log Likelihood:  -5627.77119984206 
Iteration 6 Log Likelihood:  -5627.77032601652 
Iteration 7 Log Likelihood:  -5627.7694483892 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6508.70671074197 
Iteration 2 Log Likelihood:  -1018.90436886785 
Iteration 3 Log Likelihood:  -1018.80297976607 
Iteration 4 Log Likelihood:  -1018.58525073566 
Iteration 5 Log Likelihood:  -1018.18120272502 
Iteration 6 Log Likelihood:  -1017.60668868193 
Iteration 7 Log Likelihood:  -1017.03538380828 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6515.22059533469 
Iteration 2 Log Likelihood:  -6460.81779331577 
Iteration 3 Log Likelihood:  -6460.80541447549 
Iteration 4 Log Likelihood:  -6460.79205590167 
Iteration 5 Log Likelihood:  -6460.77740734807 
Iteration 6 Log Likelihood:  -6460.76112608373 
Iteration 7 Log Likelihood:  -6460.74283258437 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6512.70563229795 
Iteration 2 Log Likelihood:  -5627.08097104618 
Iteration 3 Log Likelihood:  -5627.00353545941 
Iteration 4 Log Likelihood:  -5626.91396005591 
Iteration 5 Log Likelihood:  -5626.80235209489 
Iteration 6 Log Likelihood:  -5626.65203471354 
Iteration 7 Log Likelihood:  -5626.43455885031 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6507.08437819357 
Iteration 2 Log Likelihood:  -994.282751523442 
Iteration 3 Log Likelihood:  -952.321393458459 
Iteration 4 Log Likelihood:  -943.328872841084 
Iteration 5 Log Likelihood:  -942.289223813255 
Iteration 6 Log Likelihood:  -942.138213627571 
Iteration 7 Log Likelihood:  -942.092793891225 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.02396769791 
Iteration 2 Log Likelihood:  -6461.53703407961 
Iteration 3 Log Likelihood:  -6461.53703407961 
Iteration 4 Log Likelihood:  -6461.53703407961 
Iteration 5 Log Likelihood:  -6461.53703407961 
Iteration 6 Log Likelihood:  -6461.53703407961 
Iteration 7 Log Likelihood:  -6461.53703407961 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6513.85426220285 
Iteration 2 Log Likelihood:  -5627.685815142 
Iteration 3 Log Likelihood:  -5627.685815142 
Iteration 4 Log Likelihood:  -5627.685815142 
Iteration 5 Log Likelihood:  -5627.685815142 
Iteration 6 Log Likelihood:  -5627.685815142 
Iteration 7 Log Likelihood:  -5627.685815142 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6508.66943018046 
Iteration 2 Log Likelihood:  -1018.99520871927 
Iteration 3 Log Likelihood:  -1018.99520871929 
Iteration 4 Log Likelihood:  -1018.99520871924 
Iteration 5 Log Likelihood:  -1018.99520871934 
Iteration 6 Log Likelihood:  -1018.99520871932 
Iteration 7 Log Likelihood:  -1018.9952087193 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.09946844062 
Iteration 2 Log Likelihood:  -6461.61333124644 
Iteration 3 Log Likelihood:  -6461.61296608603 
Iteration 4 Log Likelihood:  -6461.61260046357 
Iteration 5 Log Likelihood:  -6461.61223433929 
Iteration 6 Log Likelihood:  -6461.61186767525 
Iteration 7 Log Likelihood:  -6461.61150043211 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6513.91715928894 
Iteration 2 Log Likelihood:  -5627.73091483893 
Iteration 3 Log Likelihood:  -5627.72871771878 
Iteration 4 Log Likelihood:  -5627.72648707016 
Iteration 5 Log Likelihood:  -5627.72422083483 
Iteration 6 Log Likelihood:  -5627.72191685625 
Iteration 7 Log Likelihood:  -5627.71957278613 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6508.70450812461 
Iteration 2 Log Likelihood:  -1018.90445880111 
Iteration 3 Log Likelihood:  -1018.80308530967 
Iteration 4 Log Likelihood:  -1018.58520240359 
Iteration 5 Log Likelihood:  -1018.18057206004 
Iteration 6 Log Likelihood:  -1017.60466925978 
Iteration 7 Log Likelihood:  -1017.03072038138 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6514.91497729814 
Iteration 2 Log Likelihood:  -6460.46407685062 
Iteration 3 Log Likelihood:  -6460.43362683351 
Iteration 4 Log Likelihood:  -6460.40222727054 
Iteration 5 Log Likelihood:  -6460.36948424268 
Iteration 6 Log Likelihood:  -6460.33495800149 
Iteration 7 Log Likelihood:  -6460.29818360233 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6512.59210221706 
Iteration 2 Log Likelihood:  -5626.64285145489 
Iteration 3 Log Likelihood:  -5626.43989150215 
Iteration 4 Log Likelihood:  -5626.18498982273 
Iteration 5 Log Likelihood:  -5625.84432116985 
Iteration 6 Log Likelihood:  -5625.37109463735 
Iteration 7 Log Likelihood:  -5624.72023720882 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6507.06454831177 
Iteration 2 Log Likelihood:  -994.31858865111 
Iteration 3 Log Likelihood:  -952.110165407314 
Iteration 4 Log Likelihood:  -942.017732375544 
Iteration 5 Log Likelihood:  -932.798186426924 
Iteration 6 Log Likelihood:  -916.923787732419 
Iteration 7 Log Likelihood:  -915.348071882998 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.47402902304 
Iteration 2 Log Likelihood:  -6468.60008996818 
Iteration 3 Log Likelihood:  -6468.60008996818 
Iteration 4 Log Likelihood:  -6468.60008996818 
Iteration 5 Log Likelihood:  -6468.60008996818 
Iteration 6 Log Likelihood:  -6468.60008996818 
Iteration 7 Log Likelihood:  -6468.60008996818 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.46500710499 
Iteration 2 Log Likelihood:  -5622.87063204992 
Iteration 3 Log Likelihood:  -5622.87063204992 
Iteration 4 Log Likelihood:  -5622.87063204992 
Iteration 5 Log Likelihood:  -5622.87063204992 
Iteration 6 Log Likelihood:  -5622.87063204992 
Iteration 7 Log Likelihood:  -5622.87063204992 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.68175926519 
Iteration 2 Log Likelihood:  -868.706366720793 
Iteration 3 Log Likelihood:  -868.70636672077 
Iteration 4 Log Likelihood:  -868.706366720794 
Iteration 5 Log Likelihood:  -868.706366720794 
Iteration 6 Log Likelihood:  -868.706366720807 
Iteration 7 Log Likelihood:  -868.70636672085 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6520.15785510331 
Iteration 2 Log Likelihood:  -6465.32579098796 
Iteration 3 Log Likelihood:  -6465.32576635476 
Iteration 4 Log Likelihood:  -6465.32574168507 
Iteration 5 Log Likelihood:  -6465.32571697796 
Iteration 6 Log Likelihood:  -6465.32569223247 
Iteration 7 Log Likelihood:  -6465.32566744766 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.0621554033 
Iteration 2 Log Likelihood:  -5619.80769631965 
Iteration 3 Log Likelihood:  -5619.80753101542 
Iteration 4 Log Likelihood:  -5619.80736358335 
Iteration 5 Log Likelihood:  -5619.80719397084 
Iteration 6 Log Likelihood:  -5619.80702213152 
Iteration 7 Log Likelihood:  -5619.80684801767 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6513.08977587847 
Iteration 2 Log Likelihood:  -866.178496873876 
Iteration 3 Log Likelihood:  -866.156027426052 
Iteration 4 Log Likelihood:  -866.113273208808 
Iteration 5 Log Likelihood:  -866.032085721301 
Iteration 6 Log Likelihood:  -865.879785082032 
Iteration 7 Log Likelihood:  -865.600781950513 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.44276250052 
Iteration 2 Log Likelihood:  -6468.58502159857 
Iteration 3 Log Likelihood:  -6468.58281869028 
Iteration 4 Log Likelihood:  -6468.5805737692 
Iteration 5 Log Likelihood:  -6468.57827895633 
Iteration 6 Log Likelihood:  -6468.5759260124 
Iteration 7 Log Likelihood:  -6468.57350631687 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.29445809114 
Iteration 2 Log Likelihood:  -5622.85231348847 
Iteration 3 Log Likelihood:  -5622.83461222788 
Iteration 4 Log Likelihood:  -5622.81430659908 
Iteration 5 Log Likelihood:  -5622.79074279534 
Iteration 6 Log Likelihood:  -5622.7630481897 
Iteration 7 Log Likelihood:  -5622.73004343259 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.32000206197 
Iteration 2 Log Likelihood:  -861.777841156571 
Iteration 3 Log Likelihood:  -825.462722685918 
Iteration 4 Log Likelihood:  -797.778307674199 
Iteration 5 Log Likelihood:  -793.59160524373 
Iteration 6 Log Likelihood:  -792.548582089118 
Iteration 7 Log Likelihood:  -791.833047889595 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.47402902304 
Iteration 2 Log Likelihood:  -6468.60008996818 
Iteration 3 Log Likelihood:  -6468.60008996818 
Iteration 4 Log Likelihood:  -6468.60008996818 
Iteration 5 Log Likelihood:  -6468.60008996818 
Iteration 6 Log Likelihood:  -6468.60008996818 
Iteration 7 Log Likelihood:  -6468.60008996818 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.46500710499 
Iteration 2 Log Likelihood:  -5622.87063204992 
Iteration 3 Log Likelihood:  -5622.87063204992 
Iteration 4 Log Likelihood:  -5622.87063204992 
Iteration 5 Log Likelihood:  -5622.87063204992 
Iteration 6 Log Likelihood:  -5622.87063204992 
Iteration 7 Log Likelihood:  -5622.87063204992 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.68175926519 
Iteration 2 Log Likelihood:  -868.706366720901 
Iteration 3 Log Likelihood:  -868.706366720804 
Iteration 4 Log Likelihood:  -868.706366720801 
Iteration 5 Log Likelihood:  -868.706366720828 
Iteration 6 Log Likelihood:  -868.706366720756 
Iteration 7 Log Likelihood:  -868.706366720857 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6520.14886806712 
Iteration 2 Log Likelihood:  -6465.31728032733 
Iteration 3 Log Likelihood:  -6465.31722192721 
Iteration 4 Log Likelihood:  -6465.31716339415 
Iteration 5 Log Likelihood:  -6465.31710472664 
Iteration 6 Log Likelihood:  -6465.31704592343 
Iteration 7 Log Likelihood:  -6465.31698698323 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6518.0482223991 
Iteration 2 Log Likelihood:  -5619.80303024498 
Iteration 3 Log Likelihood:  -5619.80272832715 
Iteration 4 Log Likelihood:  -5619.80241979944 
Iteration 5 Log Likelihood:  -5619.80210441821 
Iteration 6 Log Likelihood:  -5619.80178195468 
Iteration 7 Log Likelihood:  -5619.80145217 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6513.07033996185 
Iteration 2 Log Likelihood:  -866.105523214683 
Iteration 3 Log Likelihood:  -865.987137019304 
Iteration 4 Log Likelihood:  -865.73206331085 
Iteration 5 Log Likelihood:  -865.240230431945 
Iteration 6 Log Likelihood:  -864.486564460374 
Iteration 7 Log Likelihood:  -863.612561265635 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6523.35820552131 
Iteration 2 Log Likelihood:  -6468.50252044225 
Iteration 3 Log Likelihood:  -6468.49727659369 
Iteration 4 Log Likelihood:  -6468.4919093131 
Iteration 5 Log Likelihood:  -6468.4864071276 
Iteration 6 Log Likelihood:  -6468.48075761528 
Iteration 7 Log Likelihood:  -6468.47494740247 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.16360891782 
Iteration 2 Log Likelihood:  -5622.78959691893 
Iteration 3 Log Likelihood:  -5622.75237034766 
Iteration 4 Log Likelihood:  -5622.70515062724 
Iteration 5 Log Likelihood:  -5622.64363077862 
Iteration 6 Log Likelihood:  -5622.56097919597 
Iteration 7 Log Likelihood:  -5622.44612091243 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6516.13777101306 
Iteration 2 Log Likelihood:  -861.473254874982 
Iteration 3 Log Likelihood:  -817.681901850837 
Iteration 4 Log Likelihood:  -779.009599731398 
Iteration 5 Log Likelihood:  -767.220796743799 
Iteration 6 Log Likelihood:  -763.531485854627 
Iteration 7 Log Likelihood:  -762.90807681959 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.59578319234 
Iteration 2 Log Likelihood:  -6470.47689284087 
Iteration 3 Log Likelihood:  -6470.47689284087 
Iteration 4 Log Likelihood:  -6470.47689284087 
Iteration 5 Log Likelihood:  -6470.47689284087 
Iteration 6 Log Likelihood:  -6470.47689284087 
Iteration 7 Log Likelihood:  -6470.47689284087 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.68578004181 
Iteration 2 Log Likelihood:  -5604.92651534846 
Iteration 3 Log Likelihood:  -5604.92651534846 
Iteration 4 Log Likelihood:  -5604.92651534846 
Iteration 5 Log Likelihood:  -5604.92651534846 
Iteration 6 Log Likelihood:  -5604.92651534846 
Iteration 7 Log Likelihood:  -5604.92651534846 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.11749461123 
Iteration 2 Log Likelihood:  -740.672715644152 
Iteration 3 Log Likelihood:  -740.672715644191 
Iteration 4 Log Likelihood:  -740.672715644187 
Iteration 5 Log Likelihood:  -740.672715644245 
Iteration 6 Log Likelihood:  -740.672715644247 
Iteration 7 Log Likelihood:  -740.672715644102 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.57782776563 
Iteration 2 Log Likelihood:  -6470.46026989822 
Iteration 3 Log Likelihood:  -6470.46026934713 
Iteration 4 Log Likelihood:  -6470.46026879565 
Iteration 5 Log Likelihood:  -6470.46026824377 
Iteration 6 Log Likelihood:  -6470.46026769147 
Iteration 7 Log Likelihood:  -6470.46026713876 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.66366866521 
Iteration 2 Log Likelihood:  -5604.90634216954 
Iteration 3 Log Likelihood:  -5604.90634076244 
Iteration 4 Log Likelihood:  -5604.90633934697 
Iteration 5 Log Likelihood:  -5604.90633792109 
Iteration 6 Log Likelihood:  -5604.90633648474 
Iteration 7 Log Likelihood:  -5604.90633503787 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.08440863589 
Iteration 2 Log Likelihood:  -740.547711593366 
Iteration 3 Log Likelihood:  -740.528947364624 
Iteration 4 Log Likelihood:  -740.488584255932 
Iteration 5 Log Likelihood:  -740.403649073271 
Iteration 6 Log Likelihood:  -740.233615406046 
Iteration 7 Log Likelihood:  -739.925596000363 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.59197407951 
Iteration 2 Log Likelihood:  -6470.47405901575 
Iteration 3 Log Likelihood:  -6470.47401406743 
Iteration 4 Log Likelihood:  -6470.4739688206 
Iteration 5 Log Likelihood:  -6470.47392327203 
Iteration 6 Log Likelihood:  -6470.47387742 
Iteration 7 Log Likelihood:  -6470.47383126254 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.67871950767 
Iteration 2 Log Likelihood:  -5604.92583016196 
Iteration 3 Log Likelihood:  -5604.92570633425 
Iteration 4 Log Likelihood:  -5604.92557488921 
Iteration 5 Log Likelihood:  -5604.92543528799 
Iteration 6 Log Likelihood:  -5604.9252871216 
Iteration 7 Log Likelihood:  -5604.92512994088 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.09154924316 
Iteration 2 Log Likelihood:  -740.417424869714 
Iteration 3 Log Likelihood:  -735.961483459479 
Iteration 4 Log Likelihood:  -700.590020194063 
Iteration 5 Log Likelihood:  -655.969703887713 
Iteration 6 Log Likelihood:  -651.03752900519 
Iteration 7 Log Likelihood:  -644.413341171829 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.59578319234 
Iteration 2 Log Likelihood:  -6470.47689284087 
Iteration 3 Log Likelihood:  -6470.47689284087 
Iteration 4 Log Likelihood:  -6470.47689284087 
Iteration 5 Log Likelihood:  -6470.47689284087 
Iteration 6 Log Likelihood:  -6470.47689284087 
Iteration 7 Log Likelihood:  -6470.47689284087 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.68578004181 
Iteration 2 Log Likelihood:  -5604.92651534846 
Iteration 3 Log Likelihood:  -5604.92651534846 
Iteration 4 Log Likelihood:  -5604.92651534846 
Iteration 5 Log Likelihood:  -5604.92651534846 
Iteration 6 Log Likelihood:  -5604.92651534846 
Iteration 7 Log Likelihood:  -5604.92651534846 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.11749461123 
Iteration 2 Log Likelihood:  -740.672715644155 
Iteration 3 Log Likelihood:  -740.672715644162 
Iteration 4 Log Likelihood:  -740.672715644184 
Iteration 5 Log Likelihood:  -740.672715644203 
Iteration 6 Log Likelihood:  -740.672715644202 
Iteration 7 Log Likelihood:  -740.672715644229 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.57780867079 
Iteration 2 Log Likelihood:  -6470.4602408157 
Iteration 3 Log Likelihood:  -6470.46024006274 
Iteration 4 Log Likelihood:  -6470.4602393126 
Iteration 5 Log Likelihood:  -6470.46023856038 
Iteration 6 Log Likelihood:  -6470.46023780607 
Iteration 7 Log Likelihood:  -6470.46023704965 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.65400410228 
Iteration 2 Log Likelihood:  -5604.90489141817 
Iteration 3 Log Likelihood:  -5604.90485256252 
Iteration 4 Log Likelihood:  -5604.90481312802 
Iteration 5 Log Likelihood:  -5604.90477294414 
Iteration 6 Log Likelihood:  -5604.90473200208 
Iteration 7 Log Likelihood:  -5604.90469029287 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6521.05031040565 
Iteration 2 Log Likelihood:  -740.51112919481 
Iteration 3 Log Likelihood:  -740.45638061654 
Iteration 4 Log Likelihood:  -740.343575505661 
Iteration 5 Log Likelihood:  -740.113508535167 
Iteration 6 Log Likelihood:  -739.664046635953 
Iteration 7 Log Likelihood:  -738.869634424384 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6527.59180221727 
Iteration 2 Log Likelihood:  -6470.47381354623 
Iteration 3 Log Likelihood:  -6470.47375318088 
Iteration 4 Log Likelihood:  -6470.47369174262 
Iteration 5 Log Likelihood:  -6470.47362876079 
Iteration 6 Log Likelihood:  -6470.47356414464 
Iteration 7 Log Likelihood:  -6470.47349779761 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6525.59165143964 
Iteration 2 Log Likelihood:  -5604.91921405606 
Iteration 3 Log Likelihood:  -5604.91724586987 
Iteration 4 Log Likelihood:  -5604.91489573008 
Iteration 5 Log Likelihood:  -5604.91209839963 
Iteration 6 Log Likelihood:  -5604.90880288994 
Iteration 7 Log Likelihood:  -5604.9049524144 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6520.7837350031 
Iteration 2 Log Likelihood:  -735.236299573521 
Iteration 3 Log Likelihood:  -697.986738883469 
Iteration 4 Log Likelihood:  -671.894449437793 
Iteration 5 Log Likelihood:  -624.504555249267 
Iteration 6 Log Likelihood:  -604.413140411792 
Iteration 7 Log Likelihood:  -603.825020649843 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6698.17706503827 
Iteration 2 Log Likelihood:  -6640.50626392944 
Iteration 3 Log Likelihood:  -6640.50626392944 
Iteration 4 Log Likelihood:  -6640.50626392944 
Iteration 5 Log Likelihood:  -6640.50626392944 
Iteration 6 Log Likelihood:  -6640.50626392944 
Iteration 7 Log Likelihood:  -6640.50626392945 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.85911171411 
Iteration 2 Log Likelihood:  -5779.64872614311 
Iteration 3 Log Likelihood:  -5779.64872614311 
Iteration 4 Log Likelihood:  -5779.64872614311 
Iteration 5 Log Likelihood:  -5779.64872614311 
Iteration 6 Log Likelihood:  -5779.64872614311 
Iteration 7 Log Likelihood:  -5779.64872614311 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.09562776377 
Iteration 2 Log Likelihood:  -1106.91869443704 
Iteration 3 Log Likelihood:  -1106.91869443709 
Iteration 4 Log Likelihood:  -1106.9186944371 
Iteration 5 Log Likelihood:  -1106.91869443704 
Iteration 6 Log Likelihood:  -1106.91869443705 
Iteration 7 Log Likelihood:  -1106.91869443711 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6698.21220734151 
Iteration 2 Log Likelihood:  -6640.54217724013 
Iteration 3 Log Likelihood:  -6640.54216932792 
Iteration 4 Log Likelihood:  -6640.54216139274 
Iteration 5 Log Likelihood:  -6640.54215343438 
Iteration 6 Log Likelihood:  -6640.54214545266 
Iteration 7 Log Likelihood:  -6640.5421374474 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.88295858874 
Iteration 2 Log Likelihood:  -5779.68219968989 
Iteration 3 Log Likelihood:  -5779.68217085961 
Iteration 4 Log Likelihood:  -5779.68214167979 
Iteration 5 Log Likelihood:  -5779.68211214396 
Iteration 6 Log Likelihood:  -5779.68208224563 
Iteration 7 Log Likelihood:  -5779.6820519782 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.09983807015 
Iteration 2 Log Likelihood:  -1106.92441424718 
Iteration 3 Log Likelihood:  -1106.90269362649 
Iteration 4 Log Likelihood:  -1106.86416191213 
Iteration 5 Log Likelihood:  -1106.79674816571 
Iteration 6 Log Likelihood:  -1106.68196676395 
Iteration 7 Log Likelihood:  -1106.49589084835 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6698.13231594697 
Iteration 2 Log Likelihood:  -6640.46979287015 
Iteration 3 Log Likelihood:  -6640.46912836699 
Iteration 4 Log Likelihood:  -6640.46844474346 
Iteration 5 Log Likelihood:  -6640.46774058287 
Iteration 6 Log Likelihood:  -6640.46701436007 
Iteration 7 Log Likelihood:  -6640.46626443345 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.70617683185 
Iteration 2 Log Likelihood:  -5779.61415014284 
Iteration 3 Log Likelihood:  -5779.61126122256 
Iteration 4 Log Likelihood:  -5779.6080037066 
Iteration 5 Log Likelihood:  -5779.60430530254 
Iteration 6 Log Likelihood:  -5779.60007466071 
Iteration 7 Log Likelihood:  -5779.59519512993 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6696.74975063716 
Iteration 2 Log Likelihood:  -1105.65311580447 
Iteration 3 Log Likelihood:  -1089.76467252516 
Iteration 4 Log Likelihood:  -1036.93027619314 
Iteration 5 Log Likelihood:  -1029.94578844745 
Iteration 6 Log Likelihood:  -1029.39911863644 
Iteration 7 Log Likelihood:  -1029.22790245808 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6698.17706503827 
Iteration 2 Log Likelihood:  -6640.50626392944 
Iteration 3 Log Likelihood:  -6640.50626392944 
Iteration 4 Log Likelihood:  -6640.50626392944 
Iteration 5 Log Likelihood:  -6640.50626392944 
Iteration 6 Log Likelihood:  -6640.50626392944 
Iteration 7 Log Likelihood:  -6640.50626392944 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.85911171411 
Iteration 2 Log Likelihood:  -5779.64872614311 
Iteration 3 Log Likelihood:  -5779.64872614311 
Iteration 4 Log Likelihood:  -5779.64872614311 
Iteration 5 Log Likelihood:  -5779.64872614311 
Iteration 6 Log Likelihood:  -5779.64872614311 
Iteration 7 Log Likelihood:  -5779.64872614311 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.09562776377 
Iteration 2 Log Likelihood:  -1106.91869443704 
Iteration 3 Log Likelihood:  -1106.91869443706 
Iteration 4 Log Likelihood:  -1106.91869443704 
Iteration 5 Log Likelihood:  -1106.91869443705 
Iteration 6 Log Likelihood:  -1106.91869443708 
Iteration 7 Log Likelihood:  -1106.91869443712 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6698.20788524257 
Iteration 2 Log Likelihood:  -6640.53953779228 
Iteration 3 Log Likelihood:  -6640.53950427307 
Iteration 4 Log Likelihood:  -6640.53947048238 
Iteration 5 Log Likelihood:  -6640.53943640073 
Iteration 6 Log Likelihood:  -6640.53940202496 
Iteration 7 Log Likelihood:  -6640.53936735185 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.85166875649 
Iteration 2 Log Likelihood:  -5779.68011334156 
Iteration 3 Log Likelihood:  -5779.68000132994 
Iteration 4 Log Likelihood:  -5779.67988576559 
Iteration 5 Log Likelihood:  -5779.67976616195 
Iteration 6 Log Likelihood:  -5779.67964233686 
Iteration 7 Log Likelihood:  -5779.67951409818 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.01850051332 
Iteration 2 Log Likelihood:  -1106.5597474788 
Iteration 3 Log Likelihood:  -1106.24065469729 
Iteration 4 Log Likelihood:  -1105.77927321153 
Iteration 5 Log Likelihood:  -1105.26219775952 
Iteration 6 Log Likelihood:  -1104.81126665374 
Iteration 7 Log Likelihood:  -1104.4423576401 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6698.09339670844 
Iteration 2 Log Likelihood:  -6640.44357563443 
Iteration 3 Log Likelihood:  -6640.44055699133 
Iteration 4 Log Likelihood:  -6640.43729255269 
Iteration 5 Log Likelihood:  -6640.43375451116 
Iteration 6 Log Likelihood:  -6640.4299126298 
Iteration 7 Log Likelihood:  -6640.42573226087 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6697.42377913425 
Iteration 2 Log Likelihood:  -5779.56333774349 
Iteration 3 Log Likelihood:  -5779.5378841576 
Iteration 4 Log Likelihood:  -5779.49972828774 
Iteration 5 Log Likelihood:  -5779.43973055629 
Iteration 6 Log Likelihood:  -5779.34017701403 
Iteration 7 Log Likelihood:  -5779.16547819055 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6696.01272077069 
Iteration 2 Log Likelihood:  -1105.25819101033 
Iteration 3 Log Likelihood:  -1083.33440185703 
Iteration 4 Log Likelihood:  -1018.88285955956 
Iteration 5 Log Likelihood:  -1001.68153837578 
Iteration 6 Log Likelihood:  -999.761151514476 
Iteration 7 Log Likelihood:  -999.574407767365 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6499.91932888432 
Iteration 2 Log Likelihood:  -6442.68293078975 
Iteration 3 Log Likelihood:  -6442.68293078975 
Iteration 4 Log Likelihood:  -6442.68293078975 
Iteration 5 Log Likelihood:  -6442.68293078975 
Iteration 6 Log Likelihood:  -6442.68293078975 
Iteration 7 Log Likelihood:  -6442.68293078975 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6497.93882317061 
Iteration 2 Log Likelihood:  -5577.24462684402 
Iteration 3 Log Likelihood:  -5577.24462684402 
Iteration 4 Log Likelihood:  -5577.24462684402 
Iteration 5 Log Likelihood:  -5577.24462684402 
Iteration 6 Log Likelihood:  -5577.24462684402 
Iteration 7 Log Likelihood:  -5577.24462684402 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6493.22220355053 
Iteration 2 Log Likelihood:  -798.232903363892 
Iteration 3 Log Likelihood:  -798.232903363929 
Iteration 4 Log Likelihood:  -798.232903363901 
Iteration 5 Log Likelihood:  -798.232903363872 
Iteration 6 Log Likelihood:  -798.232903363918 
Iteration 7 Log Likelihood:  -798.23290336387 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6500.72237954424 
Iteration 2 Log Likelihood:  -6443.47619124728 
Iteration 3 Log Likelihood:  -6443.47609274628 
Iteration 4 Log Likelihood:  -6443.47599358408 
Iteration 5 Log Likelihood:  -6443.47589374166 
Iteration 6 Log Likelihood:  -6443.47579319969 
Iteration 7 Log Likelihood:  -6443.47569193863 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6498.71997476607 
Iteration 2 Log Likelihood:  -5577.91112864504 
Iteration 3 Log Likelihood:  -5577.91046144666 
Iteration 4 Log Likelihood:  -5577.90979498033 
Iteration 5 Log Likelihood:  -5577.90912897331 
Iteration 6 Log Likelihood:  -5577.90846311625 
Iteration 7 Log Likelihood:  -5577.90779706429 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6493.98758201513 
Iteration 2 Log Likelihood:  -798.580351749438 
Iteration 3 Log Likelihood:  -798.543057189558 
Iteration 4 Log Likelihood:  -798.468534897657 
Iteration 5 Log Likelihood:  -798.324135622618 
Iteration 6 Log Likelihood:  -798.061804028473 
Iteration 7 Log Likelihood:  -797.639249230305 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6499.24732993777 
Iteration 2 Log Likelihood:  -6442.0628170814 
Iteration 3 Log Likelihood:  -6442.053884669 
Iteration 4 Log Likelihood:  -6442.04418748067 
Iteration 5 Log Likelihood:  -6442.03355600263 
Iteration 6 Log Likelihood:  -6442.02179964972 
Iteration 7 Log Likelihood:  -6442.00870461623 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6496.89102208852 
Iteration 2 Log Likelihood:  -5576.63932291416 
Iteration 3 Log Likelihood:  -5576.58202269235 
Iteration 4 Log Likelihood:  -5576.51634994614 
Iteration 5 Log Likelihood:  -5576.43352006731 
Iteration 6 Log Likelihood:  -5576.31815406302 
Iteration 7 Log Likelihood:  -5576.14173147189 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6491.60853116277 
Iteration 2 Log Likelihood:  -779.668409035117 
Iteration 3 Log Likelihood:  -716.517030381996 
Iteration 4 Log Likelihood:  -695.988025327147 
Iteration 5 Log Likelihood:  -687.977165256754 
Iteration 6 Log Likelihood:  -687.263507488559 
Iteration 7 Log Likelihood:  -687.191237565066 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6499.91932888432 
Iteration 2 Log Likelihood:  -6442.68293078975 
Iteration 3 Log Likelihood:  -6442.68293078975 
Iteration 4 Log Likelihood:  -6442.68293078975 
Iteration 5 Log Likelihood:  -6442.68293078975 
Iteration 6 Log Likelihood:  -6442.68293078975 
Iteration 7 Log Likelihood:  -6442.68293078975 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6497.93882317061 
Iteration 2 Log Likelihood:  -5577.24462684402 
Iteration 3 Log Likelihood:  -5577.24462684402 
Iteration 4 Log Likelihood:  -5577.24462684402 
Iteration 5 Log Likelihood:  -5577.24462684402 
Iteration 6 Log Likelihood:  -5577.24462684402 
Iteration 7 Log Likelihood:  -5577.24462684402 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6493.22220355053 
Iteration 2 Log Likelihood:  -798.232903363857 
Iteration 3 Log Likelihood:  -798.232903363859 
Iteration 4 Log Likelihood:  -798.232903363849 
Iteration 5 Log Likelihood:  -798.232903363876 
Iteration 6 Log Likelihood:  -798.232903363931 
Iteration 7 Log Likelihood:  -798.232903363926 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6500.67532387925 
Iteration 2 Log Likelihood:  -6443.43408991511 
Iteration 3 Log Likelihood:  -6443.43371359439 
Iteration 4 Log Likelihood:  -6443.43333340891 
Iteration 5 Log Likelihood:  -6443.43294927211 
Iteration 6 Log Likelihood:  -6443.43256111532 
Iteration 7 Log Likelihood:  -6443.4321688692 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6498.5712894166 
Iteration 2 Log Likelihood:  -5577.84412031111 
Iteration 3 Log Likelihood:  -5577.83819866459 
Iteration 4 Log Likelihood:  -5577.83174576625 
Iteration 5 Log Likelihood:  -5577.82469167471 
Iteration 6 Log Likelihood:  -5577.81695951793 
Iteration 7 Log Likelihood:  -5577.8084621814 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6493.69281354873 
Iteration 2 Log Likelihood:  -798.558836540203 
Iteration 3 Log Likelihood:  -798.493630978787 
Iteration 4 Log Likelihood:  -798.359049933988 
Iteration 5 Log Likelihood:  -798.087583551679 
Iteration 6 Log Likelihood:  -797.574771055561 
Iteration 7 Log Likelihood:  -796.719038757623 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6498.82077067668 
Iteration 2 Log Likelihood:  -6441.65875560444 
Iteration 3 Log Likelihood:  -6441.62346445505 
Iteration 4 Log Likelihood:  -6441.5844022417 
Iteration 5 Log Likelihood:  -6441.5410603641 
Iteration 6 Log Likelihood:  -6441.49295381517 
Iteration 7 Log Likelihood:  -6441.4396699869 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6495.52990147795 
Iteration 2 Log Likelihood:  -5575.1960493544 
Iteration 3 Log Likelihood:  -5573.47785784998 
Iteration 4 Log Likelihood:  -5570.65268118003 
Iteration 5 Log Likelihood:  -5568.72273254357 
Iteration 6 Log Likelihood:  -5568.14972375673 
Iteration 7 Log Likelihood:  -5567.98227311852 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6488.87406135101 
Iteration 2 Log Likelihood:  -757.87887175194 
Iteration 3 Log Likelihood:  -665.271661404216 
Iteration 4 Log Likelihood:  -657.029217130036 
Iteration 5 Log Likelihood:  -656.532094047558 
Iteration 6 Log Likelihood:  -656.432785084359 
Iteration 7 Log Likelihood:  -656.403721014496 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.07506036531 
Iteration 2 Log Likelihood:  -6553.65853658538 
Iteration 3 Log Likelihood:  -6553.65853658537 
Iteration 4 Log Likelihood:  -6553.65853658537 
Iteration 5 Log Likelihood:  -6553.65853658538 
Iteration 6 Log Likelihood:  -6553.65853658538 
Iteration 7 Log Likelihood:  -6553.65853658538 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6608.03049199244 
Iteration 2 Log Likelihood:  -5712.84879202245 
Iteration 3 Log Likelihood:  -5712.84879202245 
Iteration 4 Log Likelihood:  -5712.84879202245 
Iteration 5 Log Likelihood:  -5712.84879202245 
Iteration 6 Log Likelihood:  -5712.84879202245 
Iteration 7 Log Likelihood:  -5712.84879202245 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6605.53263867678 
Iteration 2 Log Likelihood:  -1078.66743862356 
Iteration 3 Log Likelihood:  -1078.66743862358 
Iteration 4 Log Likelihood:  -1078.66743862358 
Iteration 5 Log Likelihood:  -1078.66743862346 
Iteration 6 Log Likelihood:  -1078.6674386235 
Iteration 7 Log Likelihood:  -1078.66743862357 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.1489728746 
Iteration 2 Log Likelihood:  -6553.72886288926 
Iteration 3 Log Likelihood:  -6553.72885914113 
Iteration 4 Log Likelihood:  -6553.7288553783 
Iteration 5 Log Likelihood:  -6553.72885160067 
Iteration 6 Log Likelihood:  -6553.72884780813 
Iteration 7 Log Likelihood:  -6553.72884400059 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6608.09187133719 
Iteration 2 Log Likelihood:  -5712.88189728981 
Iteration 3 Log Likelihood:  -5712.88185134245 
Iteration 4 Log Likelihood:  -5712.88180421073 
Iteration 5 Log Likelihood:  -5712.88175584901 
Iteration 6 Log Likelihood:  -5712.8817062094 
Iteration 7 Log Likelihood:  -5712.88165524146 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6605.56549739245 
Iteration 2 Log Likelihood:  -1078.46695984063 
Iteration 3 Log Likelihood:  -1078.45149018664 
Iteration 4 Log Likelihood:  -1078.41441214833 
Iteration 5 Log Likelihood:  -1078.32804132508 
Iteration 6 Log Likelihood:  -1078.13988682896 
Iteration 7 Log Likelihood:  -1077.77958114822 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.05642506912 
Iteration 2 Log Likelihood:  -6553.64172526165 
Iteration 3 Log Likelihood:  -6553.6414065465 
Iteration 4 Log Likelihood:  -6553.64107592021 
Iteration 5 Log Likelihood:  -6553.64073264033 
Iteration 6 Log Likelihood:  -6553.64037590335 
Iteration 7 Log Likelihood:  -6553.64000483826 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6607.96893841146 
Iteration 2 Log Likelihood:  -5712.81987645606 
Iteration 3 Log Likelihood:  -5712.81407532831 
Iteration 4 Log Likelihood:  -5712.8062733671 
Iteration 5 Log Likelihood:  -5712.79530716493 
Iteration 6 Log Likelihood:  -5712.7790026764 
Iteration 7 Log Likelihood:  -5712.75292881744 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6605.38156072179 
Iteration 2 Log Likelihood:  -1075.04062790075 
Iteration 3 Log Likelihood:  -1046.82810130371 
Iteration 4 Log Likelihood:  -991.81401651366 
Iteration 5 Log Likelihood:  -958.571531249605 
Iteration 6 Log Likelihood:  -957.936485616745 
Iteration 7 Log Likelihood:  -957.935758359733 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.07506036531 
Iteration 2 Log Likelihood:  -6553.65853658538 
Iteration 3 Log Likelihood:  -6553.65853658538 
Iteration 4 Log Likelihood:  -6553.65853658538 
Iteration 5 Log Likelihood:  -6553.65853658538 
Iteration 6 Log Likelihood:  -6553.65853658538 
Iteration 7 Log Likelihood:  -6553.65853658538 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6608.03049199244 
Iteration 2 Log Likelihood:  -5712.84879202245 
Iteration 3 Log Likelihood:  -5712.84879202245 
Iteration 4 Log Likelihood:  -5712.84879202245 
Iteration 5 Log Likelihood:  -5712.84879202245 
Iteration 6 Log Likelihood:  -5712.84879202245 
Iteration 7 Log Likelihood:  -5712.84879202245 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6605.53263867678 
Iteration 2 Log Likelihood:  -1078.66743862355 
Iteration 3 Log Likelihood:  -1078.66743862354 
Iteration 4 Log Likelihood:  -1078.66743862356 
Iteration 5 Log Likelihood:  -1078.66743862349 
Iteration 6 Log Likelihood:  -1078.66743862361 
Iteration 7 Log Likelihood:  -1078.66743862355 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.14888570183 
Iteration 2 Log Likelihood:  -6553.72866765489 
Iteration 3 Log Likelihood:  -6553.7286625124 
Iteration 4 Log Likelihood:  -6553.72865734779 
Iteration 5 Log Likelihood:  -6553.72865215451 
Iteration 6 Log Likelihood:  -6553.72864693232 
Iteration 7 Log Likelihood:  -6553.72864168096 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6608.08806959295 
Iteration 2 Log Likelihood:  -5712.88092348985 
Iteration 3 Log Likelihood:  -5712.88081400166 
Iteration 4 Log Likelihood:  -5712.88069937759 
Iteration 5 Log Likelihood:  -5712.88057907375 
Iteration 6 Log Likelihood:  -5712.88045273329 
Iteration 7 Log Likelihood:  -5712.88031997344 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6605.5490630543 
Iteration 2 Log Likelihood:  -1078.41379446258 
Iteration 3 Log Likelihood:  -1078.34301254316 
Iteration 4 Log Likelihood:  -1078.19973533629 
Iteration 5 Log Likelihood:  -1077.92516052915 
Iteration 6 Log Likelihood:  -1077.4431770953 
Iteration 7 Log Likelihood:  -1076.69551162619 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6609.05564018512 
Iteration 2 Log Likelihood:  -6553.63989950466 
Iteration 3 Log Likelihood:  -6553.63945970978 
Iteration 4 Log Likelihood:  -6553.6389975273 
Iteration 5 Log Likelihood:  -6553.63851063479 
Iteration 6 Log Likelihood:  -6553.63799703553 
Iteration 7 Log Likelihood:  -6553.63745453671 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6607.93471740078 
Iteration 2 Log Likelihood:  -5712.8000770043 
Iteration 3 Log Likelihood:  -5712.78067951672 
Iteration 4 Log Likelihood:  -5712.74903791455 
Iteration 5 Log Likelihood:  -5712.69460925343 
Iteration 6 Log Likelihood:  -5712.59475941532 
Iteration 7 Log Likelihood:  -5712.3967316991 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6605.23356544707 
Iteration 2 Log Likelihood:  -1074.42769227643 
Iteration 3 Log Likelihood:  -1036.16147871249 
Iteration 4 Log Likelihood:  -956.437197254817 
Iteration 5 Log Likelihood:  -921.491441760669 
Iteration 6 Log Likelihood:  -917.502753308504 
Iteration 7 Log Likelihood:  -916.574508473376 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6615.10908969656 
Iteration 2 Log Likelihood:  -6555.93682422284 
Iteration 3 Log Likelihood:  -6555.93682422285 
Iteration 4 Log Likelihood:  -6555.93682422285 
Iteration 5 Log Likelihood:  -6555.93682422285 
Iteration 6 Log Likelihood:  -6555.93682422285 
Iteration 7 Log Likelihood:  -6555.93682422285 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.36847084979 
Iteration 2 Log Likelihood:  -5676.27197614063 
Iteration 3 Log Likelihood:  -5676.27197614062 
Iteration 4 Log Likelihood:  -5676.27197614063 
Iteration 5 Log Likelihood:  -5676.27197614062 
Iteration 6 Log Likelihood:  -5676.27197614062 
Iteration 7 Log Likelihood:  -5676.27197614062 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.60202173671 
Iteration 2 Log Likelihood:  -663.36655819586 
Iteration 3 Log Likelihood:  -663.366558195901 
Iteration 4 Log Likelihood:  -663.366558195957 
Iteration 5 Log Likelihood:  -663.366558195834 
Iteration 6 Log Likelihood:  -663.366558196027 
Iteration 7 Log Likelihood:  -663.36655819583 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6611.28324253573 
Iteration 2 Log Likelihood:  -6552.18984843927 
Iteration 3 Log Likelihood:  -6552.18980908416 
Iteration 4 Log Likelihood:  -6552.18976988659 
Iteration 5 Log Likelihood:  -6552.18973084401 
Iteration 6 Log Likelihood:  -6552.18969195387 
Iteration 7 Log Likelihood:  -6552.18965321362 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6610.46875087352 
Iteration 2 Log Likelihood:  -5672.76469689835 
Iteration 3 Log Likelihood:  -5672.76445748615 
Iteration 4 Log Likelihood:  -5672.76421597676 
Iteration 5 Log Likelihood:  -5672.76397223933 
Iteration 6 Log Likelihood:  -5672.76372614442 
Iteration 7 Log Likelihood:  -5672.76347755565 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6608.52824547062 
Iteration 2 Log Likelihood:  -662.904872278898 
Iteration 3 Log Likelihood:  -662.881484571406 
Iteration 4 Log Likelihood:  -662.837136159614 
Iteration 5 Log Likelihood:  -662.752065735269 
Iteration 6 Log Likelihood:  -662.589973674739 
Iteration 7 Log Likelihood:  -662.294850920146 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6615.01942469878 
Iteration 2 Log Likelihood:  -6555.86309329708 
Iteration 3 Log Likelihood:  -6555.85986822667 
Iteration 4 Log Likelihood:  -6555.85673557059 
Iteration 5 Log Likelihood:  -6555.8536760463 
Iteration 6 Log Likelihood:  -6555.85067025181 
Iteration 7 Log Likelihood:  -6555.84769876057 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.25662538532 
Iteration 2 Log Likelihood:  -5676.23357309555 
Iteration 3 Log Likelihood:  -5676.20958179977 
Iteration 4 Log Likelihood:  -5676.18132890274 
Iteration 5 Log Likelihood:  -5676.14627459199 
Iteration 6 Log Likelihood:  -5676.10034681823 
Iteration 7 Log Likelihood:  -5676.03669067414 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.46739263749 
Iteration 2 Log Likelihood:  -659.866113783226 
Iteration 3 Log Likelihood:  -633.836697259597 
Iteration 4 Log Likelihood:  -608.244017654708 
Iteration 5 Log Likelihood:  -586.149920866059 
Iteration 6 Log Likelihood:  -568.400657934354 
Iteration 7 Log Likelihood:  -568.278641594895 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6615.10908969656 
Iteration 2 Log Likelihood:  -6555.93682422284 
Iteration 3 Log Likelihood:  -6555.93682422285 
Iteration 4 Log Likelihood:  -6555.93682422285 
Iteration 5 Log Likelihood:  -6555.93682422285 
Iteration 6 Log Likelihood:  -6555.93682422285 
Iteration 7 Log Likelihood:  -6555.93682422285 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.36847084979 
Iteration 2 Log Likelihood:  -5676.27197614063 
Iteration 3 Log Likelihood:  -5676.27197614063 
Iteration 4 Log Likelihood:  -5676.27197614062 
Iteration 5 Log Likelihood:  -5676.27197614063 
Iteration 6 Log Likelihood:  -5676.27197614063 
Iteration 7 Log Likelihood:  -5676.27197614063 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6612.60202173671 
Iteration 2 Log Likelihood:  -663.366558195741 
Iteration 3 Log Likelihood:  -663.366558195948 
Iteration 4 Log Likelihood:  -663.366558195874 
Iteration 5 Log Likelihood:  -663.3665581958 
Iteration 6 Log Likelihood:  -663.366558195826 
Iteration 7 Log Likelihood:  -663.366558195855 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6611.27861581274 
Iteration 2 Log Likelihood:  -6552.18358022023 
Iteration 3 Log Likelihood:  -6552.18349130042 
Iteration 4 Log Likelihood:  -6552.18340227075 
Iteration 5 Log Likelihood:  -6552.18331310999 
Iteration 6 Log Likelihood:  -6552.18322381989 
Iteration 7 Log Likelihood:  -6552.18313440227 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6610.44862875249 
Iteration 2 Log Likelihood:  -5672.7601878946 
Iteration 3 Log Likelihood:  -5672.75978649668 
Iteration 4 Log Likelihood:  -5672.75938278379 
Iteration 5 Log Likelihood:  -5672.75897273208 
Iteration 6 Log Likelihood:  -5672.75855620441 
Iteration 7 Log Likelihood:  -5672.75813305825 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6608.40980398841 
Iteration 2 Log Likelihood:  -662.357972360322 
Iteration 3 Log Likelihood:  -662.012899573163 
Iteration 4 Log Likelihood:  -661.667192729252 
Iteration 5 Log Likelihood:  -661.367340144058 
Iteration 6 Log Likelihood:  -661.072615082438 
Iteration 7 Log Likelihood:  -660.696553092313 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.97623795804 
Iteration 2 Log Likelihood:  -6555.80188037288 
Iteration 3 Log Likelihood:  -6555.79420158183 
Iteration 4 Log Likelihood:  -6555.78644264491 
Iteration 5 Log Likelihood:  -6555.7786180077 
Iteration 6 Log Likelihood:  -6555.77074477657 
Iteration 7 Log Likelihood:  -6555.7628399506 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6614.06512712592 
Iteration 2 Log Likelihood:  -5676.21927028079 
Iteration 3 Log Likelihood:  -5676.18907336322 
Iteration 4 Log Likelihood:  -5676.15275736419 
Iteration 5 Log Likelihood:  -5676.10728077991 
Iteration 6 Log Likelihood:  -5676.04870637052 
Iteration 7 Log Likelihood:  -5675.97074768923 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6611.31059632209 
Iteration 2 Log Likelihood:  -642.422111775685 
Iteration 3 Log Likelihood:  -611.660309172638 
Iteration 4 Log Likelihood:  -583.759989829035 
Iteration 5 Log Likelihood:  -552.138811098186 
Iteration 6 Log Likelihood:  -525.39966204045 
Iteration 7 Log Likelihood:  -524.039962144118 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6585.12045861747 
Iteration 2 Log Likelihood:  -6527.60650550861 
Iteration 3 Log Likelihood:  -6527.60650550861 
Iteration 4 Log Likelihood:  -6527.60650550861 
Iteration 5 Log Likelihood:  -6527.60650550861 
Iteration 6 Log Likelihood:  -6527.60650550861 
Iteration 7 Log Likelihood:  -6527.60650550861 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6583.86648656129 
Iteration 2 Log Likelihood:  -5658.76953725904 
Iteration 3 Log Likelihood:  -5658.76953725904 
Iteration 4 Log Likelihood:  -5658.76953725904 
Iteration 5 Log Likelihood:  -5658.76953725904 
Iteration 6 Log Likelihood:  -5658.76953725904 
Iteration 7 Log Likelihood:  -5658.76953725904 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6580.86473560964 
Iteration 2 Log Likelihood:  -784.138970171992 
Iteration 3 Log Likelihood:  -784.138970172076 
Iteration 4 Log Likelihood:  -784.138970172023 
Iteration 5 Log Likelihood:  -784.138970172098 
Iteration 6 Log Likelihood:  -784.138970172032 
Iteration 7 Log Likelihood:  -784.138970171999 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6582.31448233982 
Iteration 2 Log Likelihood:  -6524.84356629831 
Iteration 3 Log Likelihood:  -6524.84343906865 
Iteration 4 Log Likelihood:  -6524.84331254908 
Iteration 5 Log Likelihood:  -6524.84318670055 
Iteration 6 Log Likelihood:  -6524.84306148403 
Iteration 7 Log Likelihood:  -6524.84293686052 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6581.0112658881 
Iteration 2 Log Likelihood:  -5656.20530780471 
Iteration 3 Log Likelihood:  -5656.20491654037 
Iteration 4 Log Likelihood:  -5656.20452878689 
Iteration 5 Log Likelihood:  -5656.2041440726 
Iteration 6 Log Likelihood:  -5656.20376192958 
Iteration 7 Log Likelihood:  -5656.20338189445 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.90741496056 
Iteration 2 Log Likelihood:  -783.064201028981 
Iteration 3 Log Likelihood:  -783.009480034129 
Iteration 4 Log Likelihood:  -782.92516772643 
Iteration 5 Log Likelihood:  -782.805187697832 
Iteration 6 Log Likelihood:  -782.650794182401 
Iteration 7 Log Likelihood:  -782.472218790673 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6584.59643944302 
Iteration 2 Log Likelihood:  -6527.10555005036 
Iteration 3 Log Likelihood:  -6527.09569330449 
Iteration 4 Log Likelihood:  -6527.08589546336 
Iteration 5 Log Likelihood:  -6527.07590752383 
Iteration 6 Log Likelihood:  -6527.06548111074 
Iteration 7 Log Likelihood:  -6527.05436568586 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6583.2384042013 
Iteration 2 Log Likelihood:  -5658.30478041964 
Iteration 3 Log Likelihood:  -5658.2738163746 
Iteration 4 Log Likelihood:  -5658.2396324679 
Iteration 5 Log Likelihood:  -5658.19861101951 
Iteration 6 Log Likelihood:  -5658.14550434577 
Iteration 7 Log Likelihood:  -5658.07162538902 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6580.11526457049 
Iteration 2 Log Likelihood:  -775.800550535722 
Iteration 3 Log Likelihood:  -738.860467094722 
Iteration 4 Log Likelihood:  -712.804696078297 
Iteration 5 Log Likelihood:  -705.392583416689 
Iteration 6 Log Likelihood:  -702.898539190625 
Iteration 7 Log Likelihood:  -702.101238298775 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6585.12045861747 
Iteration 2 Log Likelihood:  -6527.60650550861 
Iteration 3 Log Likelihood:  -6527.60650550861 
Iteration 4 Log Likelihood:  -6527.60650550861 
Iteration 5 Log Likelihood:  -6527.60650550861 
Iteration 6 Log Likelihood:  -6527.60650550861 
Iteration 7 Log Likelihood:  -6527.60650550861 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6583.86648656129 
Iteration 2 Log Likelihood:  -5658.76953725904 
Iteration 3 Log Likelihood:  -5658.76953725904 
Iteration 4 Log Likelihood:  -5658.76953725904 
Iteration 5 Log Likelihood:  -5658.76953725904 
Iteration 6 Log Likelihood:  -5658.76953725904 
Iteration 7 Log Likelihood:  -5658.76953725904 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6580.86473560965 
Iteration 2 Log Likelihood:  -784.138970172002 
Iteration 3 Log Likelihood:  -784.138970172074 
Iteration 4 Log Likelihood:  -784.13897017198 
Iteration 5 Log Likelihood:  -784.138970172101 
Iteration 6 Log Likelihood:  -784.138970172008 
Iteration 7 Log Likelihood:  -784.138970172027 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6582.2874005871 
Iteration 2 Log Likelihood:  -6524.8145717231 
Iteration 3 Log Likelihood:  -6524.81412465142 
Iteration 4 Log Likelihood:  -6524.81367749788 
Iteration 5 Log Likelihood:  -6524.81323028684 
Iteration 6 Log Likelihood:  -6524.81278304534 
Iteration 7 Log Likelihood:  -6524.81233579823 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6581.00552359023 
Iteration 2 Log Likelihood:  -5656.17419368916 
Iteration 3 Log Likelihood:  -5656.17274419549 
Iteration 4 Log Likelihood:  -5656.17128971189 
Iteration 5 Log Likelihood:  -5656.16982926561 
Iteration 6 Log Likelihood:  -5656.16836188513 
Iteration 7 Log Likelihood:  -5656.166886433 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.90736130301 
Iteration 2 Log Likelihood:  -782.761221773724 
Iteration 3 Log Likelihood:  -782.494709347259 
Iteration 4 Log Likelihood:  -782.154408300525 
Iteration 5 Log Likelihood:  -781.785432726549 
Iteration 6 Log Likelihood:  -781.42116177778 
Iteration 7 Log Likelihood:  -781.068669167594 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6584.35164760849 
Iteration 2 Log Likelihood:  -6526.82201407397 
Iteration 3 Log Likelihood:  -6526.78624690131 
Iteration 4 Log Likelihood:  -6526.7504714693 
Iteration 5 Log Likelihood:  -6526.71456247215 
Iteration 6 Log Likelihood:  -6526.67825994626 
Iteration 7 Log Likelihood:  -6526.6411955057 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6583.18640642275 
Iteration 2 Log Likelihood:  -5657.99342365492 
Iteration 3 Log Likelihood:  -5657.87537972425 
Iteration 4 Log Likelihood:  -5657.73936922234 
Iteration 5 Log Likelihood:  -5657.56806048322 
Iteration 6 Log Likelihood:  -5657.33554728855 
Iteration 7 Log Likelihood:  -5657.00462430078 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6580.11477735483 
Iteration 2 Log Likelihood:  -772.099230160084 
Iteration 3 Log Likelihood:  -719.615806908001 
Iteration 4 Log Likelihood:  -675.777225078334 
Iteration 5 Log Likelihood:  -658.381687566874 
Iteration 6 Log Likelihood:  -654.829494186866 
Iteration 7 Log Likelihood:  -654.006689590017 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.89369267982 
Iteration 2 Log Likelihood:  -6561.07560582709 
Iteration 3 Log Likelihood:  -6561.07560582709 
Iteration 4 Log Likelihood:  -6561.07560582709 
Iteration 5 Log Likelihood:  -6561.07560582709 
Iteration 6 Log Likelihood:  -6561.07560582709 
Iteration 7 Log Likelihood:  -6561.07560582709 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.16119414253 
Iteration 2 Log Likelihood:  -5686.83617223921 
Iteration 3 Log Likelihood:  -5686.83617223921 
Iteration 4 Log Likelihood:  -5686.83617223921 
Iteration 5 Log Likelihood:  -5686.83617223921 
Iteration 6 Log Likelihood:  -5686.8361722392 
Iteration 7 Log Likelihood:  -5686.83617223921 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6617.40456609032 
Iteration 2 Log Likelihood:  -841.932131806895 
Iteration 3 Log Likelihood:  -841.932131806852 
Iteration 4 Log Likelihood:  -841.932131806856 
Iteration 5 Log Likelihood:  -841.932131806891 
Iteration 6 Log Likelihood:  -841.932131806874 
Iteration 7 Log Likelihood:  -841.932131806853 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6620.73215739784 
Iteration 2 Log Likelihood:  -6561.88607749854 
Iteration 3 Log Likelihood:  -6561.88604501904 
Iteration 4 Log Likelihood:  -6561.88601234071 
Iteration 5 Log Likelihood:  -6561.88597946003 
Iteration 6 Log Likelihood:  -6561.88594637342 
Iteration 7 Log Likelihood:  -6561.88591307724 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.96036229631 
Iteration 2 Log Likelihood:  -5687.45072705396 
Iteration 3 Log Likelihood:  -5687.45059498994 
Iteration 4 Log Likelihood:  -5687.4504606209 
Iteration 5 Log Likelihood:  -5687.45032384189 
Iteration 6 Log Likelihood:  -5687.45018456596 
Iteration 7 Log Likelihood:  -5687.45004270204 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6618.12897677994 
Iteration 2 Log Likelihood:  -841.106276262346 
Iteration 3 Log Likelihood:  -840.669230526853 
Iteration 4 Log Likelihood:  -840.183811122732 
Iteration 5 Log Likelihood:  -839.821959707202 
Iteration 6 Log Likelihood:  -839.593822889398 
Iteration 7 Log Likelihood:  -839.433155376038 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.71247723776 
Iteration 2 Log Likelihood:  -6560.91619433764 
Iteration 3 Log Likelihood:  -6560.91328115133 
Iteration 4 Log Likelihood:  -6560.9101678383 
Iteration 5 Log Likelihood:  -6560.90682210993 
Iteration 6 Log Likelihood:  -6560.90320698802 
Iteration 7 Log Likelihood:  -6560.89927994341 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6618.7725351114 
Iteration 2 Log Likelihood:  -5686.66872413036 
Iteration 3 Log Likelihood:  -5686.6530468211 
Iteration 4 Log Likelihood:  -5686.63320736557 
Iteration 5 Log Likelihood:  -5686.60697652424 
Iteration 6 Log Likelihood:  -5686.57035647446 
Iteration 7 Log Likelihood:  -5686.51557216301 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6616.69634331023 
Iteration 2 Log Likelihood:  -823.036574684384 
Iteration 3 Log Likelihood:  -778.558001973472 
Iteration 4 Log Likelihood:  -762.271163798229 
Iteration 5 Log Likelihood:  -761.305039697819 
Iteration 6 Log Likelihood:  -761.195929131377 
Iteration 7 Log Likelihood:  -761.170341308712 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.89369267982 
Iteration 2 Log Likelihood:  -6561.07560582709 
Iteration 3 Log Likelihood:  -6561.07560582709 
Iteration 4 Log Likelihood:  -6561.07560582709 
Iteration 5 Log Likelihood:  -6561.07560582709 
Iteration 6 Log Likelihood:  -6561.07560582709 
Iteration 7 Log Likelihood:  -6561.07560582709 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.16119414253 
Iteration 2 Log Likelihood:  -5686.83617223921 
Iteration 3 Log Likelihood:  -5686.83617223921 
Iteration 4 Log Likelihood:  -5686.83617223921 
Iteration 5 Log Likelihood:  -5686.83617223921 
Iteration 6 Log Likelihood:  -5686.83617223921 
Iteration 7 Log Likelihood:  -5686.83617223921 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6617.40456609032 
Iteration 2 Log Likelihood:  -841.932131806891 
Iteration 3 Log Likelihood:  -841.932131806906 
Iteration 4 Log Likelihood:  -841.932131806851 
Iteration 5 Log Likelihood:  -841.932131806859 
Iteration 6 Log Likelihood:  -841.932131806899 
Iteration 7 Log Likelihood:  -841.932131806907 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6620.72854902772 
Iteration 2 Log Likelihood:  -6561.88052368632 
Iteration 3 Log Likelihood:  -6561.88043985928 
Iteration 4 Log Likelihood:  -6561.88035532743 
Iteration 5 Log Likelihood:  -6561.88027006506 
Iteration 6 Log Likelihood:  -6561.88018406267 
Iteration 7 Log Likelihood:  -6561.88009731061 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.95978529707 
Iteration 2 Log Likelihood:  -5687.4444006889 
Iteration 3 Log Likelihood:  -5687.4440376761 
Iteration 4 Log Likelihood:  -5687.44366629752 
Iteration 5 Log Likelihood:  -5687.44328605008 
Iteration 6 Log Likelihood:  -5687.44289670647 
Iteration 7 Log Likelihood:  -5687.44249802514 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6618.11779434687 
Iteration 2 Log Likelihood:  -841.08864852979 
Iteration 3 Log Likelihood:  -840.639926929398 
Iteration 4 Log Likelihood:  -840.132042779665 
Iteration 5 Log Likelihood:  -839.718257420724 
Iteration 6 Log Likelihood:  -839.380959450113 
Iteration 7 Log Likelihood:  -839.013087829198 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6619.6797884455 
Iteration 2 Log Likelihood:  -6560.86269130645 
Iteration 3 Log Likelihood:  -6560.85517110222 
Iteration 4 Log Likelihood:  -6560.84700873494 
Iteration 5 Log Likelihood:  -6560.83811706163 
Iteration 6 Log Likelihood:  -6560.8283943858 
Iteration 7 Log Likelihood:  -6560.81771940747 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6618.76732140989 
Iteration 2 Log Likelihood:  -5686.61617239869 
Iteration 3 Log Likelihood:  -5686.58239622996 
Iteration 4 Log Likelihood:  -5686.53999663489 
Iteration 5 Log Likelihood:  -5686.48547268241 
Iteration 6 Log Likelihood:  -5686.41240162115 
Iteration 7 Log Likelihood:  -5686.30837418152 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6616.59545063424 
Iteration 2 Log Likelihood:  -821.786536006506 
Iteration 3 Log Likelihood:  -764.643127434558 
Iteration 4 Log Likelihood:  -717.482697230982 
Iteration 5 Log Likelihood:  -702.849220270902 
Iteration 6 Log Likelihood:  -701.62703624763 
Iteration 7 Log Likelihood:  -701.583744480856 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.23420320129 
Iteration 2 Log Likelihood:  -6520.89664226753 
Iteration 3 Log Likelihood:  -6520.89664226753 
Iteration 4 Log Likelihood:  -6520.89664226753 
Iteration 5 Log Likelihood:  -6520.89664226753 
Iteration 6 Log Likelihood:  -6520.89664226753 
Iteration 7 Log Likelihood:  -6520.89664226753 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6575.95757039293 
Iteration 2 Log Likelihood:  -5665.12386044525 
Iteration 3 Log Likelihood:  -5665.12386044525 
Iteration 4 Log Likelihood:  -5665.12386044525 
Iteration 5 Log Likelihood:  -5665.12386044525 
Iteration 6 Log Likelihood:  -5665.12386044525 
Iteration 7 Log Likelihood:  -5665.12386044525 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6572.91713901799 
Iteration 2 Log Likelihood:  -899.239078888175 
Iteration 3 Log Likelihood:  -899.239078888146 
Iteration 4 Log Likelihood:  -899.239078888199 
Iteration 5 Log Likelihood:  -899.239078888191 
Iteration 6 Log Likelihood:  -899.239078888239 
Iteration 7 Log Likelihood:  -899.239078888182 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.58263227899 
Iteration 2 Log Likelihood:  -6521.25923651401 
Iteration 3 Log Likelihood:  -6521.25922180447 
Iteration 4 Log Likelihood:  -6521.25920709013 
Iteration 5 Log Likelihood:  -6521.25919237097 
Iteration 6 Log Likelihood:  -6521.25917764699 
Iteration 7 Log Likelihood:  -6521.25916291814 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6576.31111046844 
Iteration 2 Log Likelihood:  -5665.63742227468 
Iteration 3 Log Likelihood:  -5665.63731319499 
Iteration 4 Log Likelihood:  -5665.63720303839 
Iteration 5 Log Likelihood:  -5665.63709178731 
Iteration 6 Log Likelihood:  -5665.63697942524 
Iteration 7 Log Likelihood:  -5665.63686593396 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6573.26676165004 
Iteration 2 Log Likelihood:  -900.25175059427 
Iteration 3 Log Likelihood:  -900.173849165335 
Iteration 4 Log Likelihood:  -900.036658422812 
Iteration 5 Log Likelihood:  -899.820494882582 
Iteration 6 Log Likelihood:  -899.532900912893 
Iteration 7 Log Likelihood:  -899.22177844626 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.18981213448 
Iteration 2 Log Likelihood:  -6520.83880769293 
Iteration 3 Log Likelihood:  -6520.8376113534 
Iteration 4 Log Likelihood:  -6520.83641054373 
Iteration 5 Log Likelihood:  -6520.83520468178 
Iteration 6 Log Likelihood:  -6520.83399295315 
Iteration 7 Log Likelihood:  -6520.83277430482 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6575.9253979934 
Iteration 2 Log Likelihood:  -5665.04981910707 
Iteration 3 Log Likelihood:  -5665.04073191666 
Iteration 4 Log Likelihood:  -5665.03068297047 
Iteration 5 Log Likelihood:  -5665.01944202306 
Iteration 6 Log Likelihood:  -5665.0066246179 
Iteration 7 Log Likelihood:  -5664.99163187608 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6572.76897546227 
Iteration 2 Log Likelihood:  -895.511875736268 
Iteration 3 Log Likelihood:  -878.592401551251 
Iteration 4 Log Likelihood:  -830.256710060586 
Iteration 5 Log Likelihood:  -826.595532651918 
Iteration 6 Log Likelihood:  -816.880992482384 
Iteration 7 Log Likelihood:  -772.337095915086 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.23420320129 
Iteration 2 Log Likelihood:  -6520.89664226753 
Iteration 3 Log Likelihood:  -6520.89664226753 
Iteration 4 Log Likelihood:  -6520.89664226753 
Iteration 5 Log Likelihood:  -6520.89664226753 
Iteration 6 Log Likelihood:  -6520.89664226753 
Iteration 7 Log Likelihood:  -6520.89664226753 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6575.95757039293 
Iteration 2 Log Likelihood:  -5665.12386044525 
Iteration 3 Log Likelihood:  -5665.12386044525 
Iteration 4 Log Likelihood:  -5665.12386044525 
Iteration 5 Log Likelihood:  -5665.12386044525 
Iteration 6 Log Likelihood:  -5665.12386044525 
Iteration 7 Log Likelihood:  -5665.12386044525 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6572.91713901799 
Iteration 2 Log Likelihood:  -899.239078888234 
Iteration 3 Log Likelihood:  -899.239078888162 
Iteration 4 Log Likelihood:  -899.239078888264 
Iteration 5 Log Likelihood:  -899.239078888205 
Iteration 6 Log Likelihood:  -899.239078888179 
Iteration 7 Log Likelihood:  -899.239078888184 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.57679514882 
Iteration 2 Log Likelihood:  -6521.25426842223 
Iteration 3 Log Likelihood:  -6521.25420271277 
Iteration 4 Log Likelihood:  -6521.25413659475 
Iteration 5 Log Likelihood:  -6521.25407004916 
Iteration 6 Log Likelihood:  -6521.25400307452 
Iteration 7 Log Likelihood:  -6521.25393566931 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6576.27677679219 
Iteration 2 Log Likelihood:  -5665.62567980077 
Iteration 3 Log Likelihood:  -5665.62482440708 
Iteration 4 Log Likelihood:  -5665.623924362 
Iteration 5 Log Likelihood:  -5665.62297502753 
Iteration 6 Log Likelihood:  -5665.62197306425 
Iteration 7 Log Likelihood:  -5665.6209148069 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6573.18442993799 
Iteration 2 Log Likelihood:  -900.181743134162 
Iteration 3 Log Likelihood:  -900.034528008043 
Iteration 4 Log Likelihood:  -899.770651635038 
Iteration 5 Log Likelihood:  -899.344030299143 
Iteration 6 Log Likelihood:  -898.752480377963 
Iteration 7 Log Likelihood:  -898.068795816342 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6577.13708585451 
Iteration 2 Log Likelihood:  -6520.78970088088 
Iteration 3 Log Likelihood:  -6520.78398590656 
Iteration 4 Log Likelihood:  -6520.77794555052 
Iteration 5 Log Likelihood:  -6520.77156459279 
Iteration 6 Log Likelihood:  -6520.76482626809 
Iteration 7 Log Likelihood:  -6520.75771005872 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6575.61400438821 
Iteration 2 Log Likelihood:  -5664.82774032062 
Iteration 3 Log Likelihood:  -5664.66573765052 
Iteration 4 Log Likelihood:  -5664.36897548409 
Iteration 5 Log Likelihood:  -5663.79651159019 
Iteration 6 Log Likelihood:  -5662.78155810771 
Iteration 7 Log Likelihood:  -5661.52551920931 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6572.01820116865 
Iteration 2 Log Likelihood:  -885.197418659863 
Iteration 3 Log Likelihood:  -829.059869312616 
Iteration 4 Log Likelihood:  -770.224449465003 
Iteration 5 Log Likelihood:  -765.524616992553 
Iteration 6 Log Likelihood:  -756.00078250969 
Iteration 7 Log Likelihood:  -741.156917331195 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.77712286445 
Iteration 2 Log Likelihood:  -6489.89483028445 
Iteration 3 Log Likelihood:  -6489.89483028445 
Iteration 4 Log Likelihood:  -6489.89483028445 
Iteration 5 Log Likelihood:  -6489.89483028445 
Iteration 6 Log Likelihood:  -6489.89483028445 
Iteration 7 Log Likelihood:  -6489.89483028446 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.20454194529 
Iteration 2 Log Likelihood:  -5633.24434916167 
Iteration 3 Log Likelihood:  -5633.24434916167 
Iteration 4 Log Likelihood:  -5633.24434916167 
Iteration 5 Log Likelihood:  -5633.24434916167 
Iteration 6 Log Likelihood:  -5633.24434916167 
Iteration 7 Log Likelihood:  -5633.24434916167 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.4533948103 
Iteration 2 Log Likelihood:  -870.253357075895 
Iteration 3 Log Likelihood:  -870.253357075763 
Iteration 4 Log Likelihood:  -870.253357075723 
Iteration 5 Log Likelihood:  -870.253357075806 
Iteration 6 Log Likelihood:  -870.253357075776 
Iteration 7 Log Likelihood:  -870.253357075827 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.35145589132 
Iteration 2 Log Likelihood:  -6488.4237424131 
Iteration 3 Log Likelihood:  -6488.42371451353 
Iteration 4 Log Likelihood:  -6488.42368659592 
Iteration 5 Log Likelihood:  -6488.42365865912 
Iteration 6 Log Likelihood:  -6488.42363070197 
Iteration 7 Log Likelihood:  -6488.42360272327 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6542.76075872508 
Iteration 2 Log Likelihood:  -5631.34448814835 
Iteration 3 Log Likelihood:  -5631.34432806318 
Iteration 4 Log Likelihood:  -5631.3441657561 
Iteration 5 Log Likelihood:  -5631.34400113969 
Iteration 6 Log Likelihood:  -5631.34383412267 
Iteration 7 Log Likelihood:  -5631.34366460972 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6538.96737149995 
Iteration 2 Log Likelihood:  -866.965729847917 
Iteration 3 Log Likelihood:  -866.962211866829 
Iteration 4 Log Likelihood:  -866.95532824111 
Iteration 5 Log Likelihood:  -866.941957184309 
Iteration 6 Log Likelihood:  -866.916320497167 
Iteration 7 Log Likelihood:  -866.868197350478 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.73173168418 
Iteration 2 Log Likelihood:  -6489.84684980789 
Iteration 3 Log Likelihood:  -6489.84453222726 
Iteration 4 Log Likelihood:  -6489.84218713045 
Iteration 5 Log Likelihood:  -6489.83980518083 
Iteration 6 Log Likelihood:  -6489.83737624559 
Iteration 7 Log Likelihood:  -6489.83488935248 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.11562676222 
Iteration 2 Log Likelihood:  -5633.20081204864 
Iteration 3 Log Likelihood:  -5633.18405904615 
Iteration 4 Log Likelihood:  -5633.16389593101 
Iteration 5 Log Likelihood:  -5633.13872490908 
Iteration 6 Log Likelihood:  -5633.10600617921 
Iteration 7 Log Likelihood:  -5633.06152722786 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.25951292239 
Iteration 2 Log Likelihood:  -868.190120591148 
Iteration 3 Log Likelihood:  -834.896814511798 
Iteration 4 Log Likelihood:  -800.303345059751 
Iteration 5 Log Likelihood:  -790.706072727802 
Iteration 6 Log Likelihood:  -753.646625531248 
Iteration 7 Log Likelihood:  -753.197320366948 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.77712286445 
Iteration 2 Log Likelihood:  -6489.89483028445 
Iteration 3 Log Likelihood:  -6489.89483028445 
Iteration 4 Log Likelihood:  -6489.89483028446 
Iteration 5 Log Likelihood:  -6489.89483028446 
Iteration 6 Log Likelihood:  -6489.89483028445 
Iteration 7 Log Likelihood:  -6489.89483028446 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.20454194529 
Iteration 2 Log Likelihood:  -5633.24434916167 
Iteration 3 Log Likelihood:  -5633.24434916167 
Iteration 4 Log Likelihood:  -5633.24434916167 
Iteration 5 Log Likelihood:  -5633.24434916167 
Iteration 6 Log Likelihood:  -5633.24434916167 
Iteration 7 Log Likelihood:  -5633.24434916167 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.4533948103 
Iteration 2 Log Likelihood:  -870.253357075793 
Iteration 3 Log Likelihood:  -870.253357075818 
Iteration 4 Log Likelihood:  -870.253357075783 
Iteration 5 Log Likelihood:  -870.253357075786 
Iteration 6 Log Likelihood:  -870.253357075906 
Iteration 7 Log Likelihood:  -870.253357075789 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.34569629194 
Iteration 2 Log Likelihood:  -6488.41751922605 
Iteration 3 Log Likelihood:  -6488.41747402604 
Iteration 4 Log Likelihood:  -6488.41742885551 
Iteration 5 Log Likelihood:  -6488.41738371365 
Iteration 6 Log Likelihood:  -6488.41733859963 
Iteration 7 Log Likelihood:  -6488.41729351259 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6542.75472421598 
Iteration 2 Log Likelihood:  -5631.33432758979 
Iteration 3 Log Likelihood:  -5631.33390242588 
Iteration 4 Log Likelihood:  -5631.33346636213 
Iteration 5 Log Likelihood:  -5631.33301890537 
Iteration 6 Log Likelihood:  -5631.33255951443 
Iteration 7 Log Likelihood:  -5631.33208761489 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6538.96107446039 
Iteration 2 Log Likelihood:  -866.92776714917 
Iteration 3 Log Likelihood:  -866.88897980669 
Iteration 4 Log Likelihood:  -866.817186277282 
Iteration 5 Log Likelihood:  -866.690162919224 
Iteration 6 Log Likelihood:  -866.4792530579 
Iteration 7 Log Likelihood:  -866.156576424566 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6545.67934612124 
Iteration 2 Log Likelihood:  -6489.78914013511 
Iteration 3 Log Likelihood:  -6489.78544800469 
Iteration 4 Log Likelihood:  -6489.78176644721 
Iteration 5 Log Likelihood:  -6489.77808731568 
Iteration 6 Log Likelihood:  -6489.77440119183 
Iteration 7 Log Likelihood:  -6489.77069739168 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6544.06074442384 
Iteration 2 Log Likelihood:  -5633.09411673256 
Iteration 3 Log Likelihood:  -5633.04869955338 
Iteration 4 Log Likelihood:  -5632.98830695073 
Iteration 5 Log Likelihood:  -5632.90366313898 
Iteration 6 Log Likelihood:  -5632.77748062395 
Iteration 7 Log Likelihood:  -5632.57556561418 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6540.20224644247 
Iteration 2 Log Likelihood:  -868.160375308288 
Iteration 3 Log Likelihood:  -833.878389182191 
Iteration 4 Log Likelihood:  -789.540063786067 
Iteration 5 Log Likelihood:  -767.926079837915 
Iteration 6 Log Likelihood:  -727.13314563356 
Iteration 7 Log Likelihood:  -721.117082441758 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6571.79130019104 
Iteration 2 Log Likelihood:  -6511.90561746083 
Iteration 3 Log Likelihood:  -6511.90561746083 
Iteration 4 Log Likelihood:  -6511.90561746083 
Iteration 5 Log Likelihood:  -6511.90561746083 
Iteration 6 Log Likelihood:  -6511.90561746083 
Iteration 7 Log Likelihood:  -6511.90561746083 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6570.57886240789 
Iteration 2 Log Likelihood:  -5624.17741109385 
Iteration 3 Log Likelihood:  -5624.17741109385 
Iteration 4 Log Likelihood:  -5624.17741109385 
Iteration 5 Log Likelihood:  -5624.17741109384 
Iteration 6 Log Likelihood:  -5624.17741109385 
Iteration 7 Log Likelihood:  -5624.17741109385 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6567.69179814192 
Iteration 2 Log Likelihood:  -680.461632988702 
Iteration 3 Log Likelihood:  -680.461632988631 
Iteration 4 Log Likelihood:  -680.461632988594 
Iteration 5 Log Likelihood:  -680.461632988684 
Iteration 6 Log Likelihood:  -680.461632988713 
Iteration 7 Log Likelihood:  -680.46163298865 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6571.45143031403 
Iteration 2 Log Likelihood:  -6511.5826470883 
Iteration 3 Log Likelihood:  -6511.58263732963 
Iteration 4 Log Likelihood:  -6511.58262755739 
Iteration 5 Log Likelihood:  -6511.58261777138 
Iteration 6 Log Likelihood:  -6511.58260797139 
Iteration 7 Log Likelihood:  -6511.58259815723 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6570.2205300317 
Iteration 2 Log Likelihood:  -5623.94048740289 
Iteration 3 Log Likelihood:  -5623.94043043138 
Iteration 4 Log Likelihood:  -5623.94037308193 
Iteration 5 Log Likelihood:  -5623.94031535296 
Iteration 6 Log Likelihood:  -5623.94025724414 
Iteration 7 Log Likelihood:  -5623.94019875507 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6567.2976025221 
Iteration 2 Log Likelihood:  -680.226352705063 
Iteration 3 Log Likelihood:  -680.200204822609 
Iteration 4 Log Likelihood:  -680.144570805074 
Iteration 5 Log Likelihood:  -680.028233191412 
Iteration 6 Log Likelihood:  -679.797309390662 
Iteration 7 Log Likelihood:  -679.390910674769 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6571.71085655111 
Iteration 2 Log Likelihood:  -6511.84168403658 
Iteration 3 Log Likelihood:  -6511.84087956697 
Iteration 4 Log Likelihood:  -6511.84006264806 
Iteration 5 Log Likelihood:  -6511.83923180155 
Iteration 6 Log Likelihood:  -6511.83838546993 
Iteration 7 Log Likelihood:  -6511.8375220121 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6570.41729147269 
Iteration 2 Log Likelihood:  -5624.1337995223 
Iteration 3 Log Likelihood:  -5624.12873731277 
Iteration 4 Log Likelihood:  -5624.1233804272 
Iteration 5 Log Likelihood:  -5624.11770246302 
Iteration 6 Log Likelihood:  -5624.11166208772 
Iteration 7 Log Likelihood:  -5624.10519812999 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6567.41036878525 
Iteration 2 Log Likelihood:  -674.456889782276 
Iteration 3 Log Likelihood:  -619.146425865761 
Iteration 4 Log Likelihood:  -590.092138037139 
Iteration 5 Log Likelihood:  -586.52770903808 
Iteration 6 Log Likelihood:  -585.890517588048 
Iteration 7 Log Likelihood:  -585.784159996042 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6571.79130019104 
Iteration 2 Log Likelihood:  -6511.90561746083 
Iteration 3 Log Likelihood:  -6511.90561746083 
Iteration 4 Log Likelihood:  -6511.90561746083 
Iteration 5 Log Likelihood:  -6511.90561746083 
Iteration 6 Log Likelihood:  -6511.90561746083 
Iteration 7 Log Likelihood:  -6511.90561746083 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6570.57886240789 
Iteration 2 Log Likelihood:  -5624.17741109385 
Iteration 3 Log Likelihood:  -5624.17741109385 
Iteration 4 Log Likelihood:  -5624.17741109385 
Iteration 5 Log Likelihood:  -5624.17741109385 
Iteration 6 Log Likelihood:  -5624.17741109385 
Iteration 7 Log Likelihood:  -5624.17741109385 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6567.69179814192 
Iteration 2 Log Likelihood:  -680.461632988625 
Iteration 3 Log Likelihood:  -680.461632988673 
Iteration 4 Log Likelihood:  -680.461632988626 
Iteration 5 Log Likelihood:  -680.461632988617 
Iteration 6 Log Likelihood:  -680.461632988632 
Iteration 7 Log Likelihood:  -680.461632988702 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6571.44456069804 
Iteration 2 Log Likelihood:  -6511.57621511282 
Iteration 3 Log Likelihood:  -6511.57615663827 
Iteration 4 Log Likelihood:  -6511.57609781667 
Iteration 5 Log Likelihood:  -6511.57603864375 
Iteration 6 Log Likelihood:  -6511.5759791175 
Iteration 7 Log Likelihood:  -6511.57591923591 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6570.19759729129 
Iteration 2 Log Likelihood:  -5623.92865847107 
Iteration 3 Log Likelihood:  -5623.92784160216 
Iteration 4 Log Likelihood:  -5623.92697501447 
Iteration 5 Log Likelihood:  -5623.92605464964 
Iteration 6 Log Likelihood:  -5623.92507658391 
Iteration 7 Log Likelihood:  -5623.92403653912 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6567.25109704771 
Iteration 2 Log Likelihood:  -680.010993788183 
Iteration 3 Log Likelihood:  -679.757018690667 
Iteration 4 Log Likelihood:  -679.328848816615 
Iteration 5 Log Likelihood:  -678.736029781385 
Iteration 6 Log Likelihood:  -678.024149187759 
Iteration 7 Log Likelihood:  -677.206396997672 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6571.64900463587 
Iteration 2 Log Likelihood:  -6511.78018341742 
Iteration 3 Log Likelihood:  -6511.77516430005 
Iteration 4 Log Likelihood:  -6511.76987349232 
Iteration 5 Log Likelihood:  -6511.76429589246 
Iteration 6 Log Likelihood:  -6511.75841529169 
Iteration 7 Log Likelihood:  -6511.7522140262 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6570.21074622662 
Iteration 2 Log Likelihood:  -5623.93921685708 
Iteration 3 Log Likelihood:  -5623.79976117836 
Iteration 4 Log Likelihood:  -5623.5489773674 
Iteration 5 Log Likelihood:  -5623.07869688382 
Iteration 6 Log Likelihood:  -5622.23657886178 
Iteration 7 Log Likelihood:  -5621.0625029782 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6566.99112462364 
Iteration 2 Log Likelihood:  -674.663857201253 
Iteration 3 Log Likelihood:  -610.831084801548 
Iteration 4 Log Likelihood:  -559.58368727193 
Iteration 5 Log Likelihood:  -552.275855635038 
Iteration 6 Log Likelihood:  -551.571719180943 
Iteration 7 Log Likelihood:  -551.450416348572 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6405.48113097652 
Iteration 2 Log Likelihood:  -6350.01284136535 
Iteration 3 Log Likelihood:  -6350.01284136535 
Iteration 4 Log Likelihood:  -6350.01284136535 
Iteration 5 Log Likelihood:  -6350.01284136535 
Iteration 6 Log Likelihood:  -6350.01284136535 
Iteration 7 Log Likelihood:  -6350.01284136535 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6402.45311812 
Iteration 2 Log Likelihood:  -5501.78576175345 
Iteration 3 Log Likelihood:  -5501.78576175345 
Iteration 4 Log Likelihood:  -5501.78576175345 
Iteration 5 Log Likelihood:  -5501.78576175345 
Iteration 6 Log Likelihood:  -5501.78576175345 
Iteration 7 Log Likelihood:  -5501.78576175345 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6395.2753358839 
Iteration 2 Log Likelihood:  -698.918639237796 
Iteration 3 Log Likelihood:  -698.918639237747 
Iteration 4 Log Likelihood:  -698.918639237842 
Iteration 5 Log Likelihood:  -698.918639237698 
Iteration 6 Log Likelihood:  -698.918639237816 
Iteration 7 Log Likelihood:  -698.918639237843 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6401.95664040834 
Iteration 2 Log Likelihood:  -6346.5417148173 
Iteration 3 Log Likelihood:  -6346.54137788012 
Iteration 4 Log Likelihood:  -6346.5410371785 
Iteration 5 Log Likelihood:  -6346.54069244526 
Iteration 6 Log Likelihood:  -6346.54034340738 
Iteration 7 Log Likelihood:  -6346.53998978572 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6398.78793365021 
Iteration 2 Log Likelihood:  -5498.72180978428 
Iteration 3 Log Likelihood:  -5498.72065341459 
Iteration 4 Log Likelihood:  -5498.71949031196 
Iteration 5 Log Likelihood:  -5498.71831678965 
Iteration 6 Log Likelihood:  -5498.71712900575 
Iteration 7 Log Likelihood:  -5498.71592294524 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6391.33823977275 
Iteration 2 Log Likelihood:  -698.347381153324 
Iteration 3 Log Likelihood:  -698.14808959944 
Iteration 4 Log Likelihood:  -697.73648212319 
Iteration 5 Log Likelihood:  -697.036846620333 
Iteration 6 Log Likelihood:  -696.159372984946 
Iteration 7 Log Likelihood:  -695.373577002222 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6404.57073001881 
Iteration 2 Log Likelihood:  -6349.15103127408 
Iteration 3 Log Likelihood:  -6349.11823931127 
Iteration 4 Log Likelihood:  -6349.07888168893 
Iteration 5 Log Likelihood:  -6349.03016285901 
Iteration 6 Log Likelihood:  -6348.96863082301 
Iteration 7 Log Likelihood:  -6348.8901101118 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6401.00911376782 
Iteration 2 Log Likelihood:  -5500.89477862138 
Iteration 3 Log Likelihood:  -5500.75393808152 
Iteration 4 Log Likelihood:  -5500.5150668426 
Iteration 5 Log Likelihood:  -5500.02995424013 
Iteration 6 Log Likelihood:  -5498.86073419992 
Iteration 7 Log Likelihood:  -5495.85829355879 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6393.0816088702 
Iteration 2 Log Likelihood:  -663.161921379397 
Iteration 3 Log Likelihood:  -607.685202424073 
Iteration 4 Log Likelihood:  -594.484351529827 
Iteration 5 Log Likelihood:  -591.600920383206 
Iteration 6 Log Likelihood:  -590.935827887099 
Iteration 7 Log Likelihood:  -590.687292310313 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6405.48113097652 
Iteration 2 Log Likelihood:  -6350.01284136535 
Iteration 3 Log Likelihood:  -6350.01284136535 
Iteration 4 Log Likelihood:  -6350.01284136535 
Iteration 5 Log Likelihood:  -6350.01284136535 
Iteration 6 Log Likelihood:  -6350.01284136535 
Iteration 7 Log Likelihood:  -6350.01284136535 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6402.45311812 
Iteration 2 Log Likelihood:  -5501.78576175345 
Iteration 3 Log Likelihood:  -5501.78576175345 
Iteration 4 Log Likelihood:  -5501.78576175345 
Iteration 5 Log Likelihood:  -5501.78576175344 
Iteration 6 Log Likelihood:  -5501.78576175344 
Iteration 7 Log Likelihood:  -5501.78576175345 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6395.2753358839 
Iteration 2 Log Likelihood:  -698.918639237922 
Iteration 3 Log Likelihood:  -698.918639237761 
Iteration 4 Log Likelihood:  -698.918639237786 
Iteration 5 Log Likelihood:  -698.918639237821 
Iteration 6 Log Likelihood:  -698.91863923786 
Iteration 7 Log Likelihood:  -698.918639237867 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6401.89201546963 
Iteration 2 Log Likelihood:  -6346.48414682303 
Iteration 3 Log Likelihood:  -6346.48297182324 
Iteration 4 Log Likelihood:  -6346.48177843668 
Iteration 5 Log Likelihood:  -6346.48056596697 
Iteration 6 Log Likelihood:  -6346.47933372014 
Iteration 7 Log Likelihood:  -6346.47808097598 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6398.6614506993 
Iteration 2 Log Likelihood:  -5498.66892713771 
Iteration 3 Log Likelihood:  -5498.66460536731 
Iteration 4 Log Likelihood:  -5498.66001385105 
Iteration 5 Log Likelihood:  -5498.65511035564 
Iteration 6 Log Likelihood:  -5498.64984656591 
Iteration 7 Log Likelihood:  -5498.64416568216 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6391.13616265895 
Iteration 2 Log Likelihood:  -697.984572694181 
Iteration 3 Log Likelihood:  -697.413071242465 
Iteration 4 Log Likelihood:  -696.507273119941 
Iteration 5 Log Likelihood:  -695.378649261269 
Iteration 6 Log Likelihood:  -694.225291525965 
Iteration 7 Log Likelihood:  -693.257135709891 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6403.986951159 
Iteration 2 Log Likelihood:  -6348.56517565525 
Iteration 3 Log Likelihood:  -6348.44964538074 
Iteration 4 Log Likelihood:  -6348.31160364812 
Iteration 5 Log Likelihood:  -6348.14436903326 
Iteration 6 Log Likelihood:  -6347.94153828299 
Iteration 7 Log Likelihood:  -6347.69960159616 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6399.86571923353 
Iteration 2 Log Likelihood:  -5499.9205956982 
Iteration 3 Log Likelihood:  -5498.64694487971 
Iteration 4 Log Likelihood:  -5494.98114909535 
Iteration 5 Log Likelihood:  -5489.57556207948 
Iteration 6 Log Likelihood:  -5487.66762549996 
Iteration 7 Log Likelihood:  -5487.08959781395 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6391.25111568495 
Iteration 2 Log Likelihood:  -664.818808913319 
Iteration 3 Log Likelihood:  -570.378645479369 
Iteration 4 Log Likelihood:  -557.903616742362 
Iteration 5 Log Likelihood:  -556.903190232196 
Iteration 6 Log Likelihood:  -556.284426229807 
Iteration 7 Log Likelihood:  -555.954424756842 
Initialization by the identity.
Iteration 1 Log Likelihood:  -6561.4818239519 
Iteration 2 Log Likelihood:  -6505.64882766607 
Iteration 3 Log Likelihood:  -6505.64882766607 
Iteration 4 Log Likelihood:  -6505.64882766607 
Iteration 5 Log Likelihood:  -6505.64882766607 
Iteration 6 Log Likelihood:  -6505.64882766607 
Iteration 7 Log Likelihood:  -6505.64882766607 
85.696 sec elapsed
[1] "Running hdda"
0.965 sec elapsed
[1] "Running J48"
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by weka.core.WekaPackageClassLoaderManager (file:/nfs/nfs9/home/nobackup/parishar/R/library/RWekajars/java/weka.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
WARNING: Please consider reporting this to the maintainers of weka.core.WekaPackageClassLoaderManager
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
11.345 sec elapsed
[1] "Running JRip"
33.347 sec elapsed
[1] "Running LMT"
6.07 sec elapsed
[1] "Running OneR"
1.042 sec elapsed
[1] "Running PART"
6.891 sec elapsed
[1] "Running kernelpls"
0.511 sec elapsed
[1] "Running simpls"
0.51 sec elapsed
[1] "Running widekernelpls"
2.864 sec elapsed
[1] "Running kknn"
4.322 sec elapsed
[1] "Running knn"
0.642 sec elapsed
[1] "Running loclda"
16.053 sec elapsed
[1] "Running stepLDA"
 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.72359;  in: "ft";  variables (1): ft 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.705 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.73788;  in: "x3pa";  variables (1): x3pa 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.69 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.69091;  in: "x3pa";  variables (1): x3pa 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.688 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68247;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.7 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.69113;  in: "ast";  variables (1): ast 

 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.7 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68571;  in: "stl";  variables (1): stl 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.703 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68182;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.71 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.65974;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.705 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.71082;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.691 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67771;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.704 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.6868;  in: "ast";  variables (1): ast 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.704 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.6881;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.704 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.7197;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.693 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.70909;  in: "drb";  variables (1): drb 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.69 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67857;  in: "drb";  variables (1): drb 
correctness rate: 0.76558;  in: "x2pa";  variables (2): drb, x2pa 
correctness rate: 0.82576;  in: "x2p";  variables (3): drb, x2pa, x2p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       1.414 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.65823;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.69 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.6961;  in: "x3p";  variables (1): x3p 
correctness rate: 0.75152;  in: "x3pa";  variables (2): x3p, x3pa 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       1.036 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.66407;  in: "x3p";  variables (1): x3p 
correctness rate: 0.72879;  in: "x3pa";  variables (2): x3p, x3pa 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       1.034 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.66429;  in: "blk";  variables (1): blk 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.689 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.71905;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.705 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.69632;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.705 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68182;  in: "drb";  variables (1): drb 
correctness rate: 0.76039;  in: "tov";  variables (2): drb, tov 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       1.041 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68095;  in: "ft";  variables (1): ft 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.707 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68268;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.707 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.72403;  in: "fg";  variables (1): fg 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.693 

 `stepwise classification', using 10-fold cross-validated correctness rate of method lda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.66407;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.703 

21.523 sec elapsed
[1] "Running stepQDA"
 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.72749;  in: "ft";  variables (1): ft 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.686 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.69502;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.683 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67706;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.679 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.70022;  in: "x2p";  variables (1): x2p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.662 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.71342;  in: "ast";  variables (1): ast 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.677 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.69242;  in: "stl";  variables (1): stl 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.678 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67662;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.665 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.64957;  in: "drb";  variables (1): drb 
correctness rate: 0.72251;  in: "tov";  variables (2): drb, tov 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.998 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.70887;  in: "fg";  variables (1): fg 
correctness rate: 0.77879;  in: "pf";  variables (2): fg, pf 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       1.003 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.65931;  in: "stl";  variables (1): stl 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.678 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.6961;  in: "stl";  variables (1): stl 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.681 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67662;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.666 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.71753;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.68 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.71472;  in: "drb";  variables (1): drb 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.68 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68225;  in: "drb";  variables (1): drb 
correctness rate: 0.76537;  in: "trb";  variables (2): drb, trb 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       1.274 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.63593;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.661 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.68658;  in: "fg";  variables (1): fg 
correctness rate: 0.76515;  in: "tov";  variables (2): fg, tov 

 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.99 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67208;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.672 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.65;  in: "x3p";  variables (1): x3p 
correctness rate: 0.70519;  in: "x3pa";  variables (2): x3p, x3pa 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.991 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.70043;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.675 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67749;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.662 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.69134;  in: "drb";  variables (1): drb 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.675 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.66905;  in: "ast";  variables (1): ast 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.676 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67684;  in: "ast";  variables (1): ast 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.664 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.72294;  in: "fg";  variables (1): fg 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.675 

 `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.
217 observations of 22 variables in 2 classes; direction: both
stop criterion: improvement less than 5%.
correctness rate: 0.67706;  in: "x3p";  variables (1): x3p 

 hr.elapsed min.elapsed sec.elapsed 
      0.000       0.000       0.671 

20.96 sec elapsed
[1] "Running LogitBoost"
1.14 sec elapsed
[1] "Running logreg"
Something is wrong; all the Accuracy metric values are missing:
    Accuracy       Kappa    
 Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9    
<simpleError: Stopping>
1.046 sec elapsed
[1] "Running lvq"
1.52 sec elapsed
[1] "Running Mlda"
0.53 sec elapsed
[1] "Running RFlda"
7.511 sec elapsed
[1] "Running mlp"
6.099 sec elapsed
[1] "Running mlpML"
6.32 sec elapsed
[1] "Running mlpWeightDecay"
18.809 sec elapsed
[1] "Running mlpWeightDecayML"
18.958 sec elapsed
[1] "Running mlpKerasDecay"
<simpleError: Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.>
0.759 sec elapsed
[1] "Running mlpKerasDecayCost"
List of 20
 $ python              : chr "/usr/local/bin/python3"
 $ libpython           : chr "/usr/lib/python3.8/config-3.8-x86_64-linux-gnu/libpython3.8.so"
 $ pythonhome          : chr "//usr://usr"
 $ pythonpath          : chr "/nfs/nfs9/home/nobackup/parishar/R/library/reticulate/config:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/"| __truncated__
 $ prefix              : chr "/usr"
 $ exec_prefix         : chr "/usr"
 $ base_exec_prefix    : chr "/usr"
 $ virtualenv          : chr ""
 $ virtualenv_activate : chr ""
 $ version_string      : chr "3.8.10 (default, Mar 13 2023, 10:26:41)  [GCC 9.4.0]"
 $ version             : chr "3.8"
 $ architecture        : chr "64bit"
 $ anaconda            : logi FALSE
 $ conda               : logi FALSE
 $ numpy               :List of 2
  ..$ path   : chr "/usr/lib/python3/dist-packages/numpy"
  ..$ version:Class 'numeric_version'  hidden list of 1
  .. ..$ : int [1:3] 1 17 4
 $ required_module     : chr "tensorflow"
 $ required_module_path: NULL
 $ available           : logi TRUE
 $ python_versions     : chr [1:2] "/usr/local/bin/python3" "/usr/bin/python3"
 $ forced              : NULL
 - attr(*, "class")= chr "py_config"
<simpleError: Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.>
0.041 sec elapsed
[1] "Running mlpKerasDropout"
List of 20
 $ python              : chr "/usr/local/bin/python3"
 $ libpython           : chr "/usr/lib/python3.8/config-3.8-x86_64-linux-gnu/libpython3.8.so"
 $ pythonhome          : chr "//usr://usr"
 $ pythonpath          : chr "/nfs/nfs9/home/nobackup/parishar/R/library/reticulate/config:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/"| __truncated__
 $ prefix              : chr "/usr"
 $ exec_prefix         : chr "/usr"
 $ base_exec_prefix    : chr "/usr"
 $ virtualenv          : chr ""
 $ virtualenv_activate : chr ""
 $ version_string      : chr "3.8.10 (default, Mar 13 2023, 10:26:41)  [GCC 9.4.0]"
 $ version             : chr "3.8"
 $ architecture        : chr "64bit"
 $ anaconda            : logi FALSE
 $ conda               : logi FALSE
 $ numpy               :List of 2
  ..$ path   : chr "/usr/lib/python3/dist-packages/numpy"
  ..$ version:Class 'numeric_version'  hidden list of 1
  .. ..$ : int [1:3] 1 17 4
 $ required_module     : chr "tensorflow"
 $ required_module_path: NULL
 $ available           : logi TRUE
 $ python_versions     : chr [1:2] "/usr/local/bin/python3" "/usr/bin/python3"
 $ forced              : NULL
 - attr(*, "class")= chr "py_config"
<simpleError: Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.>
0.056 sec elapsed
[1] "Running mlpKerasDropoutCost"
List of 20
 $ python              : chr "/usr/local/bin/python3"
 $ libpython           : chr "/usr/lib/python3.8/config-3.8-x86_64-linux-gnu/libpython3.8.so"
 $ pythonhome          : chr "//usr://usr"
 $ pythonpath          : chr "/nfs/nfs9/home/nobackup/parishar/R/library/reticulate/config:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/"| __truncated__
 $ prefix              : chr "/usr"
 $ exec_prefix         : chr "/usr"
 $ base_exec_prefix    : chr "/usr"
 $ virtualenv          : chr ""
 $ virtualenv_activate : chr ""
 $ version_string      : chr "3.8.10 (default, Mar 13 2023, 10:26:41)  [GCC 9.4.0]"
 $ version             : chr "3.8"
 $ architecture        : chr "64bit"
 $ anaconda            : logi FALSE
 $ conda               : logi FALSE
 $ numpy               :List of 2
  ..$ path   : chr "/usr/lib/python3/dist-packages/numpy"
  ..$ version:Class 'numeric_version'  hidden list of 1
  .. ..$ : int [1:3] 1 17 4
 $ required_module     : chr "tensorflow"
 $ required_module_path: NULL
 $ available           : logi TRUE
 $ python_versions     : chr [1:2] "/usr/local/bin/python3" "/usr/bin/python3"
 $ forced              : NULL
 - attr(*, "class")= chr "py_config"
<simpleError: Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.>
0.037 sec elapsed
[1] "Running monmlp"
** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2288266  :
 [1]  230.2898442 -232.6622805 -334.5111091  453.3639042 -794.1112152
 [6]  -89.1441498  209.4742016 -640.4326855  109.5206300  271.3806019
[11]  804.5393674 -804.9207609  208.2743607  134.6703998  211.1395767
[16] -126.0615265   87.4349922   -7.0137869  -12.4651355   39.1931671
[21]  353.5806601  122.4045960  -95.4976471   -0.8858437   -0.1347161
[26]    0.8858452    0.1347166
0.2288266 
** 0.2288266 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.177348  :
 [1]  1.114607e+03 -1.627043e+02 -1.049765e+03  1.809366e+03 -2.353762e+03
 [6] -2.588275e+02  2.181196e+03 -2.222439e+02  2.647239e+02  5.727076e+02
[11]  3.388214e+03  1.924515e+01 -1.275488e+03  1.464453e+03  9.679730e+02
[16] -2.824007e+03 -3.411697e+01  1.008141e+02 -2.463194e+03 -1.307451e+03
[21]  2.888945e+03  5.551593e+02  3.338434e+01  1.759384e+02 -1.772951e+02
[26]  8.813743e+01 -3.233009e+02  4.682040e+02 -7.225832e+00 -4.638074e+02
[31]  1.442340e+03 -3.452283e+02  7.995210e+01 -9.792390e+01  7.094438e+02
[36] -4.044738e+02 -9.498745e+01 -6.025323e+02 -4.722476e+02 -6.822226e+02
[41]  1.355116e+02  1.639113e+02 -2.783852e+02  7.829658e+02  1.911894e+02
[46] -8.730721e+02  1.831156e+01  8.005558e+02  9.560995e+02  4.643544e+02
[51]  1.284013e+03  9.031799e+02 -2.234412e+02  8.251077e+02 -6.161804e+02
[56]  4.065781e+01 -4.007614e+02  1.177736e+03 -1.669711e+02  2.983823e+02
[61]  1.137090e+02 -1.054349e+02  1.079408e+02  5.578994e+02  6.893397e+02
[66]  4.652961e+02 -2.821611e+01 -1.410111e+02 -1.158986e+03 -9.185057e-01
[71]  9.438585e-01  2.940451e-02  8.171346e-01  9.185022e-01 -9.438355e-01
[76] -2.940533e-02 -8.171124e-01
0.177348 
** 0.177348 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.06825905  :
  [1] -15.7654360  -0.6566545   8.2193361 -23.0582678  39.1347047  -0.2583519
  [7] -42.6482594  -6.8845669  13.9399430  -8.1659465 -65.3095571 -32.6772800
 [13]  23.9823658 -20.0026938 -13.2238554  61.5716861   5.2887967 -26.3034666
 [19]  21.1069872   5.7935357 -43.4955031 -36.2256045 -25.1379528 -12.3913885
 [25]  -4.1157586  -1.7909259 -22.4441116  20.0637210  -7.5469575 -14.4849212
 [31]  18.2530585  -9.0577448   3.0439104 -49.1598778  14.9640346  -1.4897221
 [37]  -6.8972962  -9.8351115   9.6196515  -8.6427736  -1.5311056  32.7258504
 [43]  14.6825368 -33.3178156 -25.9760946  10.7571979   7.5241769   3.9780681
 [49]  -4.9480306  22.5253381   1.1840226 -21.5563732  13.7402791  -7.5034958
 [55]   7.0836388  -8.3139376  15.0836241 -10.3478651  30.6760969  10.2092902
 [61]  17.9767139   1.9055240  22.5051130  26.9824658  -4.2726033   1.9589475
 [67]  19.2914873  21.7637092 -17.1072697 -12.0582120  -9.6887298 -11.1381008
 [73]  -8.3990403 -16.9997915 -22.0157658  -3.1032918 -28.8064385 -22.8186295
 [79]   1.9544088 -10.0083471 -28.1613144  10.4669393 -19.1021374  -9.1473544
 [85]   6.5384939   1.4766388 -16.5513744   7.5241411 -27.0337925  -8.5575026
 [91]   0.7061195  41.4035903   7.0820935 -29.2856138 -23.0093090  16.0030968
 [97] -35.9440479 -11.9361168  29.4063497 -33.9891964  14.7229486  20.2676373
[103]  40.4750375 -49.0144665   7.0860971  -4.3096593   4.4896716  -2.4673914
[109] -13.3515951 -12.6912302  44.3542735  17.2230188   4.7709262   3.3929540
[115]  38.4757630   0.2688709   0.9184642  -0.6544285  -0.8318856  -1.0329077
[121]   0.8399697  -0.2688709  -0.9184642   0.6544284   0.8318856   1.0329076
[127]  -0.8399696
0.06825905 
** 0.06825905 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2847802  :
 [1] -259.6155793  265.5324766  -14.8864402 -267.3502596  414.3069021
 [6]  125.5223168   88.2973414  413.5606346  131.8236868 -151.2853170
[11] -343.8110962  323.6569228  -86.1799310 -274.9397852 -245.0437767
[16]  -38.8525146 -170.9095482  -63.8576243   95.3829128  153.8487919
[21] -172.8885860  -68.4376352  -50.9392786    0.8517225    0.1216791
[26]   -0.8517209   -0.1216773
0.2847802 
** 0.2847802 

** Ensemble 1 
0.1879654 
** 0.1879654 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.03228503  :
  [1] -1.222882e+03  1.455697e+02 -5.835811e+02 -1.058322e+03  9.858517e+02
  [6]  8.329881e+02  2.109532e+02  1.336343e+03  6.714285e+02 -3.802979e+02
 [11] -1.528794e+03  1.005697e+03 -4.514520e+02 -8.128304e+02 -8.396154e+02
 [16] -3.276885e+02 -3.154706e+02 -6.197736e+02  4.287031e+02  1.517155e+03
 [21] -2.894989e+02 -1.158699e+03 -7.748175e+02  9.394552e+01  4.330860e+00
 [26] -2.943643e+01 -4.067084e+01  1.254069e+02  4.930060e+00  1.965431e+02
 [31]  1.213285e+02 -4.776988e+01  1.578683e+01 -1.722257e+02  1.896990e+01
 [36]  1.177421e+02 -5.641259e+00 -1.400757e+00 -6.725532e+01 -6.679200e+01
 [41] -3.483357e+01 -6.141187e+01  7.036779e+01 -3.414192e+01  2.814609e+01
 [46]  9.261503e+00  8.223865e+00  9.531383e+02  1.882382e+02 -4.022278e+02
 [51]  4.328605e+02  4.482909e+02  2.197265e+02  9.370528e+02  3.094724e+00
 [56] -4.903856e+02 -8.117856e+02  6.648989e+02  4.130536e+02 -9.048382e+01
 [61]  4.152660e+01 -2.739504e+02 -2.840308e+02 -3.301423e+02 -3.720501e+02
 [66] -1.813217e+02  1.732808e+02  4.409607e+01  1.775826e+02 -6.317258e+02
 [71] -2.839359e+02  2.492692e+02  2.593416e+02  4.712148e+02 -2.619772e+02
 [76]  1.933314e+02  3.144078e+02 -2.423420e+02  3.320752e+02 -2.711829e+02
 [81]  2.812835e+02 -6.357068e+01  7.205968e+02  4.404167e+02 -1.997932e+02
 [86]  2.003724e+02  6.285386e+02 -7.249653e+02 -2.019104e+02  3.106713e+02
 [91]  1.053921e+03 -2.807408e+02  6.253101e+01  9.380936e+02  2.073754e+02
 [96] -3.476306e+02  4.197575e+02  3.294381e+01 -4.538791e+01  6.831541e+02
[101] -2.051318e+02 -2.223313e+02 -9.742700e+02  6.207432e+02  1.203461e+02
[106] -6.918319e+02 -4.055788e+02  3.053534e+01  2.394401e+01 -5.711746e+02
[111]  4.621741e+02 -2.828550e+02 -4.505634e+02 -2.687412e+02  3.714858e+02
[116]  9.816382e-01 -2.123303e-01  1.993742e-01  1.009814e+00  9.933905e-01
[121]  5.513403e-02 -9.816393e-01  2.123370e-01 -1.993810e-01 -1.009820e+00
[126] -9.933971e-01 -5.513290e-02
0.03228503 
** 0.03228503 

** Ensemble 1 
0.3334621 
** 0.3334621 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2858158  :
 [1]  45.0509547 -48.2488846  33.3965015  99.6551732 -51.9500407  22.4728394
 [7]  15.7130186 -72.5612555  -0.7270612   8.0128617  80.4913054  32.5721783
[13] -58.8056123  91.1577099  52.8575850 -15.4980644  53.5187583  27.4909374
[19] -59.3295449 -80.4681754  81.7407790  89.7796363  69.8970921 -25.8858829
[25] -96.7163388 -38.4664195  20.9763743 -85.6797700 -48.0383691 -27.8426266
[31] -89.3750440 -49.9822209  35.4157932  -9.5524972 -89.8544403  -5.8690334
[37]  50.4615047  36.9714916  39.8502919  62.1429713 -55.5607984 -57.2686296
[43] -23.2300126 -13.1996371 -51.4142097  26.5814867  36.4179937  -9.4870572
[49]  39.5394098  49.6132840 -55.9698173 -92.4029043  36.2627640 -11.0305314
[55]  -6.9799514  14.6467774  34.9891484 -11.6044054  38.6210394  80.2892446
[61]  74.1912835  18.3817038  58.7378283  33.5545894 -33.5415176   1.3641980
[67]  56.3662881 -28.4480635  46.7914649  -0.8436172  -0.7227662  -0.6096431
[73]   0.1812131   0.8436180   0.7227689   0.6096450  -0.1812113
0.2858158 
** 0.2858158 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1122151  :
  [1] -148.52776593 -431.39183932   41.36679071  -22.53440137 -605.00606552
  [6] -398.49049052 -219.04216569 -487.28433569  112.33368784  199.99387113
 [11]   15.02049845 -527.55084626 -214.08656177  141.87849088   65.86015720
 [16]  156.65122108   98.75721357 -436.03646056  -58.72580732  -65.30617305
 [21] -130.19879394   17.47383059  301.24879771  362.43659809 -235.92668577
 [26]  118.03714499  746.53095415 -692.29715986   98.80148078    4.87543609
 [31] -666.16386750  214.30841340 -106.89776674  681.12540988  158.40905382
 [36] -183.04088231  710.24240218  516.92465678 -104.95909184  552.45809095
 [41]  -92.41509767 -445.25751159 -965.59726154  703.98889929  463.54889819
 [46]  362.69033309 -133.58408976   72.74013194  -94.56764606 -164.59139351
 [51]  113.41806437  135.32183726 -139.37849998   23.09132905  132.31275390
 [56] -167.95847299 -164.61009013   30.24426348  -26.88442329 -249.96242467
 [61] -195.17368689  -46.14275123 -335.58352015  -49.08420356  199.01919116
 [66]   42.67375323 -184.57790524   97.62922816 -114.18805176  -34.02190850
 [71]  -13.98254482   15.20671783 -100.45198578  323.96493012 -105.48095195
 [76]  119.27827295  248.23109694  137.73158105  -87.46370671 -128.90713442
 [81]  525.33902840 -411.12347308 -156.08768787 -280.13849876 -435.31899661
 [86]  340.77388944 -338.64619637   45.64722840 -487.69317849  259.88285258
 [91]  212.08330853  114.55407145  172.07837299  369.67958468   84.23771196
 [96]  -23.52957909  378.33944668  210.20601568  216.01466343  391.97705188
[101]  -52.64812013  -81.02013726   48.45379082  347.89547625   44.08617764
[106]  -84.93603786  -60.69394085   32.92867841 -108.25686747  184.93066744
[111]  111.49333096   16.39780632  128.25581842  203.96288185 -110.07581750
[116]   -0.86277452   -0.92369744    0.02885961    0.80409971   -0.03994262
[121]    0.04795517    0.86276364    0.92369949   -0.02886701   -0.80409527
[126]    0.03993388   -0.04795292
0.1122151 
** 0.1122151 

** Ensemble 1 
0.2797282 
** 0.2797282 

** Ensemble 1 
0.2127287 
** 0.2127287 

** Ensemble 1 
0.03214677 
** 0.03214677 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.4399883  :
 [1]  126.18045368 -256.76431356   43.97353258  313.51423993 -120.44692890
 [6]  -72.31946758  109.65180511 -294.26645756 -176.16299946    0.91421838
[11]  102.04895341   14.21507019  -58.94245486   88.10321574   49.96409802
[16]  110.62940127  222.08695245   52.83618844  -93.22659796 -207.58657679
[21]  159.58048168  107.15916857  -43.38109909   -0.75109133   -0.09345194
[26]    0.75108774    0.09345478
0.4399883 
** 0.4399883 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.07300523  :
 [1]  -33.4176510  188.3850200  -35.2492846 -302.3775403  -91.8485970
 [6]  182.5252991  -76.2893767   -0.5131944 -105.6929828   46.9206857
[11]  211.1243608   26.1771845    2.0097613 -166.7282261  -85.8422948
[16] -202.5812376   15.1843456  -38.6136015  -30.0259408  328.8005667
[21] -175.2397083 -339.7789873  418.9565437 -379.9404874  396.2871383
[26]  -52.5473163 -481.7179663   50.8399334  -85.3149761 -184.1505433
[31]  802.0102075  -25.4000648  304.8823685 -442.9182280 -236.6400996
[36]  133.9709439  -46.4411363  -29.3606801 -129.7690060 -321.6734548
[41] -291.4684189   38.1875725  365.2512239 -260.0664587 -465.5120001
[46]  175.8082779  273.0487435 -178.0807714   93.4038950  360.0921668
[51] -326.2078722 -525.8459549  213.4966371 -565.4578694  -34.9329540
[56]  259.9062555   32.5055146 -524.7709353  319.3470067  254.4597135
[61]  353.7918565  221.7621923  -59.9804281 -153.3347321    6.6740183
[66] -108.5250816   40.1796256  320.5506460 -408.2574821   -0.9846164
[71]    0.9653857   -0.9894289   -0.1494911    0.9846262   -0.9653889
[76]    0.9894395    0.1494944
0.07300523 
** 0.07300523 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.03669268  :
  [1]   64.9663346   10.6241013  -27.1768606   24.4655269  -11.9232140
  [6]  -55.4971525   75.9936709  -39.0184826  -75.6431591    1.4489042
 [11]    2.8842635   -2.9221290   17.9911365  -22.5832946  -11.8882417
 [16]  122.4918728   80.7519744  183.4520445  -42.2572029  -34.6946217
 [21]   45.5170594   17.0023017  -59.9337767   69.5214141 -174.1788489
 [26]   55.6777056  127.0962296   -2.3012450   72.1450676   48.0332724
 [31] -308.3157878  -29.4435974  -90.4772630  206.5168601   90.6580091
 [36]  -87.0010470   83.0464921   43.2352132  -31.4173773  125.4118087
 [41]  156.1097396  -13.0582021 -109.5155580   78.1464698  145.2135948
 [46]    0.2423417   -5.7505706  -38.4626022   -6.8159202   74.0463608
 [51]   14.9356859  -86.7844677    9.7177315 -134.5653738   44.7984422
 [56]   27.0690300   10.0318395 -113.1218612  110.6432188   -9.0925792
 [61]   33.3489960  -14.7995577  -62.0335556  -70.7422604  -70.4637722
 [66]   21.9753682  -12.5487113  -48.9140131   59.6513673  -22.0116261
 [71]    8.1178903  -48.6304133   80.9595382   47.6714291  119.2760526
 [76]  -64.8214726   99.0838336  -64.2714497   26.1878441   34.6921755
 [81]   43.6198798   43.8733437  -94.7479100  -63.2287404   34.9818061
 [86]  125.1050078   95.6207643   -7.6970436  188.6710803   -3.8240966
 [91]  156.6669627  -29.4867167  -56.6522884  -76.3335088   -1.0992791
 [96]   -0.9147694 -176.5151735   34.6062009   77.2055223  -54.2360952
[101] -165.2139973  111.5337565   93.9324100   -7.3013537   13.5906705
[106]   15.3195568   23.8886508   98.2357628   82.5206808  -20.3378978
[111]   93.1234531  166.0810739    0.4838124  133.9544612  -85.8910719
[116]   -0.9983349   -0.9898243   -1.0041955    1.0033437   -0.9899140
[121]   -0.1307410    0.9983606    0.9898325    1.0042177   -1.0033670
[126]    0.9899294    0.1307434
0.03669268 
** 0.03669268 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3301852  :
 [1]  -23.4809504  223.4886713   88.4991629 -260.9452781  327.9286768
 [6]   18.2145569 -164.1339550  243.6680458   -7.6134969  -40.7154542
[11] -148.4052849  112.6187058  -23.1817289  -94.2483740  -93.7654316
[16]  -71.4092340 -119.4610773  -15.8043304   69.5766878   -5.6563749
[21] -104.2994732  -61.2788359   41.9256548    0.8253978   -0.1256155
[26]   -0.8253938    0.1256156
0.3301852 
** 0.3301852 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.08949096  :
 [1]  -61.05391695  189.51609877   71.47709179  241.59957858   63.35823895
 [6]  105.44201242    5.17043828  232.01396859   41.75509181 -225.01729917
[11]  235.01174852  197.81095019 -225.72046032  191.88776069   53.21157365
[16] -646.59537225  130.66734487  348.15992923  430.26991974  614.75617451
[21]  542.40836186  319.48095069 -392.17104236 -216.95426743 -769.45530083
[26] -360.40670645  859.54312309 -593.05308891 -180.73877075  725.36516321
[31] -234.06198475  138.95633110   -9.07625999  321.75959446 -403.73824415
[36]   90.14834677  556.44069026  467.87369073 -594.96905528  108.30346330
[41]   54.15208636  142.29254895  792.95997640  133.52496242  -82.67005808
[46] -378.23720761 -237.70027188  647.84917429   -4.12758406 -818.38309217
[51]  320.18555454 -245.14623841 -567.94692346  975.65937482  222.39971551
[56]  -42.60511099 -688.36786827 -285.45133520  344.91801343 -288.59059281
[61] -181.80385544    8.87517330 -681.79866401 -251.46615211  188.49879363
[66]  650.67245485 -502.36137251 -429.19243073 -215.31765722    0.96740811
[71]   -0.97946021    0.94321475   -0.07070564   -0.96740828    0.97946025
[76]   -0.94321489    0.07070563
0.08949096 
** 0.08949096 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.05279081  :
  [1] -3.988454e+01  1.146597e+03  3.422339e+02 -1.347012e+03  1.593822e+03
  [6] -4.729599e+02 -1.808861e+03  1.993982e+03 -5.400201e+02  7.063414e+02
 [11] -6.506919e+02  8.476455e+01  1.393848e+02 -7.657698e+02 -8.001152e+02
 [16]  8.303097e+00 -6.025919e+02  3.041342e+02  6.924873e+02 -1.580013e+02
 [21] -5.260287e+02 -3.179866e+02  2.558556e+02 -4.156875e+02 -4.605818e+02
 [26]  1.669277e+01  1.111357e+02 -1.639042e+02 -7.361199e+01 -5.479684e+01
 [31] -3.565676e+01 -2.779606e+02 -2.015284e+02  1.101648e+02  7.645958e+02
 [36] -5.807662e+02  1.727463e+02 -8.245642e+01 -6.567198e+02 -5.520182e+02
 [41] -2.658962e+02  5.445468e+02 -8.735217e+02  1.519862e+02 -7.504968e+01
 [46] -3.734664e+02  4.937361e+01 -1.053646e+02 -2.922522e+02  5.377048e+02
 [51] -1.486935e+02  6.985245e+01  8.123602e+02  3.112187e+01  7.936710e+01
 [56] -1.216095e+02 -2.090073e+02 -2.464827e+02  2.690289e+02  1.347774e+02
 [61]  2.266779e+02 -1.288109e+02 -5.518921e+01  3.412313e+01  1.739934e+02
 [66]  6.586141e+02  8.191462e+02  4.683489e+01  1.929800e+02  4.784652e+02
 [71]  1.128077e+03  8.796678e+02 -1.093631e+03  1.494277e+02  6.495305e+02
 [76]  4.263844e+02  1.726913e+03 -9.723308e+01 -2.053769e+02  1.304234e+03
 [81]  1.947407e+03 -9.275476e+02  3.707907e+02 -6.331266e+01 -7.024737e+02
 [86] -4.456585e+00  1.035973e+03  4.974016e+02  1.458018e+02  8.557863e+02
 [91]  9.386006e+02 -1.359697e+03 -6.869800e+02  9.861847e+01  2.465756e+02
 [96] -1.334704e+03  1.635220e+02  8.497197e+02 -6.313382e+02  3.054956e+02
[101]  1.007744e+02 -8.296231e+01 -3.062204e+02 -2.337244e+02 -1.041680e+03
[106] -5.667883e+02 -8.000237e+02  5.300469e+02 -6.759298e+01 -1.392106e+03
[111] -3.492065e+02 -1.477538e+02  2.481828e+02  7.436994e+02 -7.227096e+02
[116]  9.917361e-01  6.163753e-01  1.612046e+00  5.683335e-03  9.929271e-01
[121] -6.045889e-02 -9.917343e-01 -6.163753e-01 -1.612036e+00 -5.683676e-03
[126] -9.929197e-01  6.045862e-02
0.05279081 
** 0.05279081 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3324381  :
 [1]  128.47078372 -114.17456638   47.95764125  178.22857267 -126.24973040
 [6] -179.49069217   21.78513550 -144.88077952  -34.72993909  141.44029973
[11]  271.13975971   65.48190275  -13.13422318  150.21013155  106.58464787
[16]  126.23409203  288.35138811   34.11129240 -249.79473739 -336.95241799
[21]  145.92646303  244.48993749   32.41801446   -0.81438556   -0.01123238
[26]    0.81439575    0.01124222
0.3324381 
** 0.3324381 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2246594  :
 [1]   26.99610677 -216.94727893 -197.19969390   16.08747139 -277.76823230
 [6]  138.73729877 -136.22234885 -361.99978973  135.66295425  258.84669252
[11]  335.42970449 -195.28012037  -63.41915683  390.34276847  276.48844679
[16]  -96.45335384  311.54910560   87.72340076 -245.76372052 -223.33080143
[21]   31.83076325 -238.54481686  260.21181493 -341.47592839  181.94688664
[26]   43.19001222 -426.77116306  542.11806473  318.47339446  111.22876503
[31]  571.99874493  -53.30176012 -395.07325041 -732.37820466  240.64824090
[36]  -76.90600147 -592.58985543 -480.88801306  -15.34333445 -668.85018277
[41]  130.56408039  399.27656847  660.31239272 -337.17556399 -483.55998780
[46] -110.90429423  -22.49704624 -100.96548027 -325.46475558   24.73932385
[51] -181.27597390   51.71672048 -102.58624018 -201.47038710  -84.36136996
[56]    3.09599894   59.37513457 -218.94464855   44.80991052  230.37978472
[61]  189.73502924   28.66659297  273.22789894  -71.94912344   83.91018106
[66]   10.54744414  -14.13161170 -178.57929867  -89.31757989   -0.27799112
[71]    0.81965987   -0.19391914    0.09626524    0.27799078   -0.81966068
[76]    0.19391862   -0.09626498
0.2246594 
** 0.2246594 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.06529705  :
  [1]  236.42496260  126.75079583   84.44934815  180.06020936    1.76641856
  [6] -350.90644469  103.01184398  -25.30929800   60.68204582  355.76090385
 [11]   93.83323231    2.96335155  255.31937765  187.80081700  230.50438415
 [16]   58.31643075  197.26937884  -52.02650261  107.63526940   70.38014354
 [21]  108.81500543   30.41970890  138.73006808  -82.26509912   81.93319748
 [26]  152.70419736  -75.91108653  182.40285341 -199.58321576   91.16456845
 [31]  259.56875899   40.00513382 -135.97882956 -238.48122265  133.29388422
 [36]  -12.65163811 -266.42787968 -214.37337684 -107.04742910 -141.13907917
 [41]  -50.56411477    3.55821462  -21.15456992  -42.44537542   52.47474142
 [46]  162.01822612 -254.80765424  127.51797348   44.15672738 -226.25230229
 [51]  420.56794806   98.91403795   99.29411358  600.91998341  -84.86659949
 [56]  -70.17532333 -680.46857058  384.97558573  -67.58067795 -429.08464420
 [61] -366.53975053  -96.64544557 -281.52507460   71.45187037  266.10555823
 [66]  422.81665977 -275.42466739 -189.85100829   64.77097873  -43.29454311
 [71]   88.61538287  130.70393025    5.10985614  113.67497529 -101.98011295
 [76]   49.65345724  176.19755112  -18.28862993   15.02554760 -180.02814510
 [81]  134.43664988   20.11850522   73.78221999   38.07225720  -44.71549889
 [86]   63.56948042   26.47903513   -3.38068528 -397.98315387   71.33724578
 [91]  159.62655719 -348.70331423   87.11152222  163.13292540  207.23078455
 [96]  158.30578232  305.37193444  103.80480452  209.28399368  263.68195164
[101]  113.30883799 -124.66114941   87.69391080  309.44709081  -60.11788395
[106]   43.93112733    5.17804341  239.61292567  218.30071366  -73.91168198
[111]  198.78305629  104.35202139  226.54163417  224.89670640  127.93982525
[116]   -0.95090000    0.08012842    0.97314211    0.82946417    0.98147743
[121]    0.62895506    0.95089970   -0.08012747   -0.97314345   -0.82947229
[126]   -0.98147660   -0.62896312
0.06529705 
** 0.06529705 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2773145  :
 [1]    8.9023410  405.2038330   74.0119616 -120.8888719  235.8424820
 [6]  102.5249619 -210.0592439  357.4424354   44.5812122 -137.9853259
[11]  -92.2026921   96.3630261  -17.1114274 -283.5051626 -228.4062471
[16] -121.2851734 -197.9174830   66.9832467  316.0948248 -161.9703981
[21] -193.4450975 -110.9871328   71.4031218    0.8540319   -0.1062632
[26]   -0.8540326    0.1062633
0.2773145 
** 0.2773145 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.03595274  :
 [1]  -69.07817725 -406.52086842  139.12711924  -66.88304748  -74.93373007
 [6] -102.92162950  341.55632305 -253.51690996 -300.62547050  431.30469609
[11]  -68.30686436  135.47095606  -51.82217078  326.02207574  228.68680121
[16]  554.95690335   42.19782475 -241.19346144 -121.73147540  515.49643730
[21]  -94.69645287  -73.68090218  -78.35177007 -161.85242921  755.24737810
[26]  323.32863494 -348.57333010  592.80228447   47.15071064 -357.93398171
[31] 1006.01247086 -101.39641959 -265.70945656 -487.44242297  547.96115598
[36]   -6.35141473 -573.54789218 -522.41366510 -102.23421412 -567.70978322
[41]   83.30224938  702.17778992 -270.56682026 -517.88357423 -225.26187566
[46]   97.64613922   -2.39755295   63.96175117 -302.81516579 -142.39543290
[51]   49.20076431 -364.08329014 -154.66769468 -247.09854906   63.02292285
[56] -348.87706221 -379.60595428 -440.68549086  273.82290500 -215.04579613
[61]  -66.91068360 -162.64173284 -444.07739147  470.75061834  -73.00109300
[66] -493.68548842 -227.84232771 -245.38062216  226.53857411   -0.98944980
[71]    0.97524995   -0.98092627   -0.02262695    0.98945159   -0.97525160
[76]    0.98092936    0.02262683
0.03595274 
** 0.03595274 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 2.281615e-16  :
  [1] -4.785804e+01 -1.599119e+02 -2.577602e+02  6.148963e+01  5.356311e+00
  [6] -8.327155e+02 -6.936557e+01 -3.446420e+02  9.059629e+01 -2.362770e+02
 [11] -1.378118e+02 -1.368208e+02  2.633791e+02  4.002667e+01  9.257386e+01
 [16]  1.240259e+02 -1.480597e+00  3.843652e+02 -8.021403e+02 -7.700611e+02
 [21] -1.465927e+02  7.064298e+01  3.811496e+02  2.943601e+01  1.875330e+02
 [26] -7.608899e+01  7.513620e+01  1.969541e+02  5.031444e+01 -1.562645e+02
 [31] -3.571456e+01  2.893278e+01 -1.630993e+02 -1.361853e+01 -6.461952e+01
 [36] -3.655340e+01 -1.879691e+02 -1.399966e+02  1.082487e+01 -8.679450e+01
 [41]  9.644634e+00  1.504874e+02 -8.776459e+01 -3.914536e+01  7.002323e+01
 [46]  4.072720e+01  3.166249e+02 -4.090248e+02 -2.674052e+02  3.896314e+02
 [51] -5.477125e+02  2.711301e+01  2.801656e+02 -6.934004e+02  1.913156e+02
 [56]  9.167075e+01  4.437050e+02 -4.823593e+02 -2.722345e+01  2.701693e+02
 [61]  2.907827e+02 -2.396510e+02  3.742573e+02 -1.638073e+01 -5.105490e+02
 [66]  2.500094e+02  5.395942e+02  1.767406e+02 -3.039178e+01 -1.293609e+02
 [71] -2.623082e+02  3.781244e+02 -2.228364e+02 -6.648523e+01  1.853344e+02
 [76]  1.716674e+02 -6.622247e+01 -2.934096e+02  1.754901e+02  8.116376e-01
 [81]  1.194945e+02  6.128677e+01  1.047681e+02  1.059879e+02  3.570516e+02
 [86] -5.493005e+01 -6.177807e+01  3.513066e+02  5.687993e+02 -3.663025e+02
 [91] -7.113382e+00 -1.715616e+02 -5.756438e+01 -2.823220e+02  1.536716e+02
 [96] -6.196423e+01 -9.616617e+01 -1.812726e+02  4.257973e+01 -1.949086e+02
[101]  4.095096e+02  2.254987e+02 -6.539315e+01 -9.585631e+01  2.893444e+01
[106] -3.560695e+01 -1.526133e+01 -1.406287e+02  9.995591e+01 -4.831045e+01
[111] -1.130346e+02 -1.398785e+02 -1.126761e+02  6.608221e+01 -1.073625e+02
[116] -9.977038e-01 -3.242603e-09 -9.977038e-01 -9.977038e-01 -8.404318e-10
[121] -4.597713e-03  9.977038e-01  2.516680e-09  9.977038e-01  9.977038e-01
[126] -2.973654e-09  4.597711e-03
2.281615e-16 
** 2.281615e-16 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3241229  :
 [1]   18.19111921  -77.67647789 -106.50667754   75.57855067 -225.98384634
 [6]  -92.62545785  -30.05200302 -199.96425682   21.23004621  166.14715075
[11]  158.37795701  -98.45519258    3.59939842  208.42661244  169.91403428
[16]  121.17583508  115.16879138  -14.01567380  -93.77621850 -120.87341227
[21]  123.02542065  111.48841190   18.04660820   -0.82127451    0.05677021
[26]    0.82127451   -0.05677021
0.3241229 
** 0.3241229 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1154728  :
 [1] -4.969376e+02 -1.495570e+03 -1.463190e+03  9.405539e+02 -1.692306e+03
 [6]  7.541002e+02 -5.391505e+02 -2.686201e+03  9.245348e+02  1.473139e+03
[11]  1.607537e+03 -2.053579e+03 -5.803509e+01  2.229450e+02  4.043580e+02
[16]  7.953743e+02  1.696295e+03 -2.761145e+02  2.303329e+02  2.490480e+03
[21]  1.036783e+02 -2.086738e+03  3.002289e+03  3.341321e+02  7.183618e+02
[26]  9.661136e+02  5.538184e+02  1.279055e+03  6.721030e+02  1.019777e+02
[31]  5.266543e+02  6.094132e+02  3.894547e+02  4.990453e+02  9.124844e+02
[36]  1.242631e+02 -1.664887e+00  4.665885e+00  1.792272e+02 -3.968238e+02
[41]  4.050374e+02  4.129335e+02  1.470308e+02  2.998470e+02 -1.564504e+02
[46] -4.702720e+02  7.844670e+02  6.031826e+02 -1.081627e+03  1.280500e+03
[51] -2.481126e+03 -2.046096e+03 -1.254645e+02 -2.315513e+03 -7.733596e+02
[56]  2.217260e+03  2.632036e+03 -3.548307e+02  1.611604e+02  2.474910e+03
[61]  2.226693e+03  1.669693e+03  1.934848e+02  7.151145e+02 -1.634884e+03
[66] -3.247189e+03  1.485522e+03  3.575176e+03  9.685316e+02 -8.673395e-01
[71]  4.663674e-02 -9.620712e-01  8.218826e-01  8.673498e-01 -4.663743e-02
[76]  9.620797e-01 -8.218965e-01
0.1154728 
** 0.1154728 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.07305172  :
  [1]   20.26261756   20.92931101  -12.71405271   26.25363280  -16.74268691
  [6]   -4.04994034   15.33939997  -19.41099425   19.21832313   12.40304136
 [11]   11.99862674  -27.73453660   -2.94450199   -4.67537027    0.86937265
 [16]   13.90436350   39.31934521  -16.82616901  -34.81993860   33.12233356
 [21]   31.21589917   26.48451475   20.58872584   68.88677772  -57.86467325
 [26]   19.08263550  103.16811466  -23.40666610  -20.48151193   32.71790198
 [31]  -63.04581238  -13.57585757  116.97438602   45.03231857  -72.27216113
 [36]   -6.28214887  128.97048782   95.49476128   83.54287729   79.59617336
 [41]   -8.03186549 -142.51260688  -66.95774908  100.40769536  124.70799363
 [46]   25.26407784  -29.09832852 -227.63242893  -88.41228308  111.40261911
 [51] -284.20447093  -22.13786316  -85.16840459 -269.48464997  -38.02132706
 [56]  265.08358754  201.12374744 -240.64104497   90.60520646  124.06245929
 [61]  136.09627886  -91.67112604  145.07854493  -70.74314886  -41.47058317
 [66]  293.31790189  -19.49061075 -139.76994121  414.80894096  -38.76271641
 [71]   39.94940623  -62.11116789 -175.12683841 -111.71572676   71.76557042
 [76]   15.46015477  101.67140459  -64.76737906 -145.61115083   52.30775927
 [81]   40.15501359   30.20333419 -101.94138998  -66.98369998  -70.05098499
 [86]  -65.67150557  -33.30439322  100.13748960  190.52959973  -91.41331565
 [91]  -28.18848372  -24.35578906   63.20602647   33.73532570  -99.03539449
 [96]  194.92119613 -286.48601360 -164.89967844   39.92156373 -224.64147669
[101]    2.83033218  230.94142060  222.04745204   12.32278769 -111.74713303
[106]  346.03040518  251.02317734  150.02272956  101.78120384   89.52652747
[111] -228.93911307 -387.59057558  268.41553545  325.77210984   87.68580360
[116]   -0.23891287    0.18616430   -0.96691456    0.02099992   -0.91094959
[121]    0.95324298    0.23891263   -0.18616286    0.96691465   -0.02099971
[126]    0.91094925   -0.95324363
0.07305172 
** 0.07305172 

** Ensemble 1 
0.3707033 
** 0.3707033 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.120395  :
 [1] -167.52009378  377.62561102  133.68671116 -216.31827000  215.04068646
 [6]   83.19660492   22.32310811  344.66322125  108.67824493 -288.72823094
[11] -207.15286903   47.29651341 -128.21327904   66.02109712    8.71143049
[16]   18.32127833   50.83306848  199.66480109  312.33958039  257.56904686
[21]  141.19670645  215.73235223    0.27750378 -386.01454317  370.70474504
[26]  293.76252627 -301.87461168   38.45767289  378.21644889 -221.02065402
[31]  647.00682177   22.90251443 -147.05171589 -633.24869573 -497.71682742
[36]  385.16665057 -395.82225930 -233.38425535   16.80144578  -79.26785654
[41]  109.28668798  285.38604648   51.65675257 -171.29115009 -270.99165751
[46] -255.02549005 -329.68966896  327.31186740   45.60111546 -103.09646191
[51]  220.90887272   50.15842288 -369.54421250  173.84165601  -80.19104272
[56] -175.77318402  139.87411283  238.24193343 -166.93101388 -131.31286310
[61] -162.96974270    2.35883732 -194.96994516 -204.84431451 -204.18983735
[66] -117.26762528    8.91083077  -58.00679629  120.24981546    0.92639889
[71]    0.91625143    0.97407967    0.03694152   -0.92639893   -0.91625143
[76]   -0.97407967   -0.03694153
0.120395 
** 0.120395 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.01191261  :
  [1]   26.47617973   43.65896162   44.21316228 -109.43870609   40.41959899
  [6]  -13.20647119   11.62593478    1.92469466  -74.65469598  -19.45844455
 [11] -164.23489947 -139.20702948  262.91933004  -51.76075248   43.42281453
 [16] -126.37640428  106.38339463  270.77656491  316.83965497  151.03510917
 [21] -190.04880576  -76.94987564   28.34747460 -282.41973410  326.11949550
 [26]  288.09065666 -227.45171114  164.24879881   -9.91590395  -58.33192688
 [31]  251.52980715 -287.27473501  -56.54252486 -300.39398322  253.71449048
 [36]  241.55076331  -38.98062854    7.22174164  -93.32198528  -85.72601866
 [41]    0.44951067  248.92715288 -139.18117992   91.44545041  124.87908613
 [46]   26.54370477 -126.78721227  180.45711207  -36.42165890 -105.91665553
 [51]   95.74339559   26.59024267 -108.69884297  377.45407206   -3.15000064
 [56] -232.87415544 -195.58841614 -147.73842236  -82.06931399 -340.17223925
 [61] -287.65537483  133.41867829  -82.49031555  -89.10186925  260.79912854
 [66]  202.29856557 -171.66698395 -220.29026627 -112.37751601 -213.37892818
 [71]  176.72271687 -131.22837491 -162.17080244  144.13640806  249.58193046
 [76]  -99.23256317  321.13637013  243.71107194 -104.34825410 -127.69530023
 [81] -175.18136813  -34.70837539 -294.71343637 -228.56942138  -84.14281476
 [86]   -4.71364333  243.55560797   83.55414442  362.50904576  -59.64689791
 [91] -231.75475342  -47.72186248   58.27955756  -77.57667113  -96.10815246
 [96]   48.57073939 -123.53515590  118.38593068   45.69480208  -78.60189064
[101]   42.15646981 -152.14561659   21.88388133 -188.79765580  -56.77794452
[106]  -43.69071955  -40.33210470  -67.43052763   20.81829764 -161.82823675
[111]   86.46104899  285.73862720  -31.68006194 -197.15932614   11.38884713
[116]   -0.98518006    0.98456213    0.66755043    0.97523475   -0.65699088
[121]    0.01190937    0.98517908   -0.98456132   -0.66755318   -0.97523436
[126]    0.65699347   -0.01190970
0.01191261 
** 0.01191261 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2548501  :
 [1]   647.1815181 -1972.4807042 -1398.5647115  1768.8897355 -3091.6051384
 [6]  -643.9362579   302.0416812 -2648.9991497   -51.4450469  1754.9676204
[11]  1638.0607338 -1346.4304412  1111.8774822  1024.4415504  1163.5117549
[16]  1067.1688516  1143.8492102   -69.0578715  -902.9068155  -231.0155421
[21]  1268.8379828   667.2746572  -124.5754862    -0.8672869    -0.1079112
[26]     0.8672869     0.1079112
0.2548501 
** 0.2548501 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2407953  :
 [1]  4.253326e+02 -5.474339e+02 -6.543294e+02  8.479032e+02 -1.390994e+03
 [6]  7.150805e+02  4.657772e+02 -7.373253e+02 -5.804332e+02  2.750441e+02
[11]  2.400996e+02 -7.494445e+02  1.514401e+02  4.612606e+02  4.261482e+02
[16]  8.162011e+02  7.133126e+02  1.358424e+02 -3.158563e+02  2.614315e+02
[21]  5.281961e+02 -4.228819e+02  1.154029e+02  9.203221e+02  4.007568e+03
[26]  2.227131e+03 -1.709998e+02  9.226876e+03 -3.729283e+02 -2.249846e+01
[31]  4.472884e+03 -1.348619e+03 -1.384267e+03 -4.990537e+02  3.004108e+03
[36] -1.782941e+03 -1.100942e+03 -1.435553e+03  2.767243e+03  1.752547e+03
[41]  1.003187e+03  1.867183e+03  1.105210e+03  2.965495e+02  5.245981e+03
[46] -1.103812e+03 -3.921809e+03  4.864175e+03  4.881441e+03 -9.992148e+03
[51]  1.514285e+04  3.240937e+03 -1.027945e+03  1.183083e+04 -6.230020e+01
[56] -6.193273e+03 -6.490927e+03  6.613641e+03 -3.955004e+03 -3.423375e+03
[61] -4.325156e+03 -3.090829e+03 -3.101629e+03  1.739780e+02  1.168320e+03
[66]  1.664335e+03 -5.445762e+03 -1.795479e+03  3.496233e+02 -1.954880e-02
[71]  1.502831e-02  8.717591e-01 -6.324443e-02  1.954882e-02 -1.502798e-02
[76] -8.717592e-01  6.324463e-02
0.2407953 
** 0.2407953 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.0181721  :
  [1]  -82.65958987 -429.53018754 -167.27428784  129.80393874 -243.20103464
  [6] -228.30115949  -38.77315065 -404.26480588   61.58569188  156.74549342
 [11] -230.03065577 -217.09770574   74.18853066  -60.61363339  -31.09887406
 [16]   67.40118812  182.79442704  -35.03135523  -84.20440510 -217.36940249
 [21]  -61.52163548  -69.80964050 -100.43825248  -44.49844886 -281.18747886
 [26] -353.17517214  -43.75506995  -95.05611593 -148.52106328 -124.60078314
 [31]  -37.49704408  -75.04123723  232.77508824  188.10225002  -24.64670685
 [36]   69.15711547   87.91752189   95.65851604  361.24590878   89.11272062
 [41]  181.62936485 -139.77035755  -68.99805616  241.12096332   46.52614327
 [46] -110.23972618  -48.75212746  470.21585320   75.70645501 -441.88914199
 [51]  788.83514071  123.48077943 -199.15266363  814.09640342  396.53601445
 [56] -445.54203147 -437.94916961  339.29913878 -151.07082495 -242.08216626
 [61] -247.98559790 -479.07499425 -338.96084230 -223.95293767  460.38527662
 [66] -196.15245449 -194.54409104 -240.72751514  218.70624919  126.90544810
 [71] -371.19228790 -512.38401118  321.59006181 -384.57464113 -117.26167515
 [76]   15.89512302 -433.18621770  110.24487535   95.19100915  142.75368617
 [81] -191.31857251  473.90539940  422.01209124  449.47513538  109.87378304
 [86]  290.55344506  501.03147840 -311.89268187  -99.89110740   66.28718745
 [91]  152.65285923  110.78269082 -169.89255419  -62.35027623   -1.55667691
 [96]   12.21014948  -23.27280957   37.01812332 -224.10832994 -151.70871286
[101]  -65.74831914  150.69415075  -81.51018539 -295.38032072   74.95483171
[106]    6.87189526   37.47531113 -154.87942233   66.54103412   58.88146378
[111]   31.51139465  -46.97027502  -20.26816229   53.25423103 -193.16707880
[116]   -0.99852347    0.99564423    0.99351120   -0.99329581    0.99027606
[121]   -0.06959645    0.99852155   -0.99564591   -0.99351126    0.99329900
[126]   -0.99027322    0.06959638
0.0181721 
** 0.0181721 

** Ensemble 1 
0.3018895 
** 0.3018895 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1392572  :
 [1]    35.2829293   677.3551440    65.3871253  -996.5409053   575.4642514
 [6]  -448.6423954  -194.6087841   391.7111156   100.8469523    62.6461065
[11]  -910.0953325   316.7106906   672.1581075 -1042.5988103  -601.6007239
[16]   155.1905207  -888.9296934  -487.4723577   782.5802166  1004.0503321
[21]  -748.6118832  -434.8705882  -308.2290565   521.4554171  1234.5802478
[26]    64.8209153  -600.5824662   827.1815516  -265.6126782   -58.1241031
[31]   397.4807442  -354.5813000   347.8871739  -386.7605794   898.7113134
[36]  -296.0982175  -627.0206536  -544.9448573  -114.1565103  -485.5500180
[41]   477.6363738   -53.0075591  -635.6037352  -178.0915757   470.6712231
[46] -1610.4725102    26.4683130   897.0018240  -246.1016847  -697.5603363
[51]   621.4172081   413.2010866  -533.3800980   243.9746881   263.7506424
[56]  -168.4012713 -1040.5604223  -226.3295966   531.1976100 -1345.8173255
[61]  -857.3729539     2.1637946   -17.2396697   146.5701308   741.6145913
[66]  1007.0057474  -628.3931398  -608.5017393  -109.1505776     0.5450020
[71]     0.9742033     0.4442195     0.9810386    -0.5450060    -0.9741889
[76]    -0.4442161    -0.9810240
0.1392572 
** 0.1392572 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.07025468  :
  [1]    1.35081663 -128.85283547 -281.49884489 -597.22537514  450.07104623
  [6] -189.14834471   79.50660549  107.62630505   69.30680952  243.77499707
 [11] -607.57027940   82.70298024  653.05437117 -301.51860933  -97.34123123
 [16]   74.88595689 -243.48203773 -239.12632246   20.78493184  600.26652350
 [21] -491.02296328 -302.45918492 -110.53024603   64.56335376  -24.79357840
 [26]  -17.02674265  -27.45156264   53.82730358  -17.64390764   48.35417326
 [31]   49.26695103  117.25145904   62.80846005 -104.32037661   71.85877172
 [36]   26.92076049    5.82989206    1.06280874   48.88718242  -42.02059248
 [41]    5.30875366    6.54385580   46.77723976  -64.39894903  -61.60504220
 [46]   18.85819139   52.46968429  226.72228766  -72.63934700   32.99086153
 [51]  149.88984136  432.54197483   16.81458330   59.25136445  140.70685910
 [56]  -66.90624713 -412.65533728  165.37439524 -220.11711185  249.08668634
 [61]  103.85495877  105.81921091  346.99073284  568.05955477  396.57046538
 [66]   85.71584295  212.83088386  759.11281063 -492.52017050   91.58545381
 [71]  367.89227893  198.91550029  -80.36331221   99.76548729 -124.41547241
 [76] -174.29406345  208.61997941  149.54346624 -202.51924443  149.62444510
 [81]  328.33705166  -56.80835839 -410.53040268 -366.07847923 -345.70116669
 [86] -474.88109271 -545.62804508 -366.10602907  -39.47027850 -135.59750280
 [91] -308.47915320  536.80347564  -99.61423295  -20.77495327   58.10459989
 [96]   12.44943291  -62.83572928 -202.62757440  -26.70338241  -86.81097897
[101]  147.52323099  -27.40530451  191.50569084  -38.81339879  106.38534788
[106]  -48.97391536    6.49341278  -51.55965194  -51.33973003 -121.30936070
[111]   87.24712232    8.75219469   31.74036506  -20.42546063  243.29941889
[116]    0.95905471    0.01840446    0.95851130    0.97537100   -0.05150131
[121]    0.01110296   -0.95905236   -0.01840149   -0.95851729   -0.97536868
[126]    0.05148920   -0.01109254
0.07025468 
** 0.07025468 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3450634  :
 [1] -104.0999326  366.5357605   -4.7287348 -199.2177738  132.0756764
 [6]  106.1891648 -161.4798793  304.4264116  111.3187394 -194.1339036
[11] -280.5742138   61.2453855   87.4550942 -257.2295836 -179.6972243
[16] -130.5300468 -297.5703394  -75.0689014  299.1695535  248.1395412
[21] -327.9167148  -93.5789886 -140.4758286    0.8184149    0.1395456
[26]   -0.8184154   -0.1395465
0.3450634 
** 0.3450634 

** Ensemble 1 
0.2432938 
** 0.2432938 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.05322688  :
  [1]  3.080960e+01  2.683120e+01 -2.230318e+01 -3.372493e+01  2.981227e+01
  [6]  3.225866e+01  2.546020e+01 -1.520145e+02  1.378221e+01  7.151554e+00
 [11]  8.728124e+01 -3.069771e+01 -8.310224e+01  6.296949e+01  4.000456e+01
 [16] -2.906685e+01  1.016741e+02  4.831690e+01 -5.532261e+01 -1.129234e+02
 [21]  1.823071e+02  6.018232e+01  1.952214e+01 -5.108235e+00  3.060423e+01
 [26]  3.989871e+01  6.015069e+01  5.952225e+01  3.102989e+01 -2.470304e+01
 [31]  2.885157e+01  3.196549e+01  5.290935e+00 -1.195124e+01 -4.926438e+00
 [36]  6.690494e+00  4.383616e+01  2.965710e+01  2.771270e+01  2.386933e+01
 [41]  2.525149e+01 -8.124448e+01 -2.466493e+01  9.367181e+00  1.512635e+02
 [46] -4.324128e+01  2.826196e+01 -3.532280e+01 -7.817682e+00  4.253022e+01
 [51] -5.288470e+00  8.711061e+00  2.321870e+01 -3.768346e+01 -3.031040e+01
 [56]  1.995456e+01  5.520606e+01 -9.672223e-01 -1.819437e+01  3.129132e+01
 [61]  2.016502e+01  1.041244e-02  1.841640e+01  1.356048e+01 -4.545670e+01
 [66] -3.975310e+01  4.754124e+01  3.848634e+01  2.026016e+01  4.247815e+00
 [71]  6.297692e+01  3.269702e+01  4.631773e-02  5.939425e+01  1.063817e+02
 [76]  4.509448e+01  6.874736e+01  1.644587e+01 -6.671322e+00 -8.923514e+01
 [81]  7.257197e+01 -1.209490e+02  3.218553e+01 -1.398250e+01 -3.941472e+01
 [86]  9.579596e+01  2.629439e+01  1.193650e+02  2.177269e+01  6.766540e+01
 [91]  1.245164e+02 -1.142878e+02  3.409764e+01  2.071731e+01 -3.528148e+01
 [96] -2.279879e+01  4.069839e+01  1.614988e-01 -1.147723e+02  9.216164e+01
[101]  1.930233e+01 -1.163191e+01 -2.363010e+01  6.143914e+01  8.391803e+00
[106] -4.728902e+01 -6.155214e+01 -1.449133e+01 -6.015951e+01  2.632930e+01
[111] -1.765236e+01 -3.940388e+01  1.079011e+01 -2.216339e+01  4.777120e+01
[116] -9.890020e-01  2.463067e-02 -5.743684e-03  9.981774e-01  9.671692e-01
[121]  2.653255e-02  9.890192e-01 -2.461340e-02  5.717753e-03 -9.981987e-01
[126] -9.671870e-01 -2.652645e-02
0.05322688 
** 0.05322688 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3645858  :
 [1]  114.80346383  -59.88714185   -3.16857218  156.18906427 -287.06588621
 [6]  -72.93744614   52.33148703 -368.41018562  -19.94490692   66.80263920
[11]  150.30796911  -19.11106662   34.49814047   68.09417681   85.35652077
[16]  -18.25746172   50.62532489  -27.92293350  -74.66230436  -70.17594002
[21]  281.21654793   75.38736179    0.48722023   -0.79799273   -0.07722591
[26]    0.79799285    0.07722559
0.3645858 
** 0.3645858 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2267885  :
 [1] -1.498061e+01  3.017018e+02  2.072256e+02  7.963177e+00  4.320111e+02
 [6]  1.769864e+02 -4.573844e+01  4.814088e+02 -6.975817e+01 -8.309794e+01
[11] -1.086540e+02  1.896114e+02 -1.787448e+02 -2.635772e+01 -9.544958e+01
[16] -2.160993e+00 -1.483442e+02  1.453611e+02 -2.694245e+00 -1.536867e+02
[21] -8.905837e+01  2.233809e+02 -2.554011e+02 -4.058177e+02  1.726289e+02
[26] -4.013091e+01 -5.185007e+02  2.989679e+01 -3.419566e+01 -1.788545e+02
[31]  4.826475e+02  1.723584e+02 -9.951875e+01 -5.328414e+02 -1.885245e+02
[36]  5.263887e+02 -2.421748e+02 -5.751308e+01 -3.293758e+01 -4.113532e+02
[41] -2.101313e+02  4.563657e+02  3.253234e+02 -4.535968e+02 -4.236677e+02
[46] -2.046075e+02  4.531121e+02 -3.101763e+02 -2.827794e+02  6.375106e+02
[51] -1.145335e+03 -8.020817e+01  2.432669e+02 -1.425539e+03 -2.657360e+02
[56]  2.189501e+02  6.258194e+02 -2.958768e+02  2.969775e+01  4.825288e+02
[61]  4.694309e+02 -2.169567e+02  2.038826e+02  1.269325e+02 -4.233712e+02
[66] -1.232639e+02  9.689062e+02  1.058085e+02 -2.264169e+02  3.292546e-01
[71]  5.652083e-01 -6.001436e-01 -2.698309e-02 -3.292579e-01 -5.652094e-01
[76]  6.001454e-01  2.698202e-02
0.2267885 
** 0.2267885 

** Ensemble 1 
0.05204771 
** 0.05204771 

** Ensemble 1 
0.2510861 
** 0.2510861 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1576242  :
 [1]  3.416315e+03  8.520092e+03  1.726416e+03 -2.547607e+03  5.241580e+03
 [6] -3.359939e+03  2.395139e+03  9.868360e+03  1.866720e+03 -1.745815e+03
[11] -4.387492e+03  2.860044e+03 -1.004623e+03 -5.804313e+03 -4.582175e+03
[16] -4.255054e+02 -3.793698e+03 -2.266715e+03  1.349838e+03 -3.498715e+03
[21] -3.206603e+03  4.715148e+03 -7.340274e+03 -1.999551e+03  4.231291e+03
[26]  1.807585e+03 -3.337486e+03  1.211450e+03 -4.099261e+01 -1.971452e+03
[31]  4.933775e+03  8.398344e+02 -5.391491e+01 -4.033759e+03  1.276883e+03
[36]  4.751826e+03 -7.851315e+03 -4.408316e+03 -2.698375e+03 -5.696017e+03
[41] -2.656020e+03  1.001068e+04  5.180092e+03 -4.668001e+03 -3.379988e+03
[46] -2.432058e+03 -2.745600e+03  5.396387e+03 -1.256573e+03 -2.077510e+03
[51]  4.870204e+03  1.651479e+03 -3.989482e+03  4.735414e+03 -4.956331e+01
[56] -8.904120e+02 -5.117842e+03  2.890077e+03  5.834140e+03 -1.046454e+04
[61] -6.028648e+03 -5.046567e+03 -5.221439e+03 -3.642936e+02  1.099761e+04
[66]  5.972896e+03 -5.785465e+03 -6.458898e+03 -3.406881e+03  7.266354e-01
[71]  2.408226e-01  7.037339e-01  7.384508e-01 -7.266332e-01 -2.408262e-01
[76] -7.037303e-01 -7.384500e-01
0.1576242 
** 0.1576242 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.06845964  :
  [1] -2.200856e+02 -1.034260e+03 -2.781573e+02  3.682505e+02 -8.653652e+02
  [6] -1.106579e+02 -4.193260e+02 -2.595926e+03 -1.166670e+03  6.573174e+02
 [11]  5.355725e+02 -1.095159e+03 -6.408185e+02  9.306400e+02  6.038989e+02
 [16]  1.715327e+03  1.174470e+03  3.695738e+01  8.133794e+02  8.954392e+02
 [21]  1.368785e+03 -1.184371e+03 -1.828776e+03  9.372976e+02 -1.814431e+03
 [26]  1.972443e+03  1.678179e+03 -1.786097e+03 -5.020238e+02  1.655067e+03
 [31] -1.846662e+03 -1.328188e+03  2.062432e+03  2.596846e+03  1.229785e+02
 [36] -1.277416e+03  3.205717e+03  1.968084e+03  1.907262e+01  2.989046e+03
 [41] -1.873200e+02 -1.425837e+03 -2.657593e+02  2.784077e+03 -2.275355e+03
 [46]  1.492012e+03  8.069557e+02 -3.970696e+03 -1.268814e+03  1.527066e+03
 [51] -9.753260e+02  1.740700e+03  1.823733e+03 -4.519758e+03  1.534050e+03
 [56] -6.024619e+02  1.821138e+03 -1.115416e+03 -1.861834e+02  3.121999e+03
 [61]  2.193728e+03  4.771120e+02  3.856645e+03  7.137897e+02 -3.648582e+03
 [66] -2.740659e+02  2.863585e+03  2.117082e+03 -5.014158e+01 -1.173440e+03
 [71]  8.445763e+02 -6.747636e+01 -1.967447e+03  5.542503e+02 -1.565231e+02
 [76] -1.033601e+03  1.453994e+03  4.170707e+02 -6.262478e+02 -2.384748e+03
 [81]  8.307800e+00  1.881095e+03 -2.319784e+03 -1.182340e+03  1.729164e+02
 [86] -1.930610e+03 -3.080112e+02  2.416430e+03  1.261031e+03 -2.214766e+03
 [91] -1.017884e+03 -2.237936e+03  1.874038e+03  3.696990e+03  5.045086e+02
 [96]  6.045643e+02  1.713349e+03  1.244509e+03  4.386482e+02  3.210139e+03
[101] -1.322046e+01 -1.571777e+02  2.775825e+03  2.836453e+03 -2.688469e+03
[106] -1.928206e+03 -2.054003e+03  1.917086e+03  9.593687e+02  2.103239e+03
[111]  4.346788e+02  1.132997e+03  1.069176e+03  3.181216e+03 -8.076913e+02
[116] -3.730657e-01 -6.137072e-01 -6.083578e-01  3.741537e-01  9.872053e-01
[121] -1.592116e-02  3.730724e-01  6.136922e-01  6.083454e-01 -3.741654e-01
[126] -9.871951e-01  1.592328e-02
0.06845964 
** 0.06845964 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.4600653  :
 [1]  -32.0018983  445.8208057  157.0297553 -335.8341669  283.1090502
 [6]  210.2745307 -219.6236215  303.6960663  274.0260202 -237.0656296
[11] -400.1114999 -285.4700730  352.0039077 -639.8498686 -365.9340505
[16] -133.4316987  108.2429560  -40.7348324  335.5121412  546.5535650
[21] -343.4698047 -209.3416240 -155.4560196    0.7624301    0.2143405
[26]   -0.7624218   -0.2143358
0.4600653 
** 0.4600653 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2722634  :
 [1]   48.8801124 -133.6559675  -34.5462409   59.1961889  -31.3249567
 [6] -157.4613572   63.7331824  -94.5212220   -7.0229018  107.0019736
[11]  118.6906334   38.2771694   -9.4622068  101.9279752   69.3068855
[16]  129.7121974   60.7841922  -83.0840220  -59.0007592 -100.2372495
[21]   13.5500224  138.8321059   18.0466601   26.4638070  204.8724496
[26]  167.3097117 -199.9680381   98.6253324   32.6084639  -91.0144797
[31]  201.3891987   16.6947880  -69.6728602 -155.1887296  -53.4196161
[36]   33.9243102 -253.2436703 -171.3192967  -93.3571761   23.4695596
[41] -119.2113690  192.3553007  211.3845889 -193.8669649 -145.2137126
[46]   49.6976870   52.3310337  -42.1379338   50.3959734   71.1601007
[51]   53.2586692  -20.0831093   23.7672401   28.1441846  -44.3631494
[56]  -36.5129116   22.3283097   45.1919269  -76.6033466   91.8035340
[61]   37.9279418   11.5287211   -1.3131920   16.1938799  -69.9964846
[66] -135.1758122   37.8771860   92.3916668  -52.1645807   -0.6170108
[71]    0.9596495    0.7085769    0.1247820    0.6170117   -0.9596499
[76]   -0.7085772   -0.1247825
0.2722634 
** 0.2722634 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.01811849  :
  [1] -4.823648e+01  4.731715e+01 -3.274880e+01 -2.706800e+01  4.643584e+01
  [6]  4.965886e-01 -8.402761e+01  3.307080e+01  2.689301e+01 -7.837638e+01
 [11] -1.078464e+02 -3.990290e+01 -2.642995e+01 -1.917359e+01 -2.205068e+01
 [16] -1.234737e+02 -8.609197e+01  2.831777e+01  1.262365e+02  7.592371e+01
 [21] -1.907401e+01 -3.402274e+01  9.719073e+01 -1.450818e+02 -1.051726e+02
 [26] -1.079139e+02  1.834027e+02 -5.422127e+00 -3.284219e+01  3.767248e+01
 [31] -2.602353e+02 -4.716778e+01  1.102050e+02  2.060339e+02  1.348076e+02
 [36] -1.290056e+02  1.721106e+02  9.582053e+01  5.798196e+01  1.538478e+02
 [41]  1.682645e+02 -1.510589e+02 -1.781653e+02  1.198932e+02  1.225442e+02
 [46]  7.524340e+01 -3.366681e+01 -3.386790e+00 -1.057585e+02  1.635890e+01
 [51]  3.203005e+01  2.578645e+01 -1.519113e+01 -5.745362e+01  4.298116e+01
 [56]  1.639803e+00 -2.104086e+01 -4.724412e+01  9.027639e+01 -5.478567e+01
 [61] -8.709383e+00 -7.691556e+01 -3.376750e+01 -4.069914e+01  6.907267e+01
 [66]  7.659527e+01 -1.147163e+02 -8.824373e+01  1.388700e+02  2.345125e+01
 [71]  1.071530e+02  1.209763e+02  2.345560e+01  4.630410e+00  8.814467e+01
 [76] -9.155807e+01  2.836167e+00  3.369967e-02  2.492161e+01  1.933352e+02
 [81]  1.416218e+02  5.318925e+01  8.755749e+01  8.283191e+01  4.642849e+01
 [86] -1.034893e+02 -8.593914e+01 -3.773757e+00  1.472863e+02  1.467376e+02
 [91]  9.693691e+00 -1.463000e+02 -8.803253e+01  2.185958e+01 -3.861417e+00
 [96] -2.409299e+01  9.042316e+01  3.908033e+01 -1.652739e+02  2.612709e+00
[101]  8.899938e+00 -1.973460e+02 -2.770642e+01  7.892174e+01 -1.087404e+02
[106]  3.906275e+00 -4.012334e+01 -1.024460e+02  9.173501e+01  7.185823e+01
[111]  1.369125e+01 -1.453103e+02  6.922159e+01  3.895817e+01  1.927874e+02
[116]  9.937488e-01 -9.872688e-01 -9.918592e-01  9.979329e-01  9.896129e-01
[121] -3.620500e-03 -9.937645e-01  9.872749e-01  9.918811e-01 -9.979388e-01
[126] -9.896346e-01  3.624973e-03
0.01811849 
** 0.01811849 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.2976473  :
 [1]   79.16064436 -320.07162882   14.77095834  397.63454893 -412.00082371
 [6]   27.45282290  187.13921353 -305.40380569  -14.56735660   96.74417924
[11]  230.70573183  -43.55254543 -211.19139855  550.40964414  327.92050048
[16]    0.77002590  356.67188084  -51.60725788 -383.11312408 -150.52168007
[21]  311.94160947  212.39034655  178.95179341   -0.84091133    0.09688002
[26]    0.84091123   -0.09687997
0.2976473 
** 0.2976473 

** Ensemble 1 
0.2071636 
** 0.2071636 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.08277213  :
  [1]    5.45584218  -57.82676652  -23.76942394  -26.34433811   -7.98761057
  [6]  -43.71982243   -0.24552110   13.86390062  129.83710808  -29.57444968
 [11]  -50.22965185  -22.26864362  -60.88457849   43.81271951   13.72279294
 [16]  -80.98212319   57.58744520 -156.40704827   17.99993248   32.29649419
 [21]    3.98027007  200.42569971  267.09588798 -111.13032831 -130.39857626
 [26] -252.71396461 -210.19494736  179.89128009  138.53600832 -156.87962396
 [31]   86.62762341   46.44178621 -112.89334172 -323.83401328 -119.07421250
 [36] -161.04947809  -20.40460798  -57.92840293  -13.06230092  -33.95298073
 [41] -236.40797507  194.13690917  180.30226665 -176.70542523 -264.19712899
 [46] -225.21812043  124.54925356  296.95179545  -11.93310576  -22.07243629
 [51]  168.60902370  274.99844002   -0.07041214  325.26329888  -45.61451605
 [56]    8.68934397  256.77511571  294.08019907  -98.27042365   80.02014460
 [61]   47.17453220    4.13068870  -67.24420843  -22.84360671  -17.92612263
 [66]  113.90204152  141.27165134  245.85200154 -227.29181543  175.87878208
 [71]  109.04654922 -119.72851912 -298.79906238  311.11546404  -94.42024009
 [76] -201.15160282  388.57904546  -10.17327770  212.43446411 -239.08578278
 [81]  246.12243834   10.68850663 -206.97097217 -161.50025067  -76.71009181
 [86] -128.33844231   19.93521999  125.82738967  -67.32028992 -122.05169429
 [91]  -28.13337676   67.46282027   39.91588953  -53.77412995   64.41839485
 [96]  116.86272086  -92.92540576   12.26999443   65.34973837  -88.83253811
[101]   25.41202021   32.45700526   72.54144226  -18.90707294  -48.23279325
[106]   95.10895222   52.60347155   11.30905356   88.65429183   32.71063344
[111]    2.31578829  -45.26274572   69.91381702  163.96214690  221.39392707
[116]    0.05967375    0.89296925    0.91365890    0.90229194   -0.07395761
[121]    0.01222854   -0.05967392   -0.89296791   -0.91365918   -0.90229134
[126]    0.07395760   -0.01222978
0.08277213 
** 0.08277213 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3177404  :
 [1] -147.25332108  564.24326350  299.01672342 -205.57277041  262.54575849
 [6]  111.99377512 -289.74949319  564.22587980  -81.24465506  -91.58395719
[11] -203.07570734  -20.89779060    7.32460933 -338.74961893 -267.90644453
[16]   49.28666741 -272.34452524  -84.94797695  242.31956061  192.49478406
[21] -467.55473205 -192.47440627   45.80519936    0.82391001   -0.03417573
[26]   -0.82390977    0.03417547
0.3177404 
** 0.3177404 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1827183  :
 [1]  -80.90418146   64.60709598  -71.43161008  -84.64382326   42.00672012
 [6]   44.64230953 -171.25952996   36.76207642   59.24663299 -111.25874044
[11] -104.13247219    2.59768487  -97.35388436    4.13297097  -32.61323080
[16]   12.03868628   96.10306179  -53.91741178   80.47469283 -170.10540630
[21]  -59.80576255  -67.58727380  -61.26673429   74.28992975 -153.19671536
[26] -136.95527845  171.12031354 -259.97189672   15.91619753  103.06883237
[31] -399.30578497   72.42308474    4.00467076   96.32368945  -47.24629344
[36]   69.79495837   54.59746457  100.37168236  -13.06948208  101.69171965
[41]   67.31247085 -137.74671484  129.33363918  277.06779773  141.87202753
[46]  -58.14309327   29.34811813  180.10848208  107.86264445   23.51372254
[51]  145.63331208  177.93829484    8.88831068  225.80995607  -58.04217457
[56]    8.94531525  138.94525722  213.84965885  -48.47344258  -17.12206867
[61]  -36.20412534   58.75473747   75.11486867  104.01574193  -14.98343617
[66]   25.86029359    9.38672973  290.69796363  -42.66767536    0.87832552
[71]   -0.89752524    0.94930615    0.02014787   -0.87832945    0.89752855
[76]   -0.94931181   -0.02014789
0.1827183 
** 0.1827183 

** Ensemble 1 
0.06092111 
** 0.06092111 

** Ensemble 1 
0.3378025 
** 0.3378025 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1942405  :
 [1] -246.2088611  -63.4082583  315.1444834   82.5824560  199.2126479
 [6] -176.5938654 -247.1105885 -146.7671321 -164.3302161  177.5705462
[11]  427.3402197  259.7465051 -455.0549963  -22.0548600 -151.7236407
[16] -116.2520211 -170.2809874 -763.1143993 -367.3342661 -393.2929988
[21]  231.8170390  478.6474801  764.7641352  -53.0564468   88.6826690
[26]  159.0330410  168.0972730  137.4883906  -72.9947872  -62.0213750
[31]   49.3782022  -10.6101290   97.5966095  433.8743932  256.7699031
[36] -330.4203794  255.7487848  106.3448899   47.3886649  231.1104008
[41] -270.9293703  263.4393992  361.7842701  376.0897559  -11.7912938
[46] -342.4957605 -650.6527144  386.2384022  170.6250986 -879.0877273
[51] 1192.6450403  141.1232677  305.5911117 1108.9400051 -145.2542882
[56] -151.8923546 -720.7538711  348.7451564 -105.3185215 -600.1086139
[61] -541.8680033 -355.9903975 -334.4090949  220.6287685  214.8866239
[66]   32.7371310   30.0842762 -247.0384642   14.7985857    0.5530739
[71]    0.5532976    0.9474440   -0.1200251   -0.5530823   -0.5533083
[76]   -0.9474473    0.1200262
0.1942405 
** 0.1942405 

** Ensemble 1 
0.06758287 
** 0.06758287 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3926536  :
 [1] -246.4989205  447.0310872   65.6884613 -436.9459663  209.5251157
 [6]   66.8029392 -284.3069798  375.8014322 -104.9314024  -87.8335811
[11] -390.3040750  -69.3828385  116.0402034 -351.7402696 -232.2238318
[16]   52.8217780 -265.4178339   42.3100653  515.2603102  371.8185487
[21] -472.9298732 -262.2347724  -28.4475842    0.7773615   -0.0394054
[26]   -0.7773615    0.0394054
0.3926536 
** 0.3926536 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1529557  :
 [1]  8.714438e+02 -4.832785e+02 -5.662621e+02  6.904230e+02 -6.292942e+02
 [6]  1.836105e+02  2.951060e+02 -1.407747e+03  4.178084e+02  3.145816e+02
[11]  1.162946e+03  1.396420e+02 -3.895386e+02  7.353325e+02  4.939071e+02
[16] -1.938997e+02  7.483603e+02  2.249813e+02 -1.536147e+03 -7.308865e+02
[21]  1.249026e+03  6.123020e+02  1.096121e+02  3.754249e+02 -4.041632e+02
[26] -3.722399e+02  3.176768e+02 -8.529137e+02  6.757235e+02  1.536511e+02
[31] -4.923627e+02 -1.716623e+02  1.905939e+02  8.698365e+02 -7.830270e+02
[36]  1.288312e+02  4.811277e+02  4.138823e+02  1.137601e+02  1.869808e+01
[41] -1.097840e+02  2.559820e+02  5.624249e+02 -1.205246e+02 -3.350077e+02
[46]  2.239624e+02 -9.241265e+01  8.455881e+01 -1.456282e+02 -1.105208e+02
[51]  1.087247e+02  7.539405e+02  7.761760e+00  2.233919e+02  3.137255e+00
[56] -1.991905e+02 -1.297793e+02  3.190315e+02 -9.594346e+01 -1.228470e+02
[61] -1.244015e+02  2.697719e+02  8.030041e+01 -5.904082e+00  7.596604e+01
[66]  2.114403e+02  3.699434e+02  1.117932e+00  7.584089e+01 -9.126732e-01
[71] -9.263173e-01  8.817186e-01  4.311492e-03  9.126742e-01  9.263259e-01
[76] -8.817277e-01 -4.312987e-03
0.1529557 
** 0.1529557 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.01664851  :
  [1]   38.43951541  -21.41773103  -27.25362128   55.11113404  -60.20844017
  [6]   -9.79305738  -16.44206211  -52.33054759   -2.50969236   26.18412529
 [11]   82.95777851 -139.34626339   20.88206164   25.02323792   28.32542683
 [16]  -38.82478624   -2.74165245   16.04904553    5.96975424   77.84854466
 [21]  -40.83573980  -36.74971061   99.29372274  -74.58705726   21.19850780
 [26]  -63.09571271  -56.18585364   -5.10070185   60.39235431  -57.49492590
 [31]  -53.18980197   24.41201144   -7.67469300  -64.77922064   -4.20447469
 [36]   74.55466323  -43.94487061   -8.71386303   18.41748161   45.15699295
 [41]  -17.73330899  100.22024831   47.35213207  -36.63453884 -128.14756638
 [46]  -25.03035260 -124.12972412   85.78190585   58.10924561  -88.59626373
 [51]   79.45292045  -10.26381632  -38.89546631  174.18486491  -73.81224366
 [56]  -12.78482664 -144.34085455  -33.02279156   90.76685067 -109.49857776
 [61]  -63.60787773    7.33070656  -79.98047656  -52.79490639  235.19635587
 [66]   83.78651729 -182.12531260 -124.43596468    3.60558848   49.50022753
 [71]  -31.67865611   54.91744683   44.78879948  -49.00263769  -43.33915776
 [76]   49.60369133  -17.11926150  -24.34656972    4.44777320   60.47485915
 [81]  -45.04620602  -29.60550253   48.10408947   26.32364415   -1.72626725
 [86]   33.20364568   -8.04819188  -18.99445010  -75.54682095   -1.61299931
 [91]   73.73706713  -15.23364161   62.36880319  -18.14489804   54.92954097
 [96]   58.54863078  -10.35611910  -97.68713959   69.86591519    0.49468864
[101]  -19.54005511   15.83743179   60.49972563   33.54304110  -51.19889555
[106]   83.22274749   45.14241451   -4.57627673  -41.12468978  -11.45249890
[111]  -72.89841697 -102.63156695   20.10414961  143.01686638   26.00952393
[116]  -56.64478523  -33.45986764    0.98265844   -0.09383354  -33.37889523
[121]   56.57756169   56.69801241   33.49030540   -0.98295248    0.09393196
[126]   33.40916661  -56.63074467
0.01664851 
** 0.01664851 

** Ensemble 1 
0.2860583 
** 0.2860583 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3266984  :
 [1]  -64.15860004   54.86375855   -1.86317156  -80.57947711   40.29113122
 [6]  -18.76299053  -59.26562022   72.48568749   51.38842427    0.22543258
[11]  -92.65701265  -49.63833580   34.51898478 -102.44602991  -65.59730252
[16]  -12.04545244 -130.49052288   20.52874701  187.16811867  121.52726765
[21] -119.80165413  -91.92318832 -106.58207676   -6.21435629  139.96159629
[26]  -17.42217068  -26.08672718  142.46474413  -41.49971224  -47.64061341
[31]  177.19982607    2.31303938   25.72507258  -49.43716879   49.40991367
[36]   38.21193515 -156.19682637 -103.55846333  -85.03609067 -129.35451903
[41]   22.86484308  127.65004284   37.47930064 -139.60029752  -40.24431006
[46]   18.56552952  107.06949607  -82.80261386   -0.66177418  237.56937732
[51]   25.53626486   34.66471673   49.69685855 -205.81388336   70.69518832
[56]  -65.81216464  158.91958453   72.19332088  -12.35499422  128.21320903
[61]   89.05853821  -70.67233981  139.59392794   52.17286702 -321.86115503
[66] -180.43909467  218.67372847  148.75587778   33.76797465   -0.03124849
[71]    0.50557756   -0.47272709   -0.10486623    0.03124033   -0.50557128
[76]    0.47272987    0.10486199
0.3266984 
** 0.3266984 

** Ensemble 1 
0.04745497 
** 0.04745497 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3722667  :
 [1]   88.4200144 -239.4537200   81.8609887  276.8358813 -223.6152487
 [6]  -65.7880217  169.4363885 -332.4356862 -270.8315658  105.4340607
[11]  257.2818892   63.5808681  -48.2368466  256.3096905  172.6485964
[16]  -13.9495382  205.9029328  128.6776729 -360.9017225 -390.5563237
[21]  372.2928898   68.9888137   72.9513667   -0.7965610    0.1064723
[26]    0.7965580   -0.1064719
0.3722667 
** 0.3722667 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1573809  :
 [1] -193.59016486 -312.09478395  393.20547126  346.64309210 -530.98200589
 [6] -195.82389499  201.43701133 -860.86134307 -585.85863119   98.32544622
[11]  418.32173252 -111.34912189 -128.56217274  634.62340628  419.32920026
[16]  149.77927849  140.04988563   87.78884122 -465.94942405 -292.36010878
[21]  498.32323472   70.63880080   34.61040040  -23.81471339 -267.31445549
[26]   22.78186821   44.82182575   25.42544961  -41.72300023  -56.75176286
[31]  182.53583496 -166.45833088   94.82474588  -64.58986809   74.20701489
[36] -169.12126161   91.63803053   19.76972760  -24.50331556  -85.36678499
[41]  190.39339440    8.53709522 -215.37864023  366.90266543   18.82899271
[46]   67.92059639 -283.46085556  327.09407113  -55.62038162 -402.28186996
[51]  194.53945536 -202.02141708 -461.33191447  459.05414037  122.16985712
[56]   43.49635169 -164.36153942   43.65621571  225.52156635 -320.46047181
[61] -184.50627736  330.98384679 -133.04213802 -468.14790782   97.78655851
[66]  483.74604234 -446.66816856 -240.62317361 -407.42506212   -0.90202913
[71]    0.94989062    0.95231684    0.04013477    0.90205360   -0.94996379
[76]   -0.95234579   -0.04013100
0.1573809 
** 0.1573809 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.01813622  :
  [1]  1.751550e+02  4.873600e+02  1.671004e+02 -2.908731e+01  8.454689e+01
  [6]  2.471427e+02 -2.697635e+02  4.291033e+02 -7.083122e+01 -1.705037e+02
 [11]  1.676223e+02  4.210454e+02 -4.946118e+02  4.145805e+01 -6.968067e+01
 [16] -8.945522e+01 -3.245428e+02  4.867558e+02  3.519513e+02  3.372817e+02
 [21]  2.108570e+02  5.160611e+01 -5.403997e+02 -9.078768e+01 -1.318379e+02
 [26]  3.836850e+01 -5.095392e+01 -2.055558e+02 -1.048884e+00 -3.360436e+02
 [31] -1.621013e+02 -4.152154e+02  4.337315e+01 -6.996070e+01  1.424361e+02
 [36]  6.508854e+01  5.711289e+01  7.133539e+01  2.087155e+02 -5.991270e+01
 [41] -6.634111e+02  1.199174e+02 -8.108394e+02  2.832610e+02  5.265964e+02
 [46]  3.922670e+02  1.967104e+01  2.592655e+02 -4.524813e+01 -8.830139e+01
 [51]  1.615914e+02 -2.393123e+02 -2.398886e+02  2.183759e+02  3.338951e+02
 [56] -2.867470e+02 -1.151184e+02 -4.708598e+01  3.672910e+01 -2.336962e+02
 [61] -1.568102e+02 -8.388543e+01 -4.726862e+02  3.073043e+02  2.780014e+02
 [66]  3.316530e+00 -2.491208e+02  2.080171e+02  4.649753e+02  3.927474e+02
 [71] -7.401348e+02 -1.943339e+02  5.928079e+02 -2.898361e+02 -2.439667e+02
 [76]  6.452770e+02 -1.132398e+03 -4.427328e+02  2.261978e+02  4.202280e+02
 [81]  5.443404e+02 -3.875647e+02  2.009811e+02  9.008625e+01 -3.262740e+02
 [86]  4.813501e+02  3.651992e+02  5.868346e+01 -7.927866e+02  9.308876e+02
 [91]  9.290357e+01  3.526157e+02 -4.214683e+01 -1.940038e+02 -1.360418e+02
 [96]  1.307933e+02 -5.967154e+02 -1.735643e+02  2.569585e+02 -6.701966e+02
[101]  2.182144e+01  2.215894e+02  4.631976e+02 -3.222033e+02  1.496507e+02
[106]  3.431787e+02  3.186821e+02  3.547272e+02 -2.669953e+02 -3.866287e+02
[111] -3.045488e+02 -7.787461e+01  4.954490e+02  1.273691e+02  6.962257e+02
[116]  9.958733e-01  9.936154e-01 -9.298502e-04 -9.870292e-01 -9.993789e-01
[121]  1.020830e+00 -9.958771e-01 -9.936188e-01  9.303464e-04  9.870293e-01
[126]  9.993836e-01 -1.020833e+00
0.01813622 
** 0.01813622 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.3678543  :
 [1]    1.13379576 -114.18289747   24.46119228   76.77853278  -94.18659370
 [6]  -81.30234391    6.23981088 -133.19359891  -48.69336320   67.27999309
[11]  104.52927210  -12.84957725   -3.70784052  127.37029569   93.49362715
[16]   29.44704033   62.72765767   30.32859204  -42.76706007  -94.02197170
[21]   96.46212031   71.76340589   12.67996163   -0.79612306    0.07714955
[26]    0.79612314   -0.07714943
0.3678543 
** 0.3678543 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1779103  :
 [1]  9.568155e+02 -2.827111e+02  3.382514e+02  5.720036e+02 -1.013760e+03
 [6]  5.670307e+02  8.729923e+02 -1.068221e+02 -9.630757e+02  7.255193e+02
[11]  1.670961e+03  4.107754e+01  2.721311e+02  6.180534e+02  5.380985e+02
[16]  1.644258e+02  4.105429e+02  1.952939e+03 -2.764920e+02 -4.008682e+02
[21]  7.378365e+02  4.827246e+02  8.660173e+02 -5.182794e+02  1.960924e+03
[26]  1.031993e+02 -1.591323e+03  2.032628e+03  4.412121e+02 -8.979594e+02
[31]  2.348519e+03  1.318195e+02 -6.748792e+02 -1.926298e+03  7.867953e+02
[36] -1.007763e+03 -7.345451e+02 -8.653527e+02 -4.088776e+02 -6.106377e+02
[41]  8.757288e+02 -6.893077e+01  5.637949e+02 -1.224208e+03 -1.021410e+03
[46]  1.513181e+02 -1.189872e+02 -1.138345e+03 -6.206408e+02  9.533900e+00
[51] -9.490729e+02 -1.505389e+03 -2.477107e+02 -1.010906e+03  1.090556e+03
[56] -1.309063e+02 -7.086223e+02 -2.090216e+03 -2.483527e+02 -2.894817e+02
[61] -2.979471e+02  1.022031e+02 -9.892113e+02 -4.179349e+02 -8.830895e+02
[66] -6.651675e+02 -7.116038e+02 -1.820023e+03  1.063319e+03 -9.495963e-01
[71]  8.711566e-01 -9.440302e-01  2.493471e-02  9.495992e-01 -8.711582e-01
[76]  9.440356e-01 -2.493363e-02
0.1779103 
** 0.1779103 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.08654755  :
  [1] -2.654100e+02 -6.107698e+02 -3.592687e+02  4.488007e+02 -2.737373e+02
  [6] -1.501756e+02 -2.700127e+02 -9.895579e+02  3.156365e+02 -1.484639e+02
 [11] -1.741849e+02 -5.390394e+02 -8.196536e+01 -3.462978e+02 -2.726945e+02
 [16]  1.163484e+02  1.153728e+03  1.090696e+03  1.080334e+02  1.050317e+03
 [21] -1.184664e+02 -6.999582e+02  4.225022e+01  3.182656e+03 -2.289959e+02
 [26]  2.337046e+03  4.977757e+03 -4.600407e+03  1.156489e+03  1.952908e+03
 [31] -1.271027e+03 -2.587142e+03  9.307031e+02  7.577613e+03 -1.135896e+03
 [36]  2.745932e+03  1.969797e+03  2.563124e+03 -3.001675e+03 -6.115560e+02
 [41]  9.283757e+02  1.347754e+03 -1.608521e+03  5.787987e+01  6.177051e+03
 [46]  6.342054e+03  4.062539e+02 -4.317773e+03 -1.120484e+02  4.092485e+03
 [51] -4.743017e+03  6.451879e+02  1.095085e+02 -7.046507e+03 -5.017245e+03
 [56]  3.428337e+03  5.033899e+03 -2.966981e+03  1.262625e+03  4.709510e+03
 [61]  3.884305e+03  2.555211e+03  2.436567e+03 -1.949618e+03 -2.362284e+03
 [66] -5.527844e+00  3.506148e+03  1.456063e+03 -5.129914e+03 -1.470759e+03
 [71]  2.591111e+03  1.577709e+03 -6.790639e+02  4.473468e+03  2.464555e+03
 [76] -1.057789e+03  2.894421e+03 -3.746518e+03  1.328678e+02  4.700800e+02
 [81]  5.746071e+03  4.549773e+02 -1.230008e+03 -8.960642e+02 -2.174928e+03
 [86]  1.810342e+03 -8.880359e+02  9.080446e+02  3.294724e+03  3.461170e+02
 [91]  5.352049e+03  2.662512e+02 -7.455759e+02 -4.818708e+03 -1.320831e+03
 [96]  5.777980e+02 -5.536453e+03 -3.298494e+03  3.014496e+02 -3.967672e+03
[101]  1.525425e+03  1.594672e+03  8.668191e+02 -4.360031e+03  1.010041e+02
[106]  1.620377e+03  1.196369e+03  1.716222e+03  1.413621e+03 -9.605058e+02
[111] -1.576219e+03 -2.122039e+03 -9.268093e+01 -6.623012e+03  1.569337e+03
[116] -3.330724e-02 -9.809226e-01 -9.282228e-01  8.585302e-01 -6.694639e-02
[121] -6.585075e-02  3.330672e-02  9.809106e-01  9.282203e-01 -8.585981e-01
[126]  6.686690e-02  6.586814e-02
0.08654755 
** 0.08654755 

** Ensemble 1 
0.31755 
** 0.31755 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.07122449  :
 [1] -1.865629e+01 -4.113192e+02  2.646757e+02  4.359174e+02 -4.576685e+02
 [6]  5.358290e+02  1.057803e+02 -4.056017e+02 -7.729353e+01  5.244962e+02
[11]  5.505588e+02 -3.229038e+02 -6.839930e+01  3.207011e+02  2.392105e+02
[16] -1.057673e+02  4.605398e+02 -4.634488e+00 -4.812716e+02 -1.713254e+02
[21]  3.396158e+02  1.100780e+02 -1.885701e+02 -5.359208e+02  2.869010e+02
[26] -3.292275e+02 -1.014732e+03  5.812135e+02  5.526404e+02 -3.613801e+02
[31]  6.338434e+02  5.919925e+02 -1.126404e+02 -1.128823e+03 -2.133451e+00
[36]  4.291509e+02 -2.324367e+02 -8.813995e+01 -6.858228e+02 -7.306256e+01
[41]  1.100520e+02  7.580662e+02  5.815466e+02 -4.528619e+02 -6.303612e+02
[46] -4.948010e+02  3.675267e+02 -1.657912e+02  4.936397e+02  1.886466e+02
[51]  1.927864e+02  1.128925e+01  2.320035e+02  1.229118e+02 -3.033451e+02
[56]  3.564677e+02  1.652859e+02  2.633164e+02 -3.246480e+02 -2.060888e+02
[61] -2.696982e+02  4.229666e+02 -1.177493e+02 -2.461829e+02 -4.661562e+02
[66] -2.759955e+02  2.259581e+02  2.036809e+02 -6.577427e+01 -9.310612e-01
[71]  9.699826e-01  9.348725e-01  2.130743e-03  9.310591e-01 -9.699818e-01
[76] -9.348701e-01 -2.131191e-03
0.07122449 
** 0.07122449 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.07054767  :
  [1]  9.038483e+00  6.647501e+00  2.179845e+01 -5.888947e+00 -1.149767e+01
  [6]  6.639461e+00  1.557656e+01  1.274191e+01  1.220068e+01  2.235600e+01
 [11] -9.927915e+00  1.949866e+00  3.767703e+00  9.516698e+00  9.907471e+00
 [16]  4.482835e+00  9.646160e+00  1.907220e+01  4.398598e+01  3.240987e+01
 [21]  1.960167e+00 -3.072708e+01 -8.377492e+01  2.199917e+01 -1.516267e+01
 [26] -2.284412e+01  3.029259e+01 -2.192822e+01  5.772857e+00  3.190002e+01
 [31] -1.773055e+01 -2.151175e+01 -1.082208e+01  3.947550e+01  3.231203e+00
 [36] -2.552023e+00  2.547409e+01  2.058473e+01  7.695212e+00  4.018527e+01
 [41] -3.018529e+01  2.688197e+00  2.022962e+01  3.833249e+01  3.091285e+01
 [46] -1.315257e+01 -9.268001e+01  4.292619e+01 -9.793571e+00 -1.655655e+02
 [51]  7.950709e+01  7.170921e+00 -8.673961e+01  1.200361e+02  3.062490e+01
 [56] -2.831725e+01 -1.419733e+02 -5.630785e+00  1.482672e+01  6.345470e+00
 [61]  3.318721e+00  1.400303e+01 -3.127692e+01 -2.160737e+01  9.614681e+01
 [66]  5.495614e+01 -9.854798e+01 -4.718022e+01 -3.441671e+01  4.899841e+01
 [71] -3.320730e+01  5.317530e+00 -3.472522e+01 -8.830400e+01  5.797581e+01
 [76]  6.931019e+01  9.983031e+00 -8.876202e+00  3.822631e+00 -3.016605e+01
 [81] -4.154020e+00 -5.032432e+01  2.147005e+01  8.355785e+00  9.613745e+01
 [86]  8.818741e+01 -1.294508e+01  5.979341e+01  9.379860e+01  1.263291e+01
 [91]  3.575400e+01 -6.644408e+01 -7.355915e+00  7.162276e+01  2.724846e+01
 [96]  1.229112e+00  6.813421e+01  3.520574e+01 -4.212033e+01  9.560775e+01
[101]  5.289965e+00 -2.221425e+01  5.188272e+01  2.074642e+01 -2.619408e+01
[106] -3.661452e+01 -3.687082e+01  3.483594e+01  5.921269e+01  3.234762e+01
[111]  2.521327e+01  3.840202e+01  1.038533e+01  4.079996e+01 -1.639071e+01
[116] -8.138940e-03 -3.496075e-02  9.760832e-01 -9.135282e-01  9.816268e-01
[121]  2.559263e-03  8.122251e-03  3.497044e-02 -9.760846e-01  9.135441e-01
[126] -9.816400e-01 -2.566032e-03
0.07054767 
** 0.07054767 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.340635  :
 [1]   28.11443629  206.11352324 -104.06475685   48.19734818  106.71431623
 [6]   -3.01839927   86.18042600  319.19918274   34.84827724 -123.86865026
[11] -217.17896058   96.80239783   -9.30004547 -587.81485331 -471.30457877
[16]   10.27657471 -772.42993245  170.93970840  376.65514768  348.78321835
[21]  -54.15900217 -126.45729403  -96.14565150    0.80960149    0.02612612
[26]   -0.80960157   -0.02612609
0.340635 
** 0.340635 

** Ensemble 1 
Complex eigenvalues found for method = BFGS 
coefficients for function value 0.1759839  :
 [1] -29.05120684 -50.27521833 -24.56342156 -25.09132379 -23.35921361
 [6] -53.27038993 -20.89645003 -46.40277101  18.07602833 -16.33978976
[11] -33.76725696 -45.05101349  25.00870556  13.38295097  17.21212997
[16] -15.14194096  30.34970939 -36.88720223 -11.07737738 -18.95222287
[21] -27.09186418 -34.87015847 -15.37341250   8.95801968 -51.99358845
[26]  16.71235289  14.51204533   0.35808725  29.38133507  13.67405950
[31] -61.29523001 -16.60776838  30.80262491  61.03401404   1.43509890
[36] -28.77270169  97.55499136  70.08339879 -14.40437912 126.57319945
[41]  -0.31871597 -85.58772426 -66.11588858  25.46186125  20.47595526
[46]  10.79401451  -6.35179426   9.41878199  26.51263964  -5.87792145
[51]  -4.51367272  -1.81150430  -1.21556079  18.47341025 -17.72046121
[56]  12.88695772  12.54494052  55.55744038 -38.82101131 -31.51391495
[61] -35.85397908 -23.42171186 -54.64919644  14.57855943  14.83644183
[66] -27.08253743  -0.73816226  26.15087373   1.06793988  -0.52936974
[71]  -0.89040442   0.56888735  -0.04744359   0.52937407   0.89040096
[76]  -0.56888986   0.04744494
0.1759839 
** 0.1759839 

** Ensemble 1 
0.03566342 
** 0.03566342 

** Ensemble 1 
0.4208382 
** 0.4208382 

36.366 sec elapsed
[1] "Running msaenet"
245.87 sec elapsed
[1] "Running naive_bayes"
1.185 sec elapsed
[1] "Running ordinalNet"
894.661 sec elapsed
[1] "Running ordinalRF"
<simpleError: Required packages are missing: ordinalForest>
0.036 sec elapsed
[1] "Running parRF"
10.154 sec elapsed
[1] "Running ranger"
8.13 sec elapsed
[1] "Running svmLinear2"
2.064 sec elapsed
[1] "Running svmLinearWeights"
5.29 sec elapsed
[1] "Running ownn"
9.752 sec elapsed
[1] "Running snn"
13.211 sec elapsed
[1] "Running pam"
123456789101112131415161718192021222324252627282930111111111111111111111111110.495 sec elapsed
[1] "Running partDSA"
46.608 sec elapsed
[1] "Running pda"
0.795 sec elapsed
[1] "Running pda2"
0.82 sec elapsed
[1] "Running PenalizedLDA"
<simpleError in .(lambda): could not find function ".">
0.069 sec elapsed
[1] "Running plr"
7.784 sec elapsed
[1] "Running plsRglm"
Registered S3 methods overwritten by 'vegan':
  method      from
  plot.rda    klaR
  predict.rda klaR
  print.rda   klaR
Loading required package: plsRglm
____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
No more significant predictors (<0.01) found
Warning only 2 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: binomial 
Link function: logit 

____Component____ 1 ____
____Component____ 2 ____
____Component____ 3 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

17.466 sec elapsed
[1] "Running PRIM"
727.278 sec elapsed
[1] "Running protoclass"
<simpleError: Required packages are missing: protoclass>
0.034 sec elapsed
[1] "Running randomGLM"
Loading required package: randomGLM
Loading required package: MASS

Attaching package: ‘MASS’

The following object is masked from ‘package:dplyr’:

    select

Loading required package: doParallel
Loading required package: iterators
Loading required package: parallel
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
Warning in randomGLM: nCandidateCovariates is larger than nFeaturesInBag.
  Will use nCandidateCovariates=nFeaturesInBag
360.881 sec elapsed
[1] "Running Rborist"
[1] "Timeout for  Rborist"
220.665 sec elapsed
[1] "Running regLogistic"
[1] "Timeout for  regLogistic"
0.066 sec elapsed
[1] "Running svmLinear3"
1.423 sec elapsed
[1] "Running svmLinearWeights2"
1.948 sec elapsed
[1] "Running rf"
1.357 sec elapsed
[1] "Running rFerns"
4.409 sec elapsed
[1] "Running rfRules"
Registered S3 method overwritten by 'RRF':
  method      from        
  plot.margin randomForest
1980 rules (length<=2) were extracted from the first 500 trees.
1988 rules (length<=2) were extracted from the first 500 trees.
3558 rules (length<=3) were extracted from the first 500 trees.
1975 rules (length<=2) were extracted from the first 500 trees.
1985 rules (length<=2) were extracted from the first 500 trees.
3624 rules (length<=3) were extracted from the first 500 trees.
1988 rules (length<=2) were extracted from the first 500 trees.
3681 rules (length<=3) were extracted from the first 500 trees.
5221 rules (length<=4) were extracted from the first 500 trees.
3616 rules (length<=3) were extracted from the first 500 trees.
1989 rules (length<=2) were extracted from the first 500 trees.
5551 rules (length<=4) were extracted from the first 500 trees.
3679 rules (length<=3) were extracted from the first 500 trees.
1946 rules (length<=2) were extracted from the first 500 trees.
5692 rules (length<=4) were extracted from the first 500 trees.
5303 rules (length<=4) were extracted from the first 500 trees.
3601 rules (length<=3) were extracted from the first 500 trees.
1988 rules (length<=2) were extracted from the first 500 trees.
3304 rules (length<=3) were extracted from the first 500 trees.
1964 rules (length<=2) were extracted from the first 500 trees.
1989 rules (length<=2) were extracted from the first 500 trees.
3773 rules (length<=3) were extracted from the first 500 trees.
3543 rules (length<=3) were extracted from the first 500 trees.
1975 rules (length<=2) were extracted from the first 500 trees.
5609 rules (length<=4) were extracted from the first 500 trees.
4967 rules (length<=4) were extracted from the first 500 trees.
1970 rules (length<=2) were extracted from the first 500 trees.
3762 rules (length<=3) were extracted from the first 500 trees.
3426 rules (length<=3) were extracted from the first 500 trees.
1993 rules (length<=2) were extracted from the first 500 trees.
5331 rules (length<=4) were extracted from the first 500 trees.
6141 rules (length<=4) were extracted from the first 500 trees.
1977 rules (length<=2) were extracted from the first 500 trees.
5773 rules (length<=4) were extracted from the first 500 trees.
3641 rules (length<=3) were extracted from the first 500 trees.
5927 rules (length<=4) were extracted from the first 500 trees.
3735 rules (length<=3) were extracted from the first 500 trees.
1972 rules (length<=2) were extracted from the first 500 trees.
5146 rules (length<=4) were extracted from the first 500 trees.
3509 rules (length<=3) were extracted from the first 500 trees.
1962 rules (length<=2) were extracted from the first 500 trees.
5714 rules (length<=4) were extracted from the first 500 trees.
3574 rules (length<=3) were extracted from the first 500 trees.
5742 rules (length<=4) were extracted from the first 500 trees.
3645 rules (length<=3) were extracted from the first 500 trees.
5428 rules (length<=4) were extracted from the first 500 trees.
5326 rules (length<=4) were extracted from the first 500 trees.
5573 rules (length<=4) were extracted from the first 500 trees.
5713 rules (length<=4) were extracted from the first 500 trees.
5797 rules (length<=4) were extracted from the first 500 trees.
5544 rules (length<=4) were extracted from the first 500 trees.
5918 rules (length<=4) were extracted from the first 500 trees.
5351 rules (length<=4) were extracted from the first 500 trees.
5613 rules (length<=4) were extracted from the first 500 trees.
5546 rules (length<=4) were extracted from the first 500 trees.
5278 rules (length<=4) were extracted from the first 500 trees.
5578 rules (length<=4) were extracted from the first 500 trees.
1981 rules (length<=2) were extracted from the first 500 trees.
1995 rules (length<=2) were extracted from the first 500 trees.
1991 rules (length<=2) were extracted from the first 500 trees.
1975 rules (length<=2) were extracted from the first 500 trees.
1987 rules (length<=2) were extracted from the first 500 trees.
1979 rules (length<=2) were extracted from the first 500 trees.
1968 rules (length<=2) were extracted from the first 500 trees.
1985 rules (length<=2) were extracted from the first 500 trees.
1985 rules (length<=2) were extracted from the first 500 trees.
3716 rules (length<=3) were extracted from the first 500 trees.
3560 rules (length<=3) were extracted from the first 500 trees.
3703 rules (length<=3) were extracted from the first 500 trees.
3471 rules (length<=3) were extracted from the first 500 trees.
3706 rules (length<=3) were extracted from the first 500 trees.
3620 rules (length<=3) were extracted from the first 500 trees.
3750 rules (length<=3) were extracted from the first 500 trees.
3589 rules (length<=3) were extracted from the first 500 trees.
3539 rules (length<=3) were extracted from the first 500 trees.
5741 rules (length<=4) were extracted from the first 500 trees.
28.285 sec elapsed
[1] "Running RRF"
8.795 sec elapsed
[1] "Running rmda"

Iter: 1 fn: -9332.9272	 Pars:  0.9999878047690 0.0000000002255 0.0000121954986 1.0000000000000
Iter: 2 fn: -11047.9746	 Pars:  1.00e+00 2.22e-16 1.22e-05 1.00e+00
Iter: 1 fn: -12258.7533	 Pars:  0.0000000217144 1.0000000000000 0.9999999780137 0.0000000002719
Iter: 1 fn: 1e+24	 Pars:  0.54977 0.29763 0.59470 0.45023 0.70237 0.40530
Iter: 2 fn: 1e+24	 Pars:  0.54977 0.29763 0.59470 0.45023 0.70237 0.40530
solnp--> Completed in 2 iterations

Iter: 2 fn: -13814.1088	 Pars:  2.185e-08 1.000e+00 1.000e+00 2.220e-16
Iter: 1 fn: -11792.6526	 Pars:  8.314e-07 1.000e+00 1.000e+00 2.220e-16
Iter: 1 fn: -44403.7681	 Pars:  0.0000001355831 0.9999884772378 1.0000000000000 0.9999998646048 0.0000115226491 0.0000000002642
Iter: 2 fn: -45956.6759	 Pars:  1.355e-07 1.000e+00 1.000e+00 1.000e+00 1.152e-05 2.220e-16
Iter: 3 fn: -11041.9246	 Pars:  1.000e+00 2.331e-16 1.220e-05 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: 1e+24	 Pars:  0.44139 0.38456 0.97836 0.55861 0.61544 0.02164
Iter: 2 fn: 1e+24	 Pars:  0.44139 0.38456 0.97836 0.55861 0.61544 0.02164
solnp--> Completed in 2 iterations

Iter: 1 fn: -8930.2139	 Pars:  1.000e+00 2.418e-08 9.983e-11 1.000e+00
Iter: 1 fn: -10051.0208	 Pars:  2.529e-11 1.000e+00 1.000e+00 1.646e-08
Iter: 1 fn: -27774.6062	 Pars:  0.0000000961995 0.0000000002804 0.9999999612171 0.9999999041255 1.0000000000000 0.0000000391938
Iter: 3 fn: -13808.6930	 Pars:  2.185e-08 1.000e+00 1.000e+00 2.331e-16
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -10374.5421	 Pars:  1.000e+00 2.428e-08 2.220e-16 1.000e+00
Iter: 2 fn: -11333.3728	 Pars:  2.220e-16 1.000e+00 1.000e+00 1.621e-08
Iter: 2 fn: -11728.3049	 Pars:  8.314e-07 1.000e+00 1.000e+00 3.886e-16
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -29320.7176	 Pars:  9.604e-08 2.220e-16 1.000e+00 1.000e+00 1.000e+00 3.899e-08
Iter: 1 fn: 1e+24	 Pars:  0.52077 0.22667 0.86942 0.47923 0.77333 0.13058
Iter: 2 fn: 1e+24	 Pars:  0.52077 0.22667 0.86942 0.47923 0.77333 0.13058
solnp--> Completed in 2 iterations

Iter: 1 fn: -10530.5176	 Pars:  1.0000000000000 0.0000000561302 0.0000000001252 0.9999999441680
Iter: 3 fn: -45951.2602	 Pars:  1.355e-07 1.000e+00 1.000e+00 1.000e+00 1.152e-05 2.331e-16
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -8395.6057	 Pars:  0.0000000001053 0.9999721757898 1.0000000000000 0.0000278243603
Iter: 2 fn: -12013.9791	 Pars:  1.000e+00 5.598e-08 2.220e-16 1.000e+00
solnp-->The linearized problem has no feasible
solnp-->solution.  The problem may not be feasible.

Iter: 2 fn: -10029.2366	 Pars:  2.220e-16 1.000e+00 1.000e+00 2.782e-05
Iter: 3 fn: -10369.1264	 Pars:  1.000e+00 2.428e-08 2.331e-16 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 3 fn: -11328.0059	 Pars:  2.331e-16 1.000e+00 1.000e+00 1.621e-08
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 3 fn: -29315.3507	 Pars:  9.604e-08 2.331e-16 1.000e+00 1.000e+00 1.000e+00 3.899e-08
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -27274.5334	 Pars:  1.000e+00 2.220e-16 1.453e-07 1.574e-06 1.000e+00 1.000e+00
Iter: 1 fn: -11523.1056	 Pars:  1.000e+00 2.220e-16 2.375e-05 1.000e+00
Iter: 1 fn: -18610.5070	 Pars:  1.000e+00 2.220e-16 2.372e-07 1.000e+00
Iter: 1 fn: 1e+24	 Pars:  0.51534 0.21175 0.66794 0.70905 0.48466 0.78825 0.33206 0.29095
Iter: 2 fn: 1e+24	 Pars:  0.51534 0.21175 0.66794 0.70905 0.48466 0.78825 0.33206 0.29095
solnp--> Completed in 2 iterations

Iter: 3 fn: -12013.9791	 Pars:  1.000e+00 5.598e-08 2.220e-16 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 3 fn: -10023.1378	 Pars:  2.331e-16 1.000e+00 1.000e+00 2.782e-05
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -8670.8496	 Pars:  0.9999998502667 0.0000000004839 0.0000001498014 1.0000000000000
Iter: 1 fn: 1e+24	 Pars:  0.54341 0.30274 0.93262 0.45659 0.69726 0.06738
Iter: 2 fn: 1e+24	 Pars:  0.54341 0.30274 0.93262 0.45659 0.69726 0.06738
solnp--> Completed in 2 iterations

Iter: 1 fn: -9157.4142	 Pars:  0.999999817208 0.000000000703 0.000000183523 1.000000000000
Iter: 2 fn: -10334.6448	 Pars:  1.000e+00 2.220e-16 1.498e-07 1.000e+00
Iter: 2 fn: -10878.9350	 Pars:  1.000e+00 2.220e-16 1.832e-07 1.000e+00
Iter: 2 fn: -11473.2192	 Pars:  1.000e+00 3.331e-16 2.375e-05 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -27274.6117	 Pars:  1.000e+00 2.220e-16 1.452e-07 1.574e-06 1.000e+00 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -18610.6041	 Pars:  1.00e+00 2.22e-16 2.37e-07 1.00e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: 1e+24	 Pars:  0.67102 0.21369 0.76074 0.51220 0.32898 0.78631 0.23926 0.48780
Iter: 1 fn: -8277.7939	 Pars:  1.0000000000000 0.0000001168181 0.0000000005349 0.9999998835018
Iter: 2 fn: 1e+24	 Pars:  0.67102 0.21369 0.76074 0.51220 0.32898 0.78631 0.23926 0.48780
solnp--> Completed in 2 iterations

Iter: 3 fn: -10329.0828	 Pars:  1.000e+00 2.331e-16 1.498e-07 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -9923.7411	 Pars:  1.000e+00 1.167e-07 2.220e-16 1.000e+00
solnp-->The linearized problem has no feasible
solnp-->solution.  The problem may not be feasible.

Iter: 3 fn: -10873.3241	 Pars:  1.000e+00 2.331e-16 1.832e-07 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -38169.1853	 Pars:  7.719e-12 1.000e+00 2.540e-07 1.000e+00 2.167e-05 1.000e+00
Iter: 2 fn: -39497.2014	 Pars:  2.220e-16 1.000e+00 2.539e-07 1.000e+00 2.167e-05 1.000e+00
Iter: 1 fn: -9088.6707	 Pars:  1.000e+00 9.912e-11 8.190e-09 1.000e+00
Iter: 1 fn: 1e+24	 Pars:  0.59028 0.36887 0.69161 0.40972 0.63113 0.30839
Iter: 2 fn: 1e+24	 Pars:  0.59028 0.36887 0.69161 0.40972 0.63113 0.30839
solnp--> Completed in 2 iterations

Iter: 2 fn: -10504.6712	 Pars:  1.000e+00 2.220e-16 8.341e-09 1.000e+00
Iter: 3 fn: -9923.7411	 Pars:  1.000e+00 1.167e-07 2.220e-16 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -8771.8711	 Pars:  0.9999999379312 0.0000000005884 0.0000000618175 1.0000000000000
Iter: 3 fn: -39491.0051	 Pars:  2.331e-16 1.000e+00 2.539e-07 1.000e+00 2.167e-05 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -9835.1098	 Pars:  0.9999999938134 0.0000000003672 0.0000000062979 1.0000000000000
Iter: 2 fn: -10442.9329	 Pars:  1.000e+00 2.220e-16 6.194e-08 1.000e+00
Iter: 3 fn: -10499.3530	 Pars:  1.000e+00 2.331e-16 8.341e-09 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -11425.4263	 Pars:  1.000e+00 2.220e-16 6.241e-09 1.000e+00
Iter: 1 fn: -9170.9456	 Pars:  0.9999996303794 0.0000000002121 0.0000003692523 1.0000000000000
Iter: 1 fn: -9083.2269	 Pars:  0.0000000054849 1.0000000000000 0.9999999945322 0.0000000009231
Iter: 2 fn: -10744.6000	 Pars:  5.476e-09 1.000e+00 1.000e+00 2.220e-16
Iter: 1 fn: -8792.3146	 Pars:  0.0000000007142 0.9999979565685 1.0000000000000 0.0000020434374
Iter: 3 fn: -10437.4196	 Pars:  1.000e+00 2.331e-16 6.194e-08 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 3 fn: -11420.0106	 Pars:  1.000e+00 2.331e-16 6.241e-09 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -10560.3981	 Pars:  2.220e-16 1.000e+00 1.000e+00 2.043e-06
Iter: 2 fn: -10768.1926	 Pars:  1.000e+00 2.220e-16 3.694e-07 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -8888.2717	 Pars:  1.603e-11 1.000e+00 1.000e+00 3.411e-07
Iter: 3 fn: -10739.2830	 Pars:  5.476e-09 1.000e+00 1.000e+00 2.331e-16
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -10174.8182	 Pars:  2.220e-16 1.000e+00 1.000e+00 3.411e-07
Iter: 3 fn: -10554.6413	 Pars:  2.331e-16 1.000e+00 1.000e+00 2.043e-06
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -9786.3497	 Pars:  0.0000000003042 0.9999999703861 1.0000000000000 0.0000000289950
Iter: 2 fn: -11367.8537	 Pars:  2.22e-16 1.00e+00 1.00e+00 2.93e-08
Iter: 1 fn: -20331.2553	 Pars:  0.0000000002338 0.9999948294436 0.9999992823835 1.0000000000000 0.0000051703649 0.0000007175345
Iter: 3 fn: -10169.2074	 Pars:  2.331e-16 1.000e+00 1.000e+00 3.411e-07
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -21884.3836	 Pars:  2.220e-16 1.000e+00 1.000e+00 1.000e+00 5.170e-06 7.176e-07
Iter: 1 fn: -10945.0766	 Pars:  3.893e-09 1.000e+00 1.000e+00 2.220e-16
Iter: 1 fn: 1e+24	 Pars:  2.946e-01 5.550e-01 2.547e-01 1.000e+00 7.054e-01 4.450e-01 7.453e-01 1.323e-23
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 3 fn: -11362.3892	 Pars:  2.331e-16 1.000e+00 1.000e+00 2.930e-08
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -8437.8110	 Pars:  5.618e-11 9.996e-01 1.000e+00 3.727e-04
Iter: 3 fn: -21878.9191	 Pars:  2.331e-16 1.000e+00 1.000e+00 1.000e+00 5.170e-06 7.176e-07
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -10943.1258	 Pars:  3.964e-09 1.000e+00 1.000e+00 2.220e-16
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -10017.8472	 Pars:  2.220e-16 9.996e-01 1.000e+00 3.727e-04
Iter: 3 fn: -10011.6508	 Pars:  2.331e-16 9.996e-01 1.000e+00 3.727e-04
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -29381.8970	 Pars:  0.0000000229634 0.9998940912530 0.0000000003104 0.9999999767807 0.0001059087497 1.0000000000000
Iter: 2 fn: -31178.3276	 Pars:  2.309e-08 9.999e-01 2.220e-16 1.000e+00 1.059e-04 1.000e+00
Iter: 1 fn: -9699.5167	 Pars:  0.0000000001437 0.9999999952949 1.0000000000000 0.0000000043047
Iter: 2 fn: -11153.4610	 Pars:  2.220e-16 1.000e+00 1.000e+00 4.487e-09
solnp-->Minor optimization routine did not converge in the 
solnp-->specified number of minor iterations.  You may need
solnp-->to increase the number of minor iterations.        

Iter: 1 fn: -9434.3441	 Pars:  3.193e-12 9.999e-01 1.000e+00 1.259e-04
Iter: 2 fn: -10650.2104	 Pars:  2.220e-16 9.999e-01 1.000e+00 1.259e-04
Iter: 3 fn: -10644.0140	 Pars:  2.331e-16 9.999e-01 1.000e+00 1.259e-04
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 3 fn: -31172.1312	 Pars:  2.309e-08 9.999e-01 2.331e-16 1.000e+00 1.059e-04 1.000e+00
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -8759.4782	 Pars:  8.108e-09 1.000e+00 1.000e+00 4.994e-11
Iter: 3 fn: -11148.1429	 Pars:  2.331e-16 1.000e+00 1.000e+00 4.487e-09
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 2 fn: -10102.3164	 Pars:  8.14e-09 1.00e+00 1.00e+00 2.22e-16
Iter: 3 fn: -10096.9982	 Pars:  8.140e-09 1.000e+00 1.000e+00 2.331e-16
solnp--> Solution not reliable....Problem Inverting Hessian.

Iter: 1 fn: -9052.0521	 Pars:  2.220e-16 1.000e+00 1.000e+00 6.129e-07
Iter: 2 fn: -9052.0948	 Pars:  2.220e-16 1.000e+00 1.000e+00 6.127e-07
solnp--> Solution not reliable....Problem Inverting Hessian.
2.837 sec elapsed
[1] "Running rocc"
2.139 sec elapsed
[1] "Running rotationForest"
3.68 sec elapsed
[1] "Running rotationForestCp"
4.783 sec elapsed
[1] "Running rpart"
1.204 sec elapsed
[1] "Running rpart1SE"
1.157 sec elapsed
[1] "Running rpart2"
1.254 sec elapsed
[1] "Running rpartCost"
2.156 sec elapsed
[1] "Running rpartScore"
4.18 sec elapsed
[1] "Running RRFglobal"
3.138 sec elapsed
[1] "Running RSimca"
Loading required package: rrcovHD
Loading required package: rrcov
Loading required package: robustbase
Loading required package: rrcovHD
Loading required package: rrcov
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcov
Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcov
Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcov
Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcov
Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Loading required package: rrcov
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: rrcov
Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcov

Attaching package: ‘rrcov’

Loading required package: robustbase
The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Loading required package: rrcov
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Loading required package: robustbase
Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)

Loading required package: rrcovHD
Loading required package: rrcov
Loading required package: robustbase

Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Scalable Robust Estimators with High Breakdown Point (version 1.7-2)


Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

Loading required package: rrcovHD
Loading required package: rrcov
Loading required package: robustbase
Scalable Robust Estimators with High Breakdown Point (version 1.7-2)


Attaching package: ‘rrcov’

The following object is masked from ‘package:R.utils’:

    getRaw

Robust Multivariate Methods for High Dimensional Data (version 0.2-7)

1.978 sec elapsed
[1] "Running sda"
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.2222 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.2222 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.2222 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1956 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1956 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1956 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.9643 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.9643 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.2546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.9643 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.2546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.2546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.5993 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.5993 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.5993 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.9643 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 0.9534 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.9643 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 0.9534 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.9643 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 0.9534 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 0.1546 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 1 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0.5 
Prediction uses 22 features.
Prediction uses 22 features.
Number of variables: 22 
Number of observations: 217 
Number of classes: 2 

Estimating optimal shrinkage intensity lambda.freq (frequencies): 1 
Estimating variances (pooled across classes)
Estimating optimal shrinkage intensity lambda.var (variance vector): 1 


Computing inverse correlation matrix (pooled across classes)
Specified shrinkage intensity lambda (correlation matrix): 0 
2.002 sec elapsed
Prediction uses 22 features.
[1] "Running sdwd"
2.369 sec elapsed
[1] "Running slda"
1.173 sec elapsed
[1] "Running treebag"
1.573 sec elapsed
[1] "Running smda"
Registered S3 method overwritten by 'sparseLDA':
  method      from
  predict.sda sda 
[1] "Timeout for  smda"
133.504 sec elapsed
[1] "Running sparseLDA"
2.406 sec elapsed
[1] "Running spls"
5.117 sec elapsed
[1] "Running vbmpRadial"
<simpleError: Required packages are missing: vbmp>
0.031 sec elapsed
[1] "Running vglmAdjCat"
2.833 sec elapsed
[1] "Running vglmContRatio"
3.511 sec elapsed
[1] "Running vglmCumulative"
3.469 sec elapsed
[1] "Running wsrf"
<simpleError in mcfork(): unable to fork, possible reason: Resource temporarily unavailable>
2.2 sec elapsed
[1] "Running xgbLinear"
[1] "Timeout for  xgbLinear"
1001.064 sec elapsed
[1] "Running xyf"
<simpleError in kohonen::supersom(list(X = as.matrix(x), Y = y), user.weights = layer_wts,     grid = kohonen::somgrid(param$xdim, param$ydim, as.character(param$topo)),     ...): Non-informative layers present: mean distance between objects zero>
3.473 sec elapsed
There were 50 or more warnings (use warnings() to see the first 50)
Warning message:
Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead. 
[1] "Completed execution on: 2023-05-30 03:43:12"
